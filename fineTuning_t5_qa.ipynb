{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1438,"status":"ok","timestamp":1697046156686,"user":{"displayName":"gvvvbjj ffbkitb","userId":"08953530729188044176"},"user_tz":-120},"id":"pIG69wI1xTci","outputId":"9e4e53c4-d9f8-4f53-cd97-2f4fe852649c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'Fig-QA'...\n","remote: Enumerating objects: 639, done.\u001b[K\n","remote: Counting objects: 100% (208/208), done.\u001b[K\n","remote: Compressing objects: 100% (119/119), done.\u001b[K\n","remote: Total 639 (delta 130), reused 139 (delta 88), pack-reused 431\u001b[K\n","Receiving objects: 100% (639/639), 2.81 MiB | 10.48 MiB/s, done.\n","Resolving deltas: 100% (353/353), done.\n","/content/Fig-QA\n"]}],"source":["# Download\n","!git clone https://github.com/nightingal3/Fig-QA\n","%cd Fig-QA/"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28633,"status":"ok","timestamp":1697046474844,"user":{"displayName":"gvvvbjj ffbkitb","userId":"08953530729188044176"},"user_tz":-120},"id":"CmJt-X3y002o","outputId":"dfb47c01-008e-4ed1-d3e4-7024bd2dafeb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.34.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.17.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.14.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n","Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)\n","Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.10->transformers[torch]) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.10->transformers[torch]) (17.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Requirement already satisfied: deepspeed in /usr/local/lib/python3.10/dist-packages (0.11.1)\n","Requirement already satisfied: hjson in /usr/local/lib/python3.10/dist-packages (from deepspeed) (3.1.0)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.11.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n","Requirement already satisfied: pydantic<2.0.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.10.13)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.0.1+cu118)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.66.1)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0->deepspeed) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.12.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (17.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n","Collecting datasets\n","  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-2.14.5 dill-0.3.7 multiprocess-0.70.15 xxhash-3.4.1\n"]}],"source":["# install\n","!pip install transformers[torch]\n","!pip install accelerate -U\n","!pip install deepspeed\n","!pip install datasets"]},{"cell_type":"markdown","metadata":{"id":"hnl88B6s0WLq"},"source":["# Try Running Their Script\n","python3 src/models/train_lm_models.py {gpt2,gpt-neo-sm,gpt-neo-lg} \\\n","[--dont_train] \\\n","[--dont_eval] \\\n","[--train_path=TRAIN_PATH] \\\n","[--eval_path=EVAL_PATH] \\\n","[--seed=SEED] \\\n","[--cuda] \\\n","[--num_epochs=NUM_EPOCHS] \\\n","[--learning_rate=LR] \\\n","[--middle_phrase=SUFFIX_PROMPT] \\\n","[--prefix=N] \\\n","[--contrastive] \\\n","[--contrast_lambd=a] \\\n","[--log_history] \\\n","[--deepspeed] \\\n","[----out_path=PATH] \\\n","[----early_stopping]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":398,"status":"ok","timestamp":1697036710855,"user":{"displayName":"gvvvbjj ffbkitb","userId":"08953530729188044176"},"user_tz":-120},"id":"5rC3hgik0Z4h","outputId":"78cb437f-9235-4a8f-e875-58fed086a902"},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: line 1: cd: Fig-QA: No such file or directory\n"]}],"source":["!python3 src/models/train_lm_models.py gpt2 --cuda"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1697036710856,"user":{"displayName":"gvvvbjj ffbkitb","userId":"08953530729188044176"},"user_tz":-120},"id":"E5YzyDt-0hU5","outputId":"552fe4f4-1859-48b9-8fd1-2540c0b6f159"},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: line 1: cd: Fig-QA: No such file or directory\n"]}],"source":["!python3 src/models/train_lm_models.py gpt-neo-sm --cuda"]},{"cell_type":"markdown","metadata":{"id":"yuZ70qniFC1F"},"source":["# Modifying code\n","\n","### Changes:\n","- modify model_init to use correct loader for model\n","- add model string to main function"]},{"cell_type":"markdown","metadata":{"id":"LW86RLCJ13hf"},"source":["# Setup Base Model: flan-t5-base"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241,"referenced_widgets":["70d40c165c4943e0a0df89fd84c4c576","cec043cb9a144e4f92d2629e671e16b2","f8c64b0aebf44360bba893487fd20307","dc08843021dd48acb698835e4bd56a52","191500a57b204bc7a4447b7feed83d9f","0423a515af344236b0263c86e7f59e14","87d84206fbe844cfb397b11408a01e4e","e5795608e20b444aa01d7c3475a77deb","eeeb31234ea64cad9c795ecbd22a2b9a","56c10f6eafe14ad8a3816c2907782a51","bf32282753f84223b5e567d273ab18cb","089172e6835a460fac915e13ee4661e7","419f1a11c0294059b79e11c7f5cafdc2","d4d3c823a8584f09bdc561f9bc3f107a","c03bd5d3e0f44200bfa621907204e486","d7feffc945e040ef809fbbaceb354615","56526590bff74160903e9d2b59d70d3d","7ffdca088b314776b11662ce2cf05042","667e715e6708430997c333054794d301","85a7e86998624deab1f08b115d165bf7","ecc4da78df434380aba28b160abe6817","adb0608c055e47ef9f00909c9cdd5a5d","b8d77e05cdb549349d8046a4500a1684","edddccf7bcf24b92ad4b3f75ab241e97","55af7f5dc9c54380991d2a49f90c6e1d","c826b981fc5b40ffb3f894d1ba5dbed1","cdbc3b25bb9a408a95aa0d3c3a10858b","a3b012607ba745dba08e0ede1ac7dadf","002859109910485c8f28080ad763086b","1e3df34a74dd4965baf4eda82f9894df","0da7bbb40a914bb5beb3b4cf970caedf","4f7e94fd47294ca587fac6ed4def3f91","86a177ce1f71411ea4ff1a66cc1dbc70","a2ea31659d9c4b3f99953c21830a8ebf","4d1828b0442540a4a1a3e81a62f47496","b0307975789e45c89c1cd6eeeafd0c1c","dbf692fafc0c4000b9b67f8c00c71a6d","338d953d031740759d3fbce10fde164f","23987df4304e4bdb893c174feacbd502","cac799e0dd114080a80109300f2fd898","61e56244890d44a3bc9d5b8ba5d4c85a","aa171d9eeaf8473bb929b505dfe67320","4dc349300b4b49fd9cf8f469561e495a","ebf79df9339341aa8ddc6b8a9eaec2c6","18d821832ff943acb81042e53f1a8b15","b2b3cc9e2ea449b7a9ef1773ae416cda","a04b9d28063341b880d8b41862ccac5b","0ee27c6705f24f46bee5c713f31c9915","df841ecb03d240668b5908ca2417bce7","e334478e7aa94f24afb967ead2747179","6b616c754e074617b569c2e69ca69671","36bc0510dd4d4046b3318dfecdec02cd","5d1bbeeeca3542cfa314c77edfd32c2b","445b09e5ce53442d9be9a880c44de7d4","a74ed066624340dab8e663a4720e0d96","b20cc5fd379643efabebef42ffd49e7e","d6477e8529a7435ca7fb2affe865d200","91de9c438b3947f9a4e4b35bf3ff06a4","6d22fbfec8334fe890e35e60224b7ef3","4a28d2ee9adb40a996e0442032a9dfa8","62b8ec06283142c08eaad7890bffdfab","5d2abec5863e45aab0a5379a9091f319","d84575b9a4814bf6924cedb17a5fdebe","391bf6451aca4aceb80c3380bc8e838f","724d461bfd264b02ac97d8e9be0b17cc","3e25d44e49e94ea0a24550ab289ec3ed","cdb88dc0478440a283bf98dbf71abeda","a7ab3185abb745f58d841ebf7c3f31b1","4f7e899147c24f87b3cef008335c982b","97a6015603d3448ca61eb7029e01a2e9","4cdd3992ef194731a58e0434d6fef13f","bc5c4d2eee714a8482bde0a6109ba300","499f6d8a64ef46aa981d907dfbdf4634","090cfbf845eb4b0f9e59fcc7b401f9bc","53085247ec3f478bafdadefa3df37a69","ff6fc5ae2a0a4f749a93e9bd19903d28","3e562c723b8044e89d4fc216cb766618"]},"executionInfo":{"elapsed":19325,"status":"ok","timestamp":1697046304138,"user":{"displayName":"gvvvbjj ffbkitb","userId":"08953530729188044176"},"user_tz":-120},"id":"TnKLGnfsSpyr","outputId":"df503f58-a0f2-4297-9e35-5f82bbe95d4b"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70d40c165c4943e0a0df89fd84c4c576","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"089172e6835a460fac915e13ee4661e7","version_major":2,"version_minor":0},"text/plain":["Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8d77e05cdb549349d8046a4500a1684","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2ea31659d9c4b3f99953c21830a8ebf","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18d821832ff943acb81042e53f1a8b15","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b20cc5fd379643efabebef42ffd49e7e","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cdb88dc0478440a283bf98dbf71abeda","version_major":2,"version_minor":0},"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import OpenAIGPTTokenizer, OpenAIGPTLMHeadModel, GPTNeoForCausalLM, AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","\n","model_id = \"google/flan-t5-base\"\n","\n","def model_init(model_string, cuda, output_attentions=False, fast=False):\n","    if model_string.startswith(\"gpt2\"):\n","        if fast:\n","            tokenizer = AutoTokenizer.from_pretrained(model_string)\n","            model = GPT2LMHeadModel.from_pretrained(model_string)\n","        else:\n","            tokenizer = GPT2Tokenizer.from_pretrained(model_string)\n","            model = GPT2LMHeadModel.from_pretrained(model_string)\n","    elif model_string.startswith(\"EleutherAI/gpt-neo\"):\n","        tokenizer = GPT2Tokenizer.from_pretrained(model_string, output_attentions=output_attentions)\n","        model = GPTNeoForCausalLM.from_pretrained(model_string, output_attentions=output_attentions)\n","    elif \"t5\" in model_string:\n","      tokenizer = AutoTokenizer.from_pretrained(model_string)\n","      model = AutoModelForSeq2SeqLM.from_pretrained(model_string)\n","    else:\n","        tokenizer = OpenAIGPTTokenizer.from_pretrained(model_string)\n","        model = OpenAIGPTLMHeadModel.from_pretrained(model_string)\n","    model.eval()\n","    if cuda:\n","        model.to('cuda')\n","    return model, tokenizer\n","\n","model, tokenizer = model_init(model_id, cuda = True, fast=True)\n","model.to('cuda')\n"]},{"cell_type":"markdown","metadata":{"id":"rE0sifBoGbrU"},"source":["# Setup Dataset"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":2604,"status":"ok","timestamp":1697050655311,"user":{"displayName":"gvvvbjj ffbkitb","userId":"08953530729188044176"},"user_tz":-120},"id":"2Mx3ucP3Gd1J"},"outputs":[],"source":["dataset = load_dataset(\"nightingal3/fig-qa\")\n","dataset['validation']\n","\n","subset_test_dataset = dataset['validation'].select(range(500))"]},{"cell_type":"markdown","metadata":{"id":"lLl63MLN1180"},"source":["# Evaluate base model"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1697050687548,"user":{"displayName":"gvvvbjj ffbkitb","userId":"08953530729188044176"},"user_tz":-120},"id":"JcDibfIn2AvZ"},"outputs":[],"source":["import numpy as np\n","from scipy.special import softmax\n","import pdb\n","import pandas as pd\n","import math\n","from typing import List\n","import random\n","import argparse\n","import torch\n","\n","\n","def sent_scoring(model_tokenizer, text, cuda, score_type=\"loss\", output_attentions=False, length_normalize=False):\n","    model = model_tokenizer[0]\n","    tokenizer = model_tokenizer[1]\n","    assert model is not None\n","    assert tokenizer is not None\n","    encoded_text = tokenizer.encode(text)\n","    input_ids = torch.tensor(encoded_text).unsqueeze(0)\n","    if cuda:\n","        input_ids = input_ids.to('cuda')\n","    with torch.no_grad():\n","        outputs = model(input_ids, labels=input_ids, output_attentions=output_attentions)\n","    loss, logits = outputs[:2]\n","\n","    sentence_prob = loss.item()\n","    if score_type == \"prob\":\n","        if length_normalize:\n","            mult = 2\n","        else:\n","            mult = len(encoded_text)\n","\n","        sentence_prob = math.exp(-1.0 * loss * (mult - 1))\n","\n","    if output_attentions:\n","        attn = outputs[\"attentions\"]\n","        return sentence_prob, attn, input_ids\n","\n","    return sentence_prob\n","\n","def confusion_matrix(P_forward_1, P_forward_2, P_backward_1, P_backward_2):\n","    correct_forward = len(np.where(np.array(P_forward_1) >= 0.5)[0]) + len(np.where(np.array(P_forward_2) >=0.5)[0])\n","    wrong_forward = len(P_forward_1) + len(P_forward_2) - correct_forward\n","\n","    correct_backward = len(np.where(np.array(P_backward_1) >= 0.5)[0]) + len(np.where(np.array(P_backward_2) >=0.5)[0])\n","    wrong_backward = len(P_backward_1) + len(P_backward_2) - correct_backward\n","\n","    print(\"correct forward\", correct_forward, \"wrong forward\", wrong_forward, \"correct backward\", correct_backward, \"wrong_backward\", wrong_backward)\n","\n","def evaluate_model(model, tokenizer, test_set, middle_phrase=\"\", use_prefix=0, verbose=True, score_type=\"prob\", use_cuda=True, return_acc=False) -> tuple:\n","    preds = []\n","    labels = []\n","    x_1 = []\n","    x_2 = []\n","    y_1 = []\n","    y_2 = []\n","    P_x_1 = []\n","    P_x_2 = []\n","    P_y_1 = []\n","    P_y_2 = []\n","    P_x_1_y_1 = []\n","    P_x_1_y_2 = []\n","    P_x_2_y_1 = []\n","    P_x_2_y_2 = []\n","    P_x_1_correct = []\n","    P_x_2_correct = []\n","    P_y_1_correct = []\n","    P_y_2_correct = []\n","    correct = 0\n","\n","    for i, metaphor_data in enumerate(test_set):\n","        ctx, p1, p2 = metaphor_data[\"startphrase\"], metaphor_data[\"ending1\"], metaphor_data[\"ending2\"]\n","        labels.append(int(metaphor_data[\"labels\"]))\n","        if use_prefix > 0:\n","            prefix_prompt = select_prefix_prompts(prompt_file, use_prefix) if use_prefix else \"\"\n","        else:\n","            prefix_prompt = \"\"\n","\n","        sent1 = prefix_prompt + ctx + \". \" + middle_phrase + p1 + \".\"\n","        sent2 = prefix_prompt + ctx + \". \" + middle_phrase + p2 + \".\"\n","\n","        score1 = sent_scoring((model, tokenizer), sent1, use_cuda, score_type=score_type)\n","        score2 = sent_scoring((model, tokenizer), sent2, use_cuda, score_type=score_type)\n","\n","        if score_type == \"loss\":\n","            pred = 0 if score1 < score2 else 1\n","        else:\n","            pred = 1 if score1 < score2 else 0\n","\n","        pred_sent = sent1 if pred == 0 else sent2\n","\n","        if i % 2 == 0:\n","            x_1.append(ctx)\n","            x_1_score = sent_scoring((model, tokenizer), ctx + \".\", use_cuda, score_type=score_type)\n","            P_x_1.append(x_1_score)\n","            y_1.append(p1)\n","            y_2.append(p2)\n","            y1_score = sent_scoring((model, tokenizer), p1 + \".\", use_cuda, score_type=score_type)\n","            y2_score = sent_scoring((model, tokenizer), p2 + \".\", use_cuda, score_type=score_type)\n","            P_y_1.append(y1_score)\n","            P_y_2.append(y2_score)\n","\n","            P_x_1_y_1.append(score1)\n","            P_x_1_y_2.append(score2)\n","            P_x_1_correct.append(score1/(score1 + score2))\n","\n","        else:\n","            x_2.append(ctx)\n","            x_2_score = sent_scoring((model, tokenizer), ctx + \".\", use_cuda, score_type=score_type)\n","            P_x_2.append(x_2_score)\n","            P_x_2_y_1.append(score1)\n","            P_x_2_y_2.append(score2)\n","            P_x_2_correct.append(score2/(score1 + score2))\n","\n","            P_y_1_correct.append(P_x_1_y_1[-1]/(P_x_1_y_1[-1] + score1))\n","            P_y_2_correct.append(score2/(P_x_1_y_2[-1] + score2))\n","\n","        if verbose:\n","            print(f\"Q: {ctx}: 1. {p1} 2. {p2}\")\n","            print(f\"model says '{pred_sent}' is more likely\")\n","            print(\"\\n\")\n","        if pred == metaphor_data[\"labels\"]:\n","            correct += 1\n","        preds.append(pred)\n","\n","    cols = {\"x_1\": x_1, \"x_2\": x_2, \"y_1\": y_1, \"y_2\": y_2, \"P(x_1)\": P_x_1, \"P(x_2)\": P_x_2, \"P(y_1)\": P_y_1, \"P(y_2)\": P_y_2,\n","        \"P(x_1, y_1)\": P_x_1_y_1, \"P(x_1, y_2)\": P_x_1_y_2, \"P(x_2, y_1)\": P_x_2_y_1, \"P(x_2, y_2)\": P_x_2_y_2,\n","        \"P(y_1|x_1)\": P_x_1_correct, \"P(y_2|x_2)\": P_x_2_correct, \"P(x_1|y_1)\": P_y_1_correct, \"P(x_2|y_2)\": P_y_2_correct}\n","    out_df = pd.DataFrame(cols)\n","\n","    if return_acc:\n","        return correct/len(preds), out_df, preds, labels\n","\n","    return out_df, preds, labels\n","\n","def compute_stats(total_df: pd.DataFrame, all_preds: List, all_labels: List) -> None:\n","    print(\"overall accuracy: \")\n","    print(len(np.where(np.array(all_preds) == np.array(all_labels))[0])/len(all_labels))\n","    print(\"confusion matrix: \")\n","    confusion_matrix(list(total_df[\"P(y_1|x_1)\"]), list(total_df[\"P(y_2|x_2)\"]), list(total_df[\"P(x_1|y_1)\"]), list(total_df[\"P(x_2|y_2)\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"23JRrLaAFS8K"},"outputs":[],"source":["out_df, preds, labels = evaluate_model(model, tokenizer, subset_test_dataset)\n","compute_stats(out_df, preds, labels)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":229,"status":"ok","timestamp":1697046894218,"user":{"displayName":"gvvvbjj ffbkitb","userId":"08953530729188044176"},"user_tz":-120},"id":"W1rqy_w74I4V","outputId":"3853efeb-3abd-43e9-9f77-0862dcb32e6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["overall accuracy: \n","0.538\n","confusion matrix: \n","correct forward 269 wrong forward 231 correct backward 275 wrong_backward 225\n"]}],"source":["compute_stats(out_df, preds, labels)\n"]},{"cell_type":"markdown","metadata":{"id":"ikC02rks4Bbv"},"source":["# Training\n","\n","- checkpoint 2000 can be downloaded here: https://drive.google.com/drive/folders/1-AUFbfZLoVCG03EkQikcV7iVpfwI3HRF?usp=drive_link\n","- file path can be checked in output below"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":239,"status":"ok","timestamp":1697047294281,"user":{"displayName":"gvvvbjj ffbkitb","userId":"08953530729188044176"},"user_tz":-120},"id":"aYNe8zlfFGs0"},"outputs":[],"source":["import argparse\n","import logging\n","from typing import Optional\n","from glob import glob\n","from pathlib import Path\n","import os, sys\n","import torch\n","import numpy as np\n","import pandas as pd\n","import pickle\n","\n","import transformers\n","from transformers import (\n","    DataCollatorForLanguageModeling,\n","    LineByLineTextDataset,\n","    LineByLineWithRefDataset,\n","    PreTrainedTokenizer,\n","    TextDataset,\n","    Trainer,\n","    TrainingArguments,\n","    set_seed,\n","    GPT2LMHeadModel,\n","    GPTNeoForCausalLM,\n","    EarlyStoppingCallback\n",")\n","from torch.utils.data import ConcatDataset\n","import pdb\n","\n","# Add path for those local py modules\n","sys.path.append('src/models/')\n","from gpt_score import evaluate_model\n","\n","logger = logging.getLogger(__name__)\n","\n","def main(model, tokenizer,model_id: str, prompt: str, train_path: str, eval_path: str, contrastive_train: bool, contrastive_train_lambd: float, num_epochs: int, seed: int, lr: int, use_cuda: bool, dont_train: bool, dont_eval: bool, out_path: str, cache_dir: str = \"./lm_train_cache/\", prefix_prompt: int = 0, batch_size: int = 8, log_history: bool = False, deepspeed: bool = False, early_stopping: bool = False) -> None:\n","    # Set up models, random seed, and logging\n","    model_name = model_id.split(\"/\")[1]\n","\n","    logging.basicConfig(\n","        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n","        datefmt=\"%m/%d/%Y %H:%M:%S\",\n","        level=logging.INFO,\n","    )\n","    transformers.utils.logging.set_verbosity_info()\n","    transformers.utils.logging.enable_default_handler()\n","    transformers.utils.logging.enable_explicit_format()\n","    logger.info(\"Training/evaluation parameters %s\", {\"model\": model_name, \"train path\": train_path, \"num epochs\": num_epochs, \"seed\": seed, \"cuda\": use_cuda, \"cache dir\": cache_dir, \"deepspeed\": deepspeed, \"early stopping\": early_stopping})\n","\n","\n","    if deepspeed and not use_cuda:\n","        logger.info(\"You must have GPUs to use deepspeed. Turning cuda flag on...\")\n","        use_cuda = True\n","\n","    tokenizer.pad_token = tokenizer.eos_token\n","    #model.resize_token_embeddings(len(tokenizer))\n","    set_seed(seed)\n","\n","    # load datasets and initialize trainer\n","    train_dataset = (\n","        get_dataset(train_path, tokenizer=tokenizer, cache_dir=cache_dir)\n","    )\n","    eval_dataset = (\n","        get_dataset(eval_path, tokenizer=tokenizer, cache_dir=cache_dir)\n","    )\n","\n","    eval_df = pd.read_csv(\"./data/filtered/dev.csv\")\n","    eval_df[\"label\"] = eval_df[\"labels\"]\n","    test_df = pd.read_csv(\"./data/filtered/dev.csv\")\n","    test_df[\"label\"] = test_df[\"labels\"]\n","\n","    data_collator = DataCollatorForLanguageModeling(\n","                tokenizer=tokenizer, mlm=False\n","            )\n","    no_cuda = not use_cuda\n","\n","    default_arguments = {\n","        \"output_dir\": f\"./lm_train_outputs/{model_name}_{seed}/\",\n","        \"do_train\": True,\n","        \"prediction_loss_only\": False,\n","        \"num_train_epochs\": num_epochs,\n","        \"seed\": seed,\n","        \"learning_rate\": lr,\n","        \"per_device_train_batch_size\": batch_size,\n","        \"per_device_eval_batch_size\": batch_size,\n","        \"no_cuda\": no_cuda\n","    }\n","\n","    if deepspeed:\n","        default_arguments[\"deepspeed\"] = \"deepspeed_config.json\"\n","    if not contrastive_train:\n","        default_arguments[\"per_device_train_batch_size\"] = batch_size\n","        default_arguments[\"per_device_eval_batch_size\"] = batch_size\n","\n","    else:\n","        default_arguments[\"per_device_train_batch_size\"] = 2\n","\n","    if log_history:\n","        default_arguments[\"evaluation_strategy\"] = \"steps\"\n","        default_arguments[\"eval_steps\"] = 100\n","    if early_stopping:\n","        default_arguments[\"evaluation_strategy\"] = \"epoch\"\n","        default_arguments[\"load_best_model_at_end\"] = True\n","        default_arguments[\"metric_for_best_model\"] = \"eval_loss\"\n","        default_arguments[\"save_strategy\"] = \"epoch\"\n","\n","    training_args = transformers.TrainingArguments(**default_arguments)\n","\n","    if early_stopping:\n","        trainer = Trainer(\n","            args=training_args,\n","            model=model,\n","            data_collator=data_collator,\n","            train_dataset=train_dataset,\n","            eval_dataset=eval_dataset,\n","            callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n","        )\n","    elif not contrastive_train:\n","        #tokenizer.pad_token = tokenizer.eos_token\n","        #dummy_init = make_dummy(model_id)\n","        trainer = Trainer(\n","            args=training_args,\n","            model=model,\n","            data_collator=data_collator,\n","            train_dataset=train_dataset,\n","            eval_dataset=eval_dataset,\n","            #model_init=dummy_init,\n","            compute_metrics=compute_metrics\n","        )\n","    else:\n","        trainer = ContrastiveTrainer(\n","            model=model,\n","            args=training_args,\n","            data_collator=data_collator,\n","            train_dataset=train_dataset,\n","            eval_dataset=eval_dataset\n","        )\n","        trainer.set_lambd(contrastive_train_lambd)\n","\n","    # Train the model\n","    if not dont_train:\n","        logger.info(\"=== Training the model ===\")\n","        trainer.train()\n","        trainer.save_model(\"./lm_train_cache/\")\n","        if log_history:\n","            log_file = f\"{model_name}_epochs_{num_epochs}_eval_loss.p\"\n","            with open(log_file, \"wb\") as f:\n","                pickle.dump(trainer.state.log_history, f)\n","\n","    # Evaluate the model\n","    results = {}\n","    if not dont_eval: #Note: for hyperparameter tuning we do it by loss on\n","        model.eval()\n","        logger.info(\"=== Evaluating the model ===\")\n","        eval_output = trainer.evaluate()\n","        eval_loss = eval_output[\"eval_loss\"]\n","        results[\"eval_loss\"] = eval_loss\n","\n","        acc_test, out_df_test, preds_test, labels_test = evaluate_model(model, tokenizer, test_df.to_dict(orient=\"records\"), use_cuda=use_cuda, return_acc=True, middle_phrase=prompt, use_prefix=prefix_prompt)\n","        acc_dev, out_df_dev, preds_dev, labels_dev = evaluate_model(model, tokenizer, eval_df.to_dict(orient=\"records\"), use_cuda=use_cuda, return_acc=True, middle_phrase=prompt, use_prefix=prefix_prompt)\n","        results[\"accuracy (test)\"] = acc_test\n","        results[\"accuracy (dev)\"] = acc_dev\n","        results[\"preds\"] = preds_test\n","        results[\"labels\"] = labels_test\n","\n","\n","    if out_path is not None:\n","        Path(out_path).mkdir(parents=True, exist_ok=True)\n","        with open(f\"{out_path}/results_{model_name}.txt\", \"w\") as writer:\n","            logger.info(\"=== Outputting results ===\")\n","            for key in sorted(results.keys()):\n","                logger.info(\"  %s = %s\", key, str(results[key]))\n","                writer.write(\"%s = %s\\n\" % (key, str(results[key])))\n","\n","        out_df_test.to_csv(f\"{out_path}/prob_{model_name}_{seed}.csv\", index=False)\n","\n","    return results\n","\n","def training_setup(model, tokenizer, model_name, seed, lr, num_epochs, train_path, eval_path, contrastive_train=False, contrast_lambd=1, is_hyperparam_opt=False, cuda=True, deepspeed=False, batch_size=8) -> Trainer:\n","    # load datasets and initialize trainer\n","    train_dataset = (\n","        get_dataset(train_path, tokenizer=tokenizer)\n","    )\n","    eval_dataset = (\n","        get_dataset(eval_path, tokenizer=tokenizer)\n","    )\n","\n","    data_collator = DataCollatorForLanguageModeling(\n","                tokenizer=tokenizer, mlm=False\n","            )\n","    set_seed(seed)\n","\n","    default_train_args = {\n","        \"output_dir\": f\"./lm_train_outputs/{model_name}_{seed}/\",\n","        \"do_train\": True,\n","        \"do_eval\": False,\n","        \"prediction_loss_only\": True,\n","        \"seed\": seed,\n","        \"num_train_epochs\": num_epochs,\n","        \"learning_rate\": lr,\n","        \"no_cuda\": not cuda,\n","        \"per_device_train_batch_size\": batch_size,\n","        \"per_device_eval_batch_size\": batch_size\n","    }\n","\n","    if contrastive_train:\n","        default_train_args[\"per_device_train_batch_size\"] = 2\n","        training_args = transformers.TrainingArguments(output_dir=f\"./lm_train_outputs/{model_name}_{seed}/\", do_train=True, do_eval=False,\n","        prediction_loss_only=True, num_train_epochs=num_epochs, seed=seed,learning_rate=lr, per_device_train_batch_size=2)\n","    elif is_hyperparam_opt:\n","        default_train_args[\"evaluation_strategy\"] = \"steps\"\n","        default_train_args[\"eval_steps\"] = 500\n","        default_train_args[\"disable_tqdm\"] = True\n","    if deepspeed == True:\n","        default_train_args[\"deepspeed\"] = \"./deepspeed_config.json\"\n","\n","    training_args = transformers.TrainingArguments(**default_train_args)\n","\n","\n","    if is_hyperparam_opt:\n","        tokenizer.pad_token = tokenizer.eos_token\n","        dummy_init = make_dummy(model_name)\n","        trainer = Trainer(\n","            args=training_args,\n","            data_collator=data_collator,\n","            train_dataset=train_dataset,\n","            eval_dataset=eval_dataset,\n","            model_init=dummy_init,\n","            compute_metrics=compute_metrics\n","        )\n","    elif contrastive_train:\n","        trainer = ContrastiveTrainer(\n","            model=model,\n","            args=training_args,\n","            data_collator=data_collator,\n","            train_dataset=train_dataset,\n","            eval_dataset=eval_dataset\n","        )\n","        trainer.set_lambd(contrast_lambd)\n","    else:\n","        trainer = Trainer(\n","            model=model,\n","            args=training_args,\n","            data_collator=data_collator,\n","            train_dataset=train_dataset,\n","            eval_dataset=eval_dataset\n","        )\n","    return trainer\n","\n","# This is adapted from the huggingface LM training example here: https://github.com/huggingface/transformers/blob/master/examples/legacy/run_language_modeling.py\n","def get_dataset(\n","    train_data_file: str,\n","    tokenizer: PreTrainedTokenizer,\n","    line_by_line: bool = True,\n","    evaluate: bool = False,\n","    eval_data_file: str = None,\n","    cache_dir: Optional[str] = None,\n","):\n","    def _dataset(file_path, ref_path=None):\n","        if line_by_line:\n","            if ref_path is not None:\n","                if not args.whole_word_mask or not args.mlm:\n","                    raise ValueError(\"You need to set world whole masking and mlm to True for Chinese Whole Word Mask\")\n","                return LineByLineWithRefDataset(\n","                    tokenizer=tokenizer,\n","                    file_path=file_path,\n","                    block_size=tokenizer.model_max_length,\n","                    ref_path=ref_path,\n","                )\n","\n","            return LineByLineTextDataset(tokenizer=tokenizer, file_path=file_path, block_size=tokenizer.model_max_length)\n","\n","    if evaluate:\n","        return _dataset(eval_data_file)\n","    else:\n","        return _dataset(train_data_file)\n","\n","def make_dummy(model_id):\n","    def dummy_init():\n","        if model_id == \"gpt2\":\n","            return GPT2LMHeadModel.from_pretrained(\"gpt2\", return_dict=True)\n","        elif \"gpt-neo\" in model_id:\n","            return GPTNeoForCausalLM.from_pretrained(model_id, return_dict=True)\n","    return dummy_init\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = predictions.argmax(axis=-1)\n","    acc = len(np.where(predictions == labels)[0])/len(labels)\n","    return {\"acc\": acc}\n","\n","class ContrastiveTrainer(Trainer):\n","    def set_lambd(self, lambd):\n","        self.lambd = lambd\n","\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        # Assumes batch size of 2!\n","        if inputs[\"labels\"].shape[0] % 2 != 0:\n","            raise ValueError(\"Batch size must be a multiple of 2\")\n","\n","        correct_inputs = {\"input_ids\": torch.stack([row for i, row in enumerate(inputs[\"input_ids\"]) if i % 2 == 0]),\n","        \"attention_mask\": torch.stack([row for i, row in enumerate(inputs[\"attention_mask\"]) if i % 2 == 0]),\n","        \"labels\":  torch.stack([row for i, row in enumerate(inputs[\"labels\"]) if i % 2 == 0])}\n","        wrong_inputs = {\"input_ids\": torch.stack([row for i, row in enumerate(inputs[\"input_ids\"]) if i % 2 == 1]),\n","        \"attention_mask\": torch.stack([row for i, row in enumerate(inputs[\"attention_mask\"]) if i % 2 == 1]),\n","        \"labels\":  torch.stack([row for i, row in enumerate(inputs[\"labels\"]) if i % 2 == 1])}\n","\n","        outputs = model(**inputs)\n","\n","        correct_outputs = model(**correct_inputs)\n","        correct_loss = correct_outputs.get('loss')\n","\n","        wrong_outputs = model(**wrong_inputs)\n","        wrong_loss = wrong_outputs.get(\"loss\")\n","\n","        # Good = when the loss for the correct item is much lower than loss for wrong item\n","        # loss should be negative (good) when wrong loss > correct loss\n","        #lambd = self.lambd if self.lambd else 1\n","        lambd = 0.2\n","        relative_score = correct_loss - lambd * (wrong_loss + correct_loss)\n","        loss = -relative_score\n","\n","        return (loss, outputs) if return_outputs else loss\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1222382,"status":"error","timestamp":1697048517873,"user":{"displayName":"gvvvbjj ffbkitb","userId":"08953530729188044176"},"user_tz":-120},"id":"3kyZue0NT2tv","outputId":"a6a12615-6be4-4e95-f618-c8785bbcfb80"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:119: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n","[INFO|language_modeling.py:130] 2023-10-11 18:01:34,947 >> Creating features from dataset file at ./data/lm_train_data/train.txt\n","[INFO|language_modeling.py:130] 2023-10-11 18:01:35,032 >> Creating features from dataset file at ./data/lm_train_data/dev.txt\n","[INFO|training_args.py:1345] 2023-10-11 18:01:35,096 >> Found safetensors installation, but --save_safetensors=False. Safetensors should be a preferred weights saving format due to security and performance reasons. If your model cannot be saved by safetensors please feel free to open an issue at https://github.com/huggingface/safetensors!\n","[INFO|training_args.py:1798] 2023-10-11 18:01:35,097 >> PyTorch: setting up devices\n","[INFO|training_args.py:1519] 2023-10-11 18:01:35,101 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","[INFO|trainer.py:1760] 2023-10-11 18:01:35,398 >> ***** Running training *****\n","[INFO|trainer.py:1761] 2023-10-11 18:01:35,399 >>   Num examples = 1,458\n","[INFO|trainer.py:1762] 2023-10-11 18:01:35,402 >>   Num Epochs = 3\n","[INFO|trainer.py:1763] 2023-10-11 18:01:35,405 >>   Instantaneous batch size per device = 2\n","[INFO|trainer.py:1766] 2023-10-11 18:01:35,408 >>   Total train batch size (w. parallel, distributed & accumulation) = 2\n","[INFO|trainer.py:1767] 2023-10-11 18:01:35,410 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1768] 2023-10-11 18:01:35,414 >>   Total optimization steps = 2,187\n","[INFO|trainer.py:1769] 2023-10-11 18:01:35,416 >>   Number of trainable parameters = 247,577,856\n","[WARNING|logging.py:290] 2023-10-11 18:01:35,428 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2187' max='2187' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2187/2187 20:02, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>No log</td>\n","      <td>-15.406539</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>No log</td>\n","      <td>-78.104118</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>No log</td>\n","      <td>-94.428482</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>No log</td>\n","      <td>-102.373970</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>-61.238500</td>\n","      <td>-110.643326</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>-61.238500</td>\n","      <td>-115.399178</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>-61.238500</td>\n","      <td>-119.467453</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>-61.238500</td>\n","      <td>-122.845894</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>-61.238500</td>\n","      <td>-125.702354</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>-110.325500</td>\n","      <td>-128.001404</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>-110.325500</td>\n","      <td>-130.221344</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>-110.325500</td>\n","      <td>-132.107346</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>-110.325500</td>\n","      <td>-133.627319</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>-110.325500</td>\n","      <td>-135.260666</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>-123.501500</td>\n","      <td>-136.421768</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>-123.501500</td>\n","      <td>-137.656738</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>-123.501500</td>\n","      <td>-138.525864</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>-123.501500</td>\n","      <td>-139.229828</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>-123.501500</td>\n","      <td>-139.823868</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>-129.846500</td>\n","      <td>-140.189148</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>-129.846500</td>\n","      <td>-140.422668</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["[INFO|trainer.py:3213] 2023-10-11 18:02:17,636 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:02:17,641 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:02:17,642 >>   Batch size = 8\n","[INFO|trainer.py:3213] 2023-10-11 18:03:20,055 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:03:20,058 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:03:20,061 >>   Batch size = 8\n","[INFO|trainer.py:3213] 2023-10-11 18:04:16,585 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:04:16,588 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:04:16,590 >>   Batch size = 8\n","[INFO|trainer.py:3213] 2023-10-11 18:05:09,715 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:05:09,719 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:05:09,721 >>   Batch size = 8\n","[INFO|trainer.py:3213] 2023-10-11 18:06:00,228 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:06:00,230 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:06:00,231 >>   Batch size = 8\n","[INFO|trainer.py:2939] 2023-10-11 18:06:15,599 >> Saving model checkpoint to ./lm_train_outputs/flan-t5-base_42/checkpoint-500\n","[INFO|configuration_utils.py:460] 2023-10-11 18:06:15,605 >> Configuration saved in ./lm_train_outputs/flan-t5-base_42/checkpoint-500/config.json\n","[INFO|configuration_utils.py:544] 2023-10-11 18:06:15,607 >> Configuration saved in ./lm_train_outputs/flan-t5-base_42/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:2118] 2023-10-11 18:06:23,707 >> Model weights saved in ./lm_train_outputs/flan-t5-base_42/checkpoint-500/pytorch_model.bin\n","[INFO|trainer.py:3213] 2023-10-11 18:07:11,013 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:07:11,014 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:07:11,016 >>   Batch size = 8\n","[INFO|trainer.py:3213] 2023-10-11 18:08:02,143 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:08:02,149 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:08:02,150 >>   Batch size = 8\n","[INFO|trainer.py:3213] 2023-10-11 18:08:54,534 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:08:54,539 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:08:54,541 >>   Batch size = 8\n","[INFO|trainer.py:3213] 2023-10-11 18:09:44,462 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:09:44,467 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:09:44,468 >>   Batch size = 8\n","[INFO|trainer.py:3213] 2023-10-11 18:10:35,526 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:10:35,527 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:10:35,530 >>   Batch size = 8\n","[INFO|trainer.py:2939] 2023-10-11 18:10:50,845 >> Saving model checkpoint to ./lm_train_outputs/flan-t5-base_42/checkpoint-1000\n","[INFO|configuration_utils.py:460] 2023-10-11 18:10:50,848 >> Configuration saved in ./lm_train_outputs/flan-t5-base_42/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:544] 2023-10-11 18:10:50,853 >> Configuration saved in ./lm_train_outputs/flan-t5-base_42/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:2118] 2023-10-11 18:10:54,249 >> Model weights saved in ./lm_train_outputs/flan-t5-base_42/checkpoint-1000/pytorch_model.bin\n","[INFO|trainer.py:3213] 2023-10-11 18:11:41,863 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:11:41,865 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:11:41,866 >>   Batch size = 8\n","[INFO|trainer.py:3213] 2023-10-11 18:12:32,738 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:12:32,741 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:12:32,744 >>   Batch size = 8\n","[INFO|trainer.py:3213] 2023-10-11 18:13:25,035 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:13:25,040 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:13:25,042 >>   Batch size = 8\n","[INFO|trainer.py:3213] 2023-10-11 18:14:14,841 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:14:14,843 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:14:14,845 >>   Batch size = 8\n","[INFO|trainer.py:3213] 2023-10-11 18:15:05,720 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:15:05,721 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:15:05,725 >>   Batch size = 8\n","[INFO|trainer.py:2939] 2023-10-11 18:15:21,138 >> Saving model checkpoint to ./lm_train_outputs/flan-t5-base_42/checkpoint-1500\n","[INFO|configuration_utils.py:460] 2023-10-11 18:15:21,141 >> Configuration saved in ./lm_train_outputs/flan-t5-base_42/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:544] 2023-10-11 18:15:21,143 >> Configuration saved in ./lm_train_outputs/flan-t5-base_42/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:2118] 2023-10-11 18:15:24,551 >> Model weights saved in ./lm_train_outputs/flan-t5-base_42/checkpoint-1500/pytorch_model.bin\n","[INFO|trainer.py:3213] 2023-10-11 18:16:12,091 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:16:12,092 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:16:12,093 >>   Batch size = 8\n","[INFO|trainer.py:3213] 2023-10-11 18:17:03,074 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:17:03,080 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:17:03,080 >>   Batch size = 8\n","[INFO|trainer.py:3213] 2023-10-11 18:17:54,177 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:17:54,179 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:17:54,181 >>   Batch size = 8\n","[INFO|trainer.py:3213] 2023-10-11 18:18:44,014 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:18:44,017 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:18:44,020 >>   Batch size = 8\n","[INFO|trainer.py:3213] 2023-10-11 18:19:35,293 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:19:35,296 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:19:35,298 >>   Batch size = 8\n","[INFO|trainer.py:2939] 2023-10-11 18:19:50,481 >> Saving model checkpoint to ./lm_train_outputs/flan-t5-base_42/checkpoint-2000\n","[INFO|configuration_utils.py:460] 2023-10-11 18:19:50,485 >> Configuration saved in ./lm_train_outputs/flan-t5-base_42/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:544] 2023-10-11 18:19:50,488 >> Configuration saved in ./lm_train_outputs/flan-t5-base_42/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:2118] 2023-10-11 18:19:53,936 >> Model weights saved in ./lm_train_outputs/flan-t5-base_42/checkpoint-2000/pytorch_model.bin\n","[INFO|trainer.py:3213] 2023-10-11 18:20:50,023 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:20:50,025 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:20:50,029 >>   Batch size = 8\n","[INFO|trainer.py:2017] 2023-10-11 18:21:38,267 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:2939] 2023-10-11 18:21:38,398 >> Saving model checkpoint to ./lm_train_cache/\n","[INFO|configuration_utils.py:460] 2023-10-11 18:21:38,402 >> Configuration saved in ./lm_train_cache/config.json\n","[INFO|configuration_utils.py:544] 2023-10-11 18:21:38,403 >> Configuration saved in ./lm_train_cache/generation_config.json\n","[INFO|modeling_utils.py:2118] 2023-10-11 18:21:41,857 >> Model weights saved in ./lm_train_cache/pytorch_model.bin\n","[INFO|trainer.py:3213] 2023-10-11 18:21:41,866 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3215] 2023-10-11 18:21:41,868 >>   Num examples = 1094\n","[INFO|trainer.py:3218] 2023-10-11 18:21:41,870 >>   Batch size = 8\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='137' max='137' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [137/137 00:15]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"ZeroDivisionError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-820337393efd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"google/flan-t5-base\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"./data/lm_train_data/train.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./data/lm_train_data/dev.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrastive_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrastive_train_lambd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdont_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdont_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepspeed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-19-e1c4a2ca38fe>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(model, tokenizer, model_id, prompt, train_path, eval_path, contrastive_train, contrastive_train_lambd, num_epochs, seed, lr, use_cuda, dont_train, dont_eval, out_path, cache_dir, prefix_prompt, batch_size, log_history, deepspeed, early_stopping)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_loss\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0macc_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_df_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"records\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmiddle_phrase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0macc_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_df_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"records\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmiddle_phrase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy (test)\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/Fig-QA/src/models/gpt_score.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, tokenizer, test_set, middle_phrase, use_prefix, verbose, score_type, use_cuda, return_acc)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mP_x_1_y_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mP_x_1_y_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mP_x_1_correct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscore2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"]}],"source":["main(model, tokenizer, \"google/flan-t5-base\", \"\",\"./data/lm_train_data/train.txt\", \"./data/lm_train_data/dev.txt\", contrastive_train=True, contrastive_train_lambd=1, num_epochs=3, seed=42, lr=5e-5, use_cuda=True, dont_train=False, dont_eval=False, out_path=None, prefix_prompt=0, log_history=True, deepspeed=False, early_stopping=False)\n"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":74737,"status":"ok","timestamp":1697050820799,"user":{"displayName":"gvvvbjj ffbkitb","userId":"08953530729188044176"},"user_tz":-120},"id":"P5QdKCk_57mO","outputId":"9aa8370e-b13c-448a-e5d9-88348315eb03"},"outputs":[{"name":"stdout","output_type":"stream","text":["Q: The girl had the flightiness of a sparrow: 1. The girl was very fickle. 2. The girl was very stable.\n","model says 'The girl had the flightiness of a sparrow. The girl was very stable..' is more likely\n","\n","\n","Q: The girl had the flightiness of a rock: 1. The girl was very fickle. 2. The girl was very stable.\n","model says 'The girl had the flightiness of a rock. The girl was very stable..' is more likely\n","\n","\n","Q: It was as peaceful as a church.: 1. It was very peaceful. 2. It was full of conflict and danger, not peace.\n","model says 'It was as peaceful as a church.. It was very peaceful..' is more likely\n","\n","\n","Q: It was as peaceful as a battlefield.: 1. It was very peaceful. 2. It was full of conflict and danger, not peace.\n","model says 'It was as peaceful as a battlefield.. It was very peaceful..' is more likely\n","\n","\n","Q: The leaves were as green as grass: 1. The leaves were very green 2. The leaves were brown and not green at all.\n","model says 'The leaves were as green as grass. The leaves were very green.' is more likely\n","\n","\n","Q: The leaves were as green as dirt: 1. The leaves were very green 2. The leaves were brown and not green at all.\n","model says 'The leaves were as green as dirt. The leaves were very green.' is more likely\n","\n","\n","Q: Shopping for groceries is finding shells on a sunny beach: 1. Shopping for groceries is a fun, rewarding chore 2. Shopping for groceries is a crazy, nearly impossible chore\n","model says 'Shopping for groceries is finding shells on a sunny beach. Shopping for groceries is a fun, rewarding chore.' is more likely\n","\n","\n","Q: Shopping for groceries is a scavenger hunt with a list created by a lunatic: 1. Shopping for groceries is a fun, rewarding chore 2. Shopping for groceries is a crazy, nearly impossible chore\n","model says 'Shopping for groceries is a scavenger hunt with a list created by a lunatic. Shopping for groceries is a fun, rewarding chore.' is more likely\n","\n","\n","Q: War is an amputation on the wrong limb: 1. War is the wrong solution to a problem 2. War is a necessary solution\n","model says 'War is an amputation on the wrong limb. War is a necessary solution.' is more likely\n","\n","\n","Q: War is an amputation to save your life: 1. War is the wrong solution to a problem 2. War is a necessary solution\n","model says 'War is an amputation to save your life. War is a necessary solution.' is more likely\n","\n","\n","Q: It's as green as grass in the spring: 1. It's fairy green 2. It's not too green\n","model says 'It's as green as grass in the spring. It's not too green.' is more likely\n","\n","\n","Q: It's as green as grass during a hot summer: 1. It's fairy green 2. It's not too green\n","model says 'It's as green as grass during a hot summer. It's not too green.' is more likely\n","\n","\n","Q: This is as peaceful as a sleeping puppy: 1. It's very peaceful 2. It's not very peaceful\n","model says 'This is as peaceful as a sleeping puppy. It's very peaceful.' is more likely\n","\n","\n","Q: This is as peaceful as European in the '40s: 1. It's very peaceful 2. It's not very peaceful\n","model says 'This is as peaceful as European in the '40s. It's very peaceful.' is more likely\n","\n","\n","Q: The music was loud like a siren.: 1. The music was very loud. 2. The music was very quiet.\n","model says 'The music was loud like a siren.. The music was very quiet..' is more likely\n","\n","\n","Q: The music was loud like a whisper.: 1. The music was very loud. 2. The music was very quiet.\n","model says 'The music was loud like a whisper.. The music was very quiet..' is more likely\n","\n","\n","Q: Jobs are as available as a marriage man.: 1. Jobs are not available. 2. Jobs are very available.\n","model says 'Jobs are as available as a marriage man.. Jobs are not available..' is more likely\n","\n","\n","Q: Jobs are as available as a bachelor.: 1. Jobs are not available. 2. Jobs are very available.\n","model says 'Jobs are as available as a bachelor.. Jobs are not available..' is more likely\n","\n","\n","Q: Peace is a human flying: 1. Peace is impossible 2. Peace is possible\n","model says 'Peace is a human flying. Peace is possible.' is more likely\n","\n","\n","Q: Peace is a human walking: 1. Peace is impossible 2. Peace is possible\n","model says 'Peace is a human walking. Peace is possible.' is more likely\n","\n","\n","Q: Plants are a lullaby: 1. Plants are calming 2. Plants are disturbing\n","model says 'Plants are a lullaby. Plants are calming.' is more likely\n","\n","\n","Q: Plants are a loud drum: 1. Plants are calming 2. Plants are disturbing\n","model says 'Plants are a loud drum. Plants are calming.' is more likely\n","\n","\n","Q: The car was as ugly as a one eyed rat: 1. it was hideous 2. it was beautiful\n","model says 'The car was as ugly as a one eyed rat. it was beautiful.' is more likely\n","\n","\n","Q: The car was as ugly as a swan: 1. it was hideous 2. it was beautiful\n","model says 'The car was as ugly as a swan. it was beautiful.' is more likely\n","\n","\n","Q: The man was as handsome as a prince: 1. he was good looking 2. he was ugly\n","model says 'The man was as handsome as a prince. he was ugly.' is more likely\n","\n","\n","Q: The man was as handsome as a hobo: 1. he was good looking 2. he was ugly\n","model says 'The man was as handsome as a hobo. he was ugly.' is more likely\n","\n","\n","Q: The conversation was sharp as a tack: 1. The conversation was sharp and witty. 2. The conversation was dull and not sharp.\n","model says 'The conversation was sharp as a tack. The conversation was sharp and witty..' is more likely\n","\n","\n","Q: The conversation was sharp as a rock: 1. The conversation was sharp and witty. 2. The conversation was dull and not sharp.\n","model says 'The conversation was sharp as a rock. The conversation was sharp and witty..' is more likely\n","\n","\n","Q: He ate it like a fat boy eats cake: 1. The food was tasty to him 2. The food was unpalatable to him\n","model says 'He ate it like a fat boy eats cake. The food was tasty to him.' is more likely\n","\n","\n","Q: He ate it like a young boy eats broccoli: 1. The food was tasty to him 2. The food was unpalatable to him\n","model says 'He ate it like a young boy eats broccoli. The food was tasty to him.' is more likely\n","\n","\n","Q: He picked it up like a mother holding a baby: 1. He held it with pride and care 2. He held it with disgust and caution\n","model says 'He picked it up like a mother holding a baby. He held it with pride and care.' is more likely\n","\n","\n","Q: He picked it up like a playboy holding a condom: 1. He held it with pride and care 2. He held it with disgust and caution\n","model says 'He picked it up like a playboy holding a condom. He held it with pride and care.' is more likely\n","\n","\n","Q: He rushed through the math test like an ape: 1. He rushed because he is dumb 2. He rushed because he is smart\n","model says 'He rushed through the math test like an ape. He rushed because he is smart.' is more likely\n","\n","\n","Q: He rushed through the math test like a rocket scientist: 1. He rushed because he is dumb 2. He rushed because he is smart\n","model says 'He rushed through the math test like a rocket scientist. He rushed because he is smart.' is more likely\n","\n","\n","Q: The bear was as hungry as a lion: 1. it was starving 2. it didn't need food\n","model says 'The bear was as hungry as a lion. it was starving.' is more likely\n","\n","\n","Q: The bear was as hungry as a piece of paper: 1. it was starving 2. it didn't need food\n","model says 'The bear was as hungry as a piece of paper. it was starving.' is more likely\n","\n","\n","Q: That conversation had the ease of doing your taxes blindfolded.: 1. Having that conversation was difficult 2. Having that conversation was easy.\n","model says 'That conversation had the ease of doing your taxes blindfolded.. Having that conversation was easy..' is more likely\n","\n","\n","Q: That conversation had the ease of a Sunday morning.: 1. Having that conversation was difficult 2. Having that conversation was easy.\n","model says 'That conversation had the ease of a Sunday morning.. Having that conversation was easy..' is more likely\n","\n","\n","Q: Their conversations were artillery bombardments.: 1. Their conversations were heated and antagonistic. 2. Their conversations were friendly.\n","model says 'Their conversations were artillery bombardments.. Their conversations were friendly..' is more likely\n","\n","\n","Q: Their conversations were a hug with words.: 1. Their conversations were heated and antagonistic. 2. Their conversations were friendly.\n","model says 'Their conversations were a hug with words.. Their conversations were friendly..' is more likely\n","\n","\n","Q: The story was as disturbing as a nightmare: 1. The story was very disturbing. 2. The story failed to be disturbing, and in fact seemed cute.\n","model says 'The story was as disturbing as a nightmare. The story was very disturbing..' is more likely\n","\n","\n","Q: The story was as disturbing as a newborn puppy: 1. The story was very disturbing. 2. The story failed to be disturbing, and in fact seemed cute.\n","model says 'The story was as disturbing as a newborn puppy. The story was very disturbing..' is more likely\n","\n","\n","Q: Their expectations of the house they could afford turned into melted ice.: 1. Their expectations were not met. 2. Their expectations were exceeded.\n","model says 'Their expectations of the house they could afford turned into melted ice.. Their expectations were not met..' is more likely\n","\n","\n","Q: Their expectations of the house they could afford leapt past the second story.: 1. Their expectations were not met. 2. Their expectations were exceeded.\n","model says 'Their expectations of the house they could afford leapt past the second story.. Their expectations were not met..' is more likely\n","\n","\n","Q: Those that heard the child sing were carried away on gentle waves.: 1. Those that heard the singing were pleasantly entertained. 2. Those that heard the singing were unpleasantly inundated.\n","model says 'Those that heard the child sing were carried away on gentle waves.. Those that heard the singing were pleasantly entertained..' is more likely\n","\n","\n","Q: Those that heard the child sing were tortured by the intruding notes.: 1. Those that heard the singing were pleasantly entertained. 2. Those that heard the singing were unpleasantly inundated.\n","model says 'Those that heard the child sing were tortured by the intruding notes.. Those that heard the singing were pleasantly entertained..' is more likely\n","\n","\n","Q: She sings like an angel: 1. her voice is magical 2. her voice is awful\n","model says 'She sings like an angel. her voice is awful.' is more likely\n","\n","\n","Q: She sings like a bullfrog: 1. her voice is magical 2. her voice is awful\n","model says 'She sings like a bullfrog. her voice is awful.' is more likely\n","\n","\n","Q: HIs opinions were as firm as concrete: 1. He was very certain of his opinion 2. He was very uncertain of his opinion\n","model says 'HIs opinions were as firm as concrete. He was very certain of his opinion.' is more likely\n","\n","\n","Q: HIs opinions were as firm as a cotton ball: 1. He was very certain of his opinion 2. He was very uncertain of his opinion\n","model says 'HIs opinions were as firm as a cotton ball. He was very certain of his opinion.' is more likely\n","\n","\n","Q: The pilot landed the plane like he was handling a new born baby.: 1. The landing was smooth and gentle 2. The landing was bumpy and rough\n","model says 'The pilot landed the plane like he was handling a new born baby.. The landing was smooth and gentle.' is more likely\n","\n","\n","Q: The pilot landed the plane like it was on a roller coaster.: 1. The landing was smooth and gentle 2. The landing was bumpy and rough\n","model says 'The pilot landed the plane like it was on a roller coaster.. The landing was smooth and gentle.' is more likely\n","\n","\n","Q: The man's personality is like a Beanie Baby: 1. The man has a soft personality. 2. The man has a hard personality.\n","model says 'The man's personality is like a Beanie Baby. The man has a hard personality..' is more likely\n","\n","\n","Q: The man's personality is like a drill sergeant: 1. The man has a soft personality. 2. The man has a hard personality.\n","model says 'The man's personality is like a drill sergeant. The man has a hard personality..' is more likely\n","\n","\n","Q: The poster was as colorful as a rainbow: 1. The poster has a lot of color. 2. The poster was dull and colorless.\n","model says 'The poster was as colorful as a rainbow. The poster has a lot of color..' is more likely\n","\n","\n","Q: The poster was as colorful as a sidewalk: 1. The poster has a lot of color. 2. The poster was dull and colorless.\n","model says 'The poster was as colorful as a sidewalk. The poster has a lot of color..' is more likely\n","\n","\n","Q: She is as eager as a beaver: 1. she is excited 2. she is bored\n","model says 'She is as eager as a beaver. she is excited.' is more likely\n","\n","\n","Q: She is as eager as a sloth: 1. she is excited 2. she is bored\n","model says 'She is as eager as a sloth. she is excited.' is more likely\n","\n","\n","Q: The motor on the boat is a Babbling drunk: 1. It is barely running 2. It is running strong\n","model says 'The motor on the boat is a Babbling drunk. It is barely running.' is more likely\n","\n","\n","Q: The motor on the boat is a Roaring lion: 1. It is barely running 2. It is running strong\n","model says 'The motor on the boat is a Roaring lion. It is barely running.' is more likely\n","\n","\n","Q: The lawyer's opening argument was a Russian novel.: 1. The lawyer's opening argument was long. 2. The lawyer's opening argument was tawdry.\n","model says 'The lawyer's opening argument was a Russian novel.. The lawyer's opening argument was long..' is more likely\n","\n","\n","Q: The lawyer's opening argument was an airport paperback.: 1. The lawyer's opening argument was long. 2. The lawyer's opening argument was tawdry.\n","model says 'The lawyer's opening argument was an airport paperback.. The lawyer's opening argument was long..' is more likely\n","\n","\n","Q: The house had the cleanliness of a museum: 1. The house was very clean. 2. The house was a mess.\n","model says 'The house had the cleanliness of a museum. The house was a mess..' is more likely\n","\n","\n","Q: The house had the cleanliness of a paintball arena: 1. The house was very clean. 2. The house was a mess.\n","model says 'The house had the cleanliness of a paintball arena. The house was a mess..' is more likely\n","\n","\n","Q: The grapes had the freshness of a secondhand toy.: 1. The grapes weren't fresh. 2. The grapes were very fresh.\n","model says 'The grapes had the freshness of a secondhand toy.. The grapes were very fresh..' is more likely\n","\n","\n","Q: The grapes had the freshness of an early summer morning.: 1. The grapes weren't fresh. 2. The grapes were very fresh.\n","model says 'The grapes had the freshness of an early summer morning.. The grapes were very fresh..' is more likely\n","\n","\n","Q: The toy had the enjoyment of an execution: 1. The toy was not fun 2. The toy was fun\n","model says 'The toy had the enjoyment of an execution. The toy was fun.' is more likely\n","\n","\n","Q: The toy had the enjoyment of roller coaster: 1. The toy was not fun 2. The toy was fun\n","model says 'The toy had the enjoyment of roller coaster. The toy was fun.' is more likely\n","\n","\n","Q: The movie's message was as heartwarming as a cup of mint tea: 1. The movie message was very heartwarming. 2. The movie's message wasn't heartwarming at all.\n","model says 'The movie's message was as heartwarming as a cup of mint tea. The movie's message wasn't heartwarming at all..' is more likely\n","\n","\n","Q: The movie's message was as heartwarming as a Popsicle: 1. The movie message was very heartwarming. 2. The movie's message wasn't heartwarming at all.\n","model says 'The movie's message was as heartwarming as a Popsicle. The movie message was very heartwarming..' is more likely\n","\n","\n","Q: The book was as classic as pancakes for breakfast: 1. The book was very classic. 2. The book wasn't a classic.\n","model says 'The book was as classic as pancakes for breakfast. The book was very classic..' is more likely\n","\n","\n","Q: The book was as classic as a bride wearing purple: 1. The book was very classic. 2. The book wasn't a classic.\n","model says 'The book was as classic as a bride wearing purple. The book was very classic..' is more likely\n","\n","\n","Q: The toy was as new as A quarter from this year.: 1. The toy was recent 2. The toy was dated.\n","model says 'The toy was as new as A quarter from this year.. The toy was dated..' is more likely\n","\n","\n","Q: The toy was as new as A quarter from the year you were born.: 1. The toy was recent 2. The toy was dated.\n","model says 'The toy was as new as A quarter from the year you were born.. The toy was dated..' is more likely\n","\n","\n","Q: The woman was as tall as a tree: 1. The woman was tall 2. The woman was short\n","model says 'The woman was as tall as a tree. The woman was tall.' is more likely\n","\n","\n","Q: The woman was as tall as a footstool: 1. The woman was tall 2. The woman was short\n","model says 'The woman was as tall as a footstool. The woman was tall.' is more likely\n","\n","\n","Q: Tom had the joy of a robot.: 1. Tom is not very joyful. 2. Tom is very joyful.\n","model says 'Tom had the joy of a robot.. Tom is very joyful..' is more likely\n","\n","\n","Q: Tom had the joy of a dog.: 1. Tom is not very joyful. 2. Tom is very joyful.\n","model says 'Tom had the joy of a dog.. Tom is very joyful..' is more likely\n","\n","\n","Q: The movie has a depth of A canyon.: 1. The movie is deeply philosophical. 2. The movie has little substance.\n","model says 'The movie has a depth of A canyon.. The movie has little substance..' is more likely\n","\n","\n","Q: The movie has a depth of A pothole.: 1. The movie is deeply philosophical. 2. The movie has little substance.\n","model says 'The movie has a depth of A pothole.. The movie has little substance..' is more likely\n","\n","\n","Q: The movie has a depth of A valley.: 1. The movie is expansive in it's meaning. 2. The movie lacks depth.\n","model says 'The movie has a depth of A valley.. The movie lacks depth..' is more likely\n","\n","\n","Q: The movie has a depth of A flatland.: 1. The movie is expansive in it's meaning. 2. The movie lacks depth.\n","model says 'The movie has a depth of A flatland.. The movie lacks depth..' is more likely\n","\n","\n","Q: She was as delicate as An elephant: 1. She was a lumbering clod 2. She was fragile\n","model says 'She was as delicate as An elephant. She was fragile.' is more likely\n","\n","\n","Q: She was as delicate as A snowflake: 1. She was a lumbering clod 2. She was fragile\n","model says 'She was as delicate as A snowflake. She was fragile.' is more likely\n","\n","\n","Q: Her dinner tasted like An old shoe: 1. The food was disgusting 2. The food was gloriously delicious\n","model says 'Her dinner tasted like An old shoe. The food was disgusting.' is more likely\n","\n","\n","Q: Her dinner tasted like Manna from heaven: 1. The food was disgusting 2. The food was gloriously delicious\n","model says 'Her dinner tasted like Manna from heaven. The food was disgusting.' is more likely\n","\n","\n","Q: The boy's lemonade stand was as successful as a Fortune 500 company: 1. The boy's lemonade stand was a wild success. 2. The boy's lemonade stand did terribly.\n","model says 'The boy's lemonade stand was as successful as a Fortune 500 company. The boy's lemonade stand did terribly..' is more likely\n","\n","\n","Q: The boy's lemonade stand was as successful as the 1962 New York Mets: 1. The boy's lemonade stand was a wild success. 2. The boy's lemonade stand did terribly.\n","model says 'The boy's lemonade stand was as successful as the 1962 New York Mets. The boy's lemonade stand did terribly..' is more likely\n","\n","\n","Q: He is as famous as a movie star: 1. people know him 2. no one knows him\n","model says 'He is as famous as a movie star. people know him.' is more likely\n","\n","\n","Q: He is as famous as a roach in a dumpster: 1. people know him 2. no one knows him\n","model says 'He is as famous as a roach in a dumpster. people know him.' is more likely\n","\n","\n","Q: She is as fancy as a prom queen: 1. she is elegant 2. she is dirty\n","model says 'She is as fancy as a prom queen. she is dirty.' is more likely\n","\n","\n","Q: She is as fancy as dish water: 1. she is elegant 2. she is dirty\n","model says 'She is as fancy as dish water. she is dirty.' is more likely\n","\n","\n","Q: Her face glowed like the sun: 1. Her face was luminous 2. her face was dull\n","model says 'Her face glowed like the sun. Her face was luminous.' is more likely\n","\n","\n","Q: Her face glowed like the reflection of a dusty mirror: 1. Her face was luminous 2. her face was dull\n","model says 'Her face glowed like the reflection of a dusty mirror. Her face was luminous.' is more likely\n","\n","\n","Q: He was the size of an ape.: 1. He was huge. 2. He was small.\n","model says 'He was the size of an ape.. He was small..' is more likely\n","\n","\n","Q: He was the size of an ant.: 1. He was huge. 2. He was small.\n","model says 'He was the size of an ant.. He was small..' is more likely\n","\n","\n","Q: The song had the creativity of an ameba.: 1. The song was too simplistic. 2. The song was very complex and beautiful.\n","model says 'The song had the creativity of an ameba.. The song was too simplistic..' is more likely\n","\n","\n","Q: The song had the creativity of all the paintings in the Louvre.: 1. The song was too simplistic. 2. The song was very complex and beautiful.\n","model says 'The song had the creativity of all the paintings in the Louvre.. The song was too simplistic..' is more likely\n","\n","\n","Q: That movie was as long as a 25-year-old tapeworm: 1. It's extremely long 2. It's as short as can be\n","model says 'That movie was as long as a 25-year-old tapeworm. It's extremely long.' is more likely\n","\n","\n","Q: That movie was as long as Howie Mandel's hair: 1. It's extremely long 2. It's as short as can be\n","model says 'That movie was as long as Howie Mandel's hair. It's extremely long.' is more likely\n","\n","\n","Q: The playground is as safe as Dracula's fangs.: 1. The playground is dangerous. 2. The playground is secure.\n","model says 'The playground is as safe as Dracula's fangs.. The playground is secure..' is more likely\n","\n","\n","Q: The playground is as safe as an insurance policy.: 1. The playground is dangerous. 2. The playground is secure.\n","model says 'The playground is as safe as an insurance policy.. The playground is secure..' is more likely\n","\n","\n","Q: The manager added kindling to our spark.: 1. The manager motivated his employees. 2. The manager demotivated his employees.\n","model says 'The manager added kindling to our spark.. The manager motivated his employees..' is more likely\n","\n","\n","Q: The manager added water to our spark.: 1. The manager motivated his employees. 2. The manager demotivated his employees.\n","model says 'The manager added water to our spark.. The manager motivated his employees..' is more likely\n","\n","\n","Q: The student was as gifted as an entrepreneur: 1. he has talant 2. he was talentless\n","model says 'The student was as gifted as an entrepreneur. he has talant.' is more likely\n","\n","\n","Q: The student was as gifted as a blind otter: 1. he has talant 2. he was talentless\n","model says 'The student was as gifted as a blind otter. he has talant.' is more likely\n","\n","\n","Q: The woman was as glamourous as a movie star: 1. she was fancy 2. she was unkempt\n","model says 'The woman was as glamourous as a movie star. she was fancy.' is more likely\n","\n","\n","Q: The woman was as glamourous as an old shoe: 1. she was fancy 2. she was unkempt\n","model says 'The woman was as glamourous as an old shoe. she was fancy.' is more likely\n","\n","\n","Q: His height was comparable to a redwood tree: 1. He was tall 2. He was short\n","model says 'His height was comparable to a redwood tree. He was tall.' is more likely\n","\n","\n","Q: His height was comparable to a mouse: 1. He was tall 2. He was short\n","model says 'His height was comparable to a mouse. He was tall.' is more likely\n","\n","\n","Q: She came up to eye level with a giraffe: 1. She was tall 2. She was short\n","model says 'She came up to eye level with a giraffe. She was tall.' is more likely\n","\n","\n","Q: She came up to eye level with a toddler: 1. She was tall 2. She was short\n","model says 'She came up to eye level with a toddler. She was tall.' is more likely\n","\n","\n","Q: The restaurant's plat du jour was the ambrosia of the gods: 1. The food was delicious 2. The food was disgusting\n","model says 'The restaurant's plat du jour was the ambrosia of the gods. The food was delicious.' is more likely\n","\n","\n","Q: The restaurant's plat du jour was hot garbage: 1. The food was delicious 2. The food was disgusting\n","model says 'The restaurant's plat du jour was hot garbage. The food was delicious.' is more likely\n","\n","\n","Q: The car was as useful as a pool with no water: 1. the car was useless 2. the car was helpful\n","model says 'The car was as useful as a pool with no water. the car was helpful.' is more likely\n","\n","\n","Q: The car was as useful as silverware during dinner: 1. the car was useless 2. the car was helpful\n","model says 'The car was as useful as silverware during dinner. the car was helpful.' is more likely\n","\n","\n","Q: My dog eats like a mayfly: 1. My dog is never eating 2. My dog never ceases eating\n","model says 'My dog eats like a mayfly. My dog is never eating.' is more likely\n","\n","\n","Q: My dog eats like a tarrare: 1. My dog is never eating 2. My dog never ceases eating\n","model says 'My dog eats like a tarrare. My dog is never eating.' is more likely\n","\n","\n","Q: That film as disastrous as the launch of the Xbox One in 2013: 1. It isn't very good 2. It's quite successful\n","model says 'That film as disastrous as the launch of the Xbox One in 2013. It's quite successful.' is more likely\n","\n","\n","Q: That film as disastrous as the Abraham Lincoln presidency: 1. It isn't very good 2. It's quite successful\n","model says 'That film as disastrous as the Abraham Lincoln presidency. It's quite successful.' is more likely\n","\n","\n","Q: The concept was as confusing as a scrambled egg: 1. The concept was hard to understand. 2. The concept was easy to understand.\n","model says 'The concept was as confusing as a scrambled egg. The concept was easy to understand..' is more likely\n","\n","\n","Q: The concept was as confusing as a kiddie puzzle: 1. The concept was hard to understand. 2. The concept was easy to understand.\n","model says 'The concept was as confusing as a kiddie puzzle. The concept was easy to understand..' is more likely\n","\n","\n","Q: The burrito has the heat of a volcano: 1. The burrito is hot 2. The burrito is cold\n","model says 'The burrito has the heat of a volcano. The burrito is cold.' is more likely\n","\n","\n","Q: The burrito has the heat of an iceberg: 1. The burrito is hot 2. The burrito is cold\n","model says 'The burrito has the heat of an iceberg. The burrito is cold.' is more likely\n","\n","\n","Q: Time moved like a snail.: 1. Time was slow. 2. Time was fast.\n","model says 'Time moved like a snail.. Time was fast..' is more likely\n","\n","\n","Q: Time moved like a cheetah.: 1. Time was slow. 2. Time was fast.\n","model says 'Time moved like a cheetah.. Time was fast..' is more likely\n","\n","\n","Q: The man has the patience of a monk.: 1. The man is very patient. 2. The man is very impatient.\n","model says 'The man has the patience of a monk.. The man is very patient..' is more likely\n","\n","\n","Q: The man has the patience of a cat in a bath.: 1. The man is very patient. 2. The man is very impatient.\n","model says 'The man has the patience of a cat in a bath.. The man is very patient..' is more likely\n","\n","\n","Q: The art is as colorful as a rainbow: 1. the art is vibrant 2. the art is dull\n","model says 'The art is as colorful as a rainbow. the art is vibrant.' is more likely\n","\n","\n","Q: The art is as colorful as a cloudy sky: 1. the art is vibrant 2. the art is dull\n","model says 'The art is as colorful as a cloudy sky. the art is vibrant.' is more likely\n","\n","\n","Q: The man's head was as handsome as a work of art: 1. The man's head was attractive 2. The man's head was ugly\n","model says 'The man's head was as handsome as a work of art. The man's head was ugly.' is more likely\n","\n","\n","Q: The man's head was as handsome as a trash can: 1. The man's head was attractive 2. The man's head was ugly\n","model says 'The man's head was as handsome as a trash can. The man's head was ugly.' is more likely\n","\n","\n","Q: The building is as old as the universe itself: 1. It's very old 2. It's brand new\n","model says 'The building is as old as the universe itself. It's brand new.' is more likely\n","\n","\n","Q: The building is as old as the baby that will be born tomorrow: 1. It's very old 2. It's brand new\n","model says 'The building is as old as the baby that will be born tomorrow. It's brand new.' is more likely\n","\n","\n","Q: That fan has the blowing power of the Greek god Aeolus: 1. It can blow a lot 2. It can hardly blow at all\n","model says 'That fan has the blowing power of the Greek god Aeolus. It can hardly blow at all.' is more likely\n","\n","\n","Q: That fan has the blowing power of an unplugged hairdryer: 1. It can blow a lot 2. It can hardly blow at all\n","model says 'That fan has the blowing power of an unplugged hairdryer. It can hardly blow at all.' is more likely\n","\n","\n","Q: The sandwich meat was as moist as a towelette: 1. The sandwich meat was moist. 2. The sandwich meat was dry.\n","model says 'The sandwich meat was as moist as a towelette. The sandwich meat was dry..' is more likely\n","\n","\n","Q: The sandwich meat was as moist as sandpaper: 1. The sandwich meat was moist. 2. The sandwich meat was dry.\n","model says 'The sandwich meat was as moist as sandpaper. The sandwich meat was dry..' is more likely\n","\n","\n","Q: She was as big as a lady bug.: 1. She was small. 2. She was big.\n","model says 'She was as big as a lady bug.. She was small..' is more likely\n","\n","\n","Q: She was as big as a elephant.: 1. She was small. 2. She was big.\n","model says 'She was as big as a elephant.. She was small..' is more likely\n","\n","\n","Q: The future had the brightness of a mud puddle: 1. The future is dull 2. The future is bright\n","model says 'The future had the brightness of a mud puddle. The future is bright.' is more likely\n","\n","\n","Q: The future had the brightness of diamond: 1. The future is dull 2. The future is bright\n","model says 'The future had the brightness of diamond. The future is bright.' is more likely\n","\n","\n","Q: The girl's happiness exploded like a bottle of champagne: 1. The girl's happiness was effusive. 2. The girl's happiness didn't really explode at all.\n","model says 'The girl's happiness exploded like a bottle of champagne. The girl's happiness was effusive..' is more likely\n","\n","\n","Q: The girl's happiness exploded like a lullaby: 1. The girl's happiness was effusive. 2. The girl's happiness didn't really explode at all.\n","model says 'The girl's happiness exploded like a lullaby. The girl's happiness was effusive..' is more likely\n","\n","\n","Q: The problem was as big as a Tootsie Roll: 1. The problem was small. 2. The problem was large.\n","model says 'The problem was as big as a Tootsie Roll. The problem was small..' is more likely\n","\n","\n","Q: The problem was as big as Antarctica: 1. The problem was small. 2. The problem was large.\n","model says 'The problem was as big as Antarctica. The problem was small..' is more likely\n","\n","\n","Q: The girl's temper was a lit match: 1. The girl was easily provoked. 2. The girl's temper was even.\n","model says 'The girl's temper was a lit match. The girl was easily provoked..' is more likely\n","\n","\n","Q: The girl's temper was a low tide: 1. The girl was easily provoked. 2. The girl's temper was even.\n","model says 'The girl's temper was a low tide. The girl was easily provoked..' is more likely\n","\n","\n","Q: The book I just finished reading is a compass of my life.: 1. The book contains a lot of timeless wisdom and helpful knowledge. 2. The book's content is so trashy and useless that one can't bear reading it again.\n","model says 'The book I just finished reading is a compass of my life.. The book contains a lot of timeless wisdom and helpful knowledge..' is more likely\n","\n","\n","Q: The book I just finished reading is my new bug smasher.: 1. The book contains a lot of timeless wisdom and helpful knowledge. 2. The book's content is so trashy and useless that one can't bear reading it again.\n","model says 'The book I just finished reading is my new bug smasher.. The book contains a lot of timeless wisdom and helpful knowledge..' is more likely\n","\n","\n","Q: The snake has the skin of a desert dweller who has never touched a bottle of lotion: 1. The snake has dry and scaly skin 2. The snake's skin is not dry and scaly\n","model says 'The snake has the skin of a desert dweller who has never touched a bottle of lotion. The snake has dry and scaly skin.' is more likely\n","\n","\n","Q: The snake has the skin of a slimy, aquatic eel: 1. The snake has dry and scaly skin 2. The snake's skin is not dry and scaly\n","model says 'The snake has the skin of a slimy, aquatic eel. The snake has dry and scaly skin.' is more likely\n","\n","\n","Q: The reporter was as tall as a basektball center: 1. the reporter was tall 2. the reporter was short\n","model says 'The reporter was as tall as a basektball center. the reporter was tall.' is more likely\n","\n","\n","Q: The reporter was as tall as a midget: 1. the reporter was tall 2. the reporter was short\n","model says 'The reporter was as tall as a midget. the reporter was tall.' is more likely\n","\n","\n","Q: The disease is spreading like a wild fire: 1. It is spreading quickly 2. It is spreading slowly\n","model says 'The disease is spreading like a wild fire. It is spreading quickly.' is more likely\n","\n","\n","Q: The disease is spreading like a growth of a finger nail: 1. It is spreading quickly 2. It is spreading slowly\n","model says 'The disease is spreading like a growth of a finger nail. It is spreading quickly.' is more likely\n","\n","\n","Q: The teen was a skyscraper: 1. The teen was tall. 2. The teen was short.\n","model says 'The teen was a skyscraper. The teen was tall..' is more likely\n","\n","\n","Q: The teen was an anthill: 1. The teen was tall. 2. The teen was short.\n","model says 'The teen was an anthill. The teen was tall..' is more likely\n","\n","\n","Q: The investigation had the weight of A bunch of feathers: 1. The investigation is not important 2. The investigation has a major impact\n","model says 'The investigation had the weight of A bunch of feathers. The investigation is not important.' is more likely\n","\n","\n","Q: The investigation had the weight of A city-wide ripple effect: 1. The investigation is not important 2. The investigation has a major impact\n","model says 'The investigation had the weight of A city-wide ripple effect. The investigation is not important.' is more likely\n","\n","\n","Q: The teacher is as encouraging as a parent: 1. the teacher helps 2. the teacher doesn't help\n","model says 'The teacher is as encouraging as a parent. the teacher helps.' is more likely\n","\n","\n","Q: The teacher is as encouraging as a dead bird: 1. the teacher helps 2. the teacher doesn't help\n","model says 'The teacher is as encouraging as a dead bird. the teacher helps.' is more likely\n","\n","\n","Q: Her hair had the luster of a horse's chestnut mane: 1. Her hair was shiny 2. Her hair was dull\n","model says 'Her hair had the luster of a horse's chestnut mane. Her hair was dull.' is more likely\n","\n","\n","Q: Her hair had the luster of straw: 1. Her hair was shiny 2. Her hair was dull\n","model says 'Her hair had the luster of straw. Her hair was dull.' is more likely\n","\n","\n","Q: His class had all the brilliance of a light bulb: 1. His class was brilliant 2. His class was not so smart.\n","model says 'His class had all the brilliance of a light bulb. His class was not so smart..' is more likely\n","\n","\n","Q: His class had all the brilliance of a rock: 1. His class was brilliant 2. His class was not so smart.\n","model says 'His class had all the brilliance of a rock. His class was not so smart..' is more likely\n","\n","\n","Q: The house was as cozy as a winter cabin on a cold night.: 1. The house was comfortable to be in. 2. The house was uncomfortable to be in.\n","model says 'The house was as cozy as a winter cabin on a cold night.. The house was comfortable to be in..' is more likely\n","\n","\n","Q: The house was as cozy as a prison cell.: 1. The house was comfortable to be in. 2. The house was uncomfortable to be in.\n","model says 'The house was as cozy as a prison cell.. The house was comfortable to be in..' is more likely\n","\n","\n","Q: The soldier was as tough as nails: 1. The soldier is very tough 2. The soldier is very weak\n","model says 'The soldier was as tough as nails. The soldier is very weak.' is more likely\n","\n","\n","Q: The soldier was as tough as cotton: 1. The soldier is very tough 2. The soldier is very weak\n","model says 'The soldier was as tough as cotton. The soldier is very weak.' is more likely\n","\n","\n","Q: She was as fragile as an elephant: 1. She was sturdy and not fragile 2. She was extremely fragile\n","model says 'She was as fragile as an elephant. She was extremely fragile.' is more likely\n","\n","\n","Q: She was as fragile as a crystal teacup: 1. She was sturdy and not fragile 2. She was extremely fragile\n","model says 'She was as fragile as a crystal teacup. She was extremely fragile.' is more likely\n","\n","\n","Q: Her closest relative may as well be a horse: 1. She is ugly 2. She is dainty\n","model says 'Her closest relative may as well be a horse. She is ugly.' is more likely\n","\n","\n","Q: Her closest relative may as well be a bird: 1. She is ugly 2. She is dainty\n","model says 'Her closest relative may as well be a bird. She is ugly.' is more likely\n","\n","\n","Q: The athlete was as good as mike tyson in the 80s: 1. the athlete was great 2. the athlete was bad\n","model says 'The athlete was as good as mike tyson in the 80s. the athlete was great.' is more likely\n","\n","\n","Q: The athlete was as good as mike tyson when he's 80: 1. the athlete was great 2. the athlete was bad\n","model says 'The athlete was as good as mike tyson when he's 80. the athlete was great.' is more likely\n","\n","\n","Q: The student was as confused as a dog at a spelling bee: 1. he didn't know what was going on 2. he knew everything\n","model says 'The student was as confused as a dog at a spelling bee. he knew everything.' is more likely\n","\n","\n","Q: The student was as confused as a lawyer in court: 1. he didn't know what was going on 2. he knew everything\n","model says 'The student was as confused as a lawyer in court. he knew everything.' is more likely\n","\n","\n","Q: The corner was as busy as a parade: 1. The corner was busy 2. The corner was abandoned and not busy\n","model says 'The corner was as busy as a parade. The corner was busy.' is more likely\n","\n","\n","Q: The corner was as busy as a graveyard: 1. The corner was busy 2. The corner was abandoned and not busy\n","model says 'The corner was as busy as a graveyard. The corner was busy.' is more likely\n","\n","\n","Q: The book was as entertaining as a party: 1. The book was entertaining. 2. The book was not entertaining at all.\n","model says 'The book was as entertaining as a party. The book was entertaining..' is more likely\n","\n","\n","Q: The book was as entertaining as a funeral: 1. The book was entertaining. 2. The book was not entertaining at all.\n","model says 'The book was as entertaining as a funeral. The book was entertaining..' is more likely\n","\n","\n","Q: The artist is as creative as vanilla ice cream: 1. The artist has no new ideas. 2. The artist is very creative.\n","model says 'The artist is as creative as vanilla ice cream. The artist has no new ideas..' is more likely\n","\n","\n","Q: The artist is as creative as caramel balsamic swirl ice cream: 1. The artist has no new ideas. 2. The artist is very creative.\n","model says 'The artist is as creative as caramel balsamic swirl ice cream. The artist has no new ideas..' is more likely\n","\n","\n","Q: This show has as many episode as a centipede has legs: 1. It has many episodes 2. It has very few\n","model says 'This show has as many episode as a centipede has legs. It has many episodes.' is more likely\n","\n","\n","Q: This show has as many episode as there are moons in the night sky: 1. It has many episodes 2. It has very few\n","model says 'This show has as many episode as there are moons in the night sky. It has many episodes.' is more likely\n","\n","\n","Q: Me and my relative have rhe closeness of conjoined twins: 1. They're extremely close 2. They very far apart\n","model says 'Me and my relative have rhe closeness of conjoined twins. They very far apart.' is more likely\n","\n","\n","Q: Me and my relative have rhe closeness of the north and south poles: 1. They're extremely close 2. They very far apart\n","model says 'Me and my relative have rhe closeness of the north and south poles. They very far apart.' is more likely\n","\n","\n","Q: The house is as fragile as steel: 1. The house is strong 2. The house is weak\n","model says 'The house is as fragile as steel. The house is strong.' is more likely\n","\n","\n","Q: The house is as fragile as silk: 1. The house is strong 2. The house is weak\n","model says 'The house is as fragile as silk. The house is strong.' is more likely\n","\n","\n","Q: The actor got as much attention as a lion exhibit at a zoo: 1. The actor got tons of attention. 2. The actor got no attention at all.\n","model says 'The actor got as much attention as a lion exhibit at a zoo. The actor got no attention at all..' is more likely\n","\n","\n","Q: The actor got as much attention as a grain of sand at a beach: 1. The actor got tons of attention. 2. The actor got no attention at all.\n","model says 'The actor got as much attention as a grain of sand at a beach. The actor got no attention at all..' is more likely\n","\n","\n","Q: That shirt looks like a Garbage bag: 1. It is ugly 2. It is pretty\n","model says 'That shirt looks like a Garbage bag. It is pretty.' is more likely\n","\n","\n","Q: That shirt looks like a Rose bush: 1. It is ugly 2. It is pretty\n","model says 'That shirt looks like a Rose bush. It is pretty.' is more likely\n","\n","\n","Q: The book has the respect of A doctor: 1. It is well respected 2. It is not highly respected\n","model says 'The book has the respect of A doctor. It is well respected.' is more likely\n","\n","\n","Q: The book has the respect of A conspiracy theorist: 1. It is well respected 2. It is not highly respected\n","model says 'The book has the respect of A conspiracy theorist. It is well respected.' is more likely\n","\n","\n","Q: My new car has the reliability of a penny stock: 1. My new car is unpredictable 2. My new car is dependable\n","model says 'My new car has the reliability of a penny stock. My new car is dependable.' is more likely\n","\n","\n","Q: My new car has the reliability of a finely-tuned piano: 1. My new car is unpredictable 2. My new car is dependable\n","model says 'My new car has the reliability of a finely-tuned piano. My new car is dependable.' is more likely\n","\n","\n","Q: The foundation was flat as a board: 1. The foundation was flat. 2. The foundation was round and curved.\n","model says 'The foundation was flat as a board. The foundation was flat..' is more likely\n","\n","\n","Q: The foundation was flat as a globe: 1. The foundation was flat. 2. The foundation was round and curved.\n","model says 'The foundation was flat as a globe. The foundation was flat..' is more likely\n","\n","\n","Q: The car is as fast as a turtle: 1. the car is slow 2. the car is speedy\n","model says 'The car is as fast as a turtle. the car is slow.' is more likely\n","\n","\n","Q: The car is as fast as a bolt of lightning: 1. the car is slow 2. the car is speedy\n","model says 'The car is as fast as a bolt of lightning. the car is slow.' is more likely\n","\n","\n","Q: He's running faster than a cheetah on jet: 1. He's running fast 2. He's not moving at all\n","model says 'He's running faster than a cheetah on jet. He's running fast.' is more likely\n","\n","\n","Q: He's running faster than a dead snail: 1. He's running fast 2. He's not moving at all\n","model says 'He's running faster than a dead snail. He's running fast.' is more likely\n","\n","\n","Q: The man's temper was a habanero pepper: 1. The man had a big temper. 2. The man had a mild temper.\n","model says 'The man's temper was a habanero pepper. The man had a big temper..' is more likely\n","\n","\n","Q: The man's temper was a cup of oat milk.: 1. The man had a big temper. 2. The man had a mild temper.\n","model says 'The man's temper was a cup of oat milk.. The man had a big temper..' is more likely\n","\n","\n","Q: The government is as stable as a broken bridge: 1. The government is falling apart 2. The government is very strong and stable.\n","model says 'The government is as stable as a broken bridge. The government is falling apart.' is more likely\n","\n","\n","Q: The government is as strong as a brick house: 1. The government is falling apart 2. The government is very strong and stable.\n","model says 'The government is as strong as a brick house. The government is falling apart.' is more likely\n","\n","\n","Q: The odds of winning the lottery are as good as finding a needle in a haystack: 1. The odds of sinning the lottery  are extremely low 2. The odds of winning the lottery are fantastic\n","model says 'The odds of winning the lottery are as good as finding a needle in a haystack. The odds of winning the lottery are fantastic.' is more likely\n","\n","\n","Q: The odds of winning the lottery are as good as lighting a match and expecting fire.: 1. The odds of sinning the lottery  are extremely low 2. The odds of winning the lottery are fantastic\n","model says 'The odds of winning the lottery are as good as lighting a match and expecting fire.. The odds of winning the lottery are fantastic.' is more likely\n","\n","\n","Q: she is as exuberant as a dog on a car ride: 1. she is excited 2. she is tired\n","model says 'she is as exuberant as a dog on a car ride. she is excited.' is more likely\n","\n","\n","Q: she is as exuberant as a sloth in bed: 1. she is excited 2. she is tired\n","model says 'she is as exuberant as a sloth in bed. she is excited.' is more likely\n","\n","\n","Q: He is fair as a priest: 1. he is nice 2. he is mean\n","model says 'He is fair as a priest. he is nice.' is more likely\n","\n","\n","Q: He is fair as a devil: 1. he is nice 2. he is mean\n","model says 'He is fair as a devil. he is nice.' is more likely\n","\n","\n","Q: The branch was as sturdy as a steel beam: 1. The branch was sturdy enough to hold a lot of weight. 2. The branch was weak and could snap easily.\n","model says 'The branch was as sturdy as a steel beam. The branch was weak and could snap easily..' is more likely\n","\n","\n","Q: The branch was as sturdy as a twig: 1. The branch was sturdy enough to hold a lot of weight. 2. The branch was weak and could snap easily.\n","model says 'The branch was as sturdy as a twig. The branch was weak and could snap easily..' is more likely\n","\n","\n","Q: That thing is sucking up as much electricity as a 1950s refrigerator: 1. It uses a lot of electricity 2. It uses no electricity\n","model says 'That thing is sucking up as much electricity as a 1950s refrigerator. It uses no electricity.' is more likely\n","\n","\n","Q: That thing is sucking up as much electricity as the Wii U in the closet: 1. It uses a lot of electricity 2. It uses no electricity\n","model says 'That thing is sucking up as much electricity as the Wii U in the closet. It uses no electricity.' is more likely\n","\n","\n","Q: The play has the excitement of a sleeping tortoise.: 1. The play is dull. 2. The play is rousing.\n","model says 'The play has the excitement of a sleeping tortoise.. The play is dull..' is more likely\n","\n","\n","Q: The play has the excitement of a lottery jackpot.: 1. The play is dull. 2. The play is rousing.\n","model says 'The play has the excitement of a lottery jackpot.. The play is dull..' is more likely\n","\n","\n","Q: The girl is as predictable as ocean waves crashing: 1. The girl was very predictable. 2. The girl was totally unpredictable.\n","model says 'The girl is as predictable as ocean waves crashing. The girl was very predictable..' is more likely\n","\n","\n","Q: The girl is as predictable as the Titanic sinking: 1. The girl was very predictable. 2. The girl was totally unpredictable.\n","model says 'The girl is as predictable as the Titanic sinking. The girl was very predictable..' is more likely\n","\n","\n","Q: The man has the height of a mountain: 1. The man is tall 2. The man is short\n","model says 'The man has the height of a mountain. The man is tall.' is more likely\n","\n","\n","Q: The man has the height of a footstool: 1. The man is tall 2. The man is short\n","model says 'The man has the height of a footstool. The man is tall.' is more likely\n","\n","\n","Q: The house is as enchanting as a castle: 1. the house is pretty 2. the house is ugly\n","model says 'The house is as enchanting as a castle. the house is pretty.' is more likely\n","\n","\n","Q: The house is as enchanting as roadkill: 1. the house is pretty 2. the house is ugly\n","model says 'The house is as enchanting as roadkill. the house is pretty.' is more likely\n","\n","\n","Q: The student was as sharp as A dull knife: 1. The student us dumb 2. The student is smart\n","model says 'The student was as sharp as A dull knife. The student is smart.' is more likely\n","\n","\n","Q: The student was as sharp as A porcupine's quill: 1. The student us dumb 2. The student is smart\n","model says 'The student was as sharp as A porcupine's quill. The student is smart.' is more likely\n","\n","\n","Q: His singing voice is sounds like Fingernails on a blackboard: 1. The voice makes you cringr 2. The voice is calming\n","model says 'His singing voice is sounds like Fingernails on a blackboard. The voice is calming.' is more likely\n","\n","\n","Q: His singing voice is sounds like A lilting breeze: 1. The voice makes you cringr 2. The voice is calming\n","model says 'His singing voice is sounds like A lilting breeze. The voice is calming.' is more likely\n","\n","\n","Q: The goods were as valuable as gold: 1. The goods were valuable 2. The goods were worthless\n","model says 'The goods were as valuable as gold. The goods were valuable.' is more likely\n","\n","\n","Q: The goods were as valuable as dirt: 1. The goods were valuable 2. The goods were worthless\n","model says 'The goods were as valuable as dirt. The goods were valuable.' is more likely\n","\n","\n","Q: The puzzle was as easy as pie: 1. The puzzle was easy 2. The puzzle was hard.\n","model says 'The puzzle was as easy as pie. The puzzle was hard..' is more likely\n","\n","\n","Q: The puzzle was as easy as brain surgery: 1. The puzzle was easy 2. The puzzle was hard.\n","model says 'The puzzle was as easy as brain surgery. The puzzle was hard..' is more likely\n","\n","\n","Q: The politician was as popular as apple pie: 1. The politician was very popular. 2. The politician was very unpopular.\n","model says 'The politician was as popular as apple pie. The politician was very popular..' is more likely\n","\n","\n","Q: The politician was as popular as a root canal: 1. The politician was very popular. 2. The politician was very unpopular.\n","model says 'The politician was as popular as a root canal. The politician was very popular..' is more likely\n","\n","\n","Q: The meeting was as lively as a funeral procession.: 1. The meeting was not lively at all. 2. The meeting was very lively.\n","model says 'The meeting was as lively as a funeral procession.. The meeting was not lively at all..' is more likely\n","\n","\n","Q: The meeting was as lively as a group of children in a bouncy house.: 1. The meeting was not lively at all. 2. The meeting was very lively.\n","model says 'The meeting was as lively as a group of children in a bouncy house.. The meeting was not lively at all..' is more likely\n","\n","\n","Q: He shopped for the item like a bride picking out her dress: 1. He shopped with great care 2. He shopped in a hurry\n","model says 'He shopped for the item like a bride picking out her dress. He shopped in a hurry.' is more likely\n","\n","\n","Q: He shopped for the item like a robber getting away: 1. He shopped with great care 2. He shopped in a hurry\n","model says 'He shopped for the item like a robber getting away. He shopped in a hurry.' is more likely\n","\n","\n","Q: Watching the movie was like going to the dentist's office: 1. The movie was dreadful 2. The movie was enjoyable\n","model says 'Watching the movie was like going to the dentist's office. The movie was enjoyable.' is more likely\n","\n","\n","Q: Watching the movie was like going to the carnival: 1. The movie was dreadful 2. The movie was enjoyable\n","model says 'Watching the movie was like going to the carnival. The movie was enjoyable.' is more likely\n","\n","\n","Q: The cookie was as chewy as a Tootsie Roll: 1. The cookie was perfectly chewy. 2. The cookie was extremely dense and tough.\n","model says 'The cookie was as chewy as a Tootsie Roll. The cookie was perfectly chewy..' is more likely\n","\n","\n","Q: The cookie was as chewy as a brick: 1. The cookie was perfectly chewy. 2. The cookie was extremely dense and tough.\n","model says 'The cookie was as chewy as a brick. The cookie was perfectly chewy..' is more likely\n","\n","\n","Q: The pizza delivery guy had the speed of an Olympic sprinter: 1. The pizza arrived quickly. 2. The pizza took forever to come.\n","model says 'The pizza delivery guy had the speed of an Olympic sprinter. The pizza arrived quickly..' is more likely\n","\n","\n","Q: The pizza delivery guy had the speed of a tectonic plate: 1. The pizza arrived quickly. 2. The pizza took forever to come.\n","model says 'The pizza delivery guy had the speed of a tectonic plate. The pizza arrived quickly..' is more likely\n","\n","\n","Q: The pot roast has the aroma of swamp water.: 1. The pot roast smells bad. 2. The pot roast smells flavorsome.\n","model says 'The pot roast has the aroma of swamp water.. The pot roast smells bad..' is more likely\n","\n","\n","Q: The pot roast has the aroma of a grandmother's kitchen.: 1. The pot roast smells bad. 2. The pot roast smells flavorsome.\n","model says 'The pot roast has the aroma of a grandmother's kitchen.. The pot roast smells bad..' is more likely\n","\n","\n","Q: The photograph has the clarity of an inkblot test.: 1. The photograph is out of focus. 2. The photograph is crystal clear.\n","model says 'The photograph has the clarity of an inkblot test.. The photograph is out of focus..' is more likely\n","\n","\n","Q: The photograph has the clarity of a full rainbow.: 1. The photograph is out of focus. 2. The photograph is crystal clear.\n","model says 'The photograph has the clarity of a full rainbow.. The photograph is out of focus..' is more likely\n","\n","\n","Q: He has the political prowess of a Kennedy: 1. He has good political skills 2. He lacks skill in politics\n","model says 'He has the political prowess of a Kennedy. He has good political skills.' is more likely\n","\n","\n","Q: He has the political prowess of a newborn baby: 1. He has good political skills 2. He lacks skill in politics\n","model says 'He has the political prowess of a newborn baby. He has good political skills.' is more likely\n","\n","\n","Q: This puzzle has the difficulty of putting a man on Mars: 1. It is very difficult 2. It is very easy\n","model says 'This puzzle has the difficulty of putting a man on Mars. It is very easy.' is more likely\n","\n","\n","Q: This puzzle has the difficulty of a child’s block sorting game: 1. It is very difficult 2. It is very easy\n","model says 'This puzzle has the difficulty of a child’s block sorting game. It is very easy.' is more likely\n","\n","\n","Q: The boy was as funny as a comedian: 1. it was funny 2. it wasn't funny\n","model says 'The boy was as funny as a comedian. it was funny.' is more likely\n","\n","\n","Q: The boy was as funny as a dead fly: 1. it was funny 2. it wasn't funny\n","model says 'The boy was as funny as a dead fly. it was funny.' is more likely\n","\n","\n","Q: The politician's apology was a chess move.: 1. The politician's apology was calculated. 2. The politician's apology was chaotic.\n","model says 'The politician's apology was a chess move.. The politician's apology was calculated..' is more likely\n","\n","\n","Q: The politician's apology was an avalanche.: 1. The politician's apology was calculated. 2. The politician's apology was chaotic.\n","model says 'The politician's apology was an avalanche.. The politician's apology was calculated..' is more likely\n","\n","\n","Q: He was as dangerous as a viper: 1. He was very dangerous 2. He was not dangerous\n","model says 'He was as dangerous as a viper. He was not dangerous.' is more likely\n","\n","\n","Q: He was as dangerous as a flea: 1. He was very dangerous 2. He was not dangerous\n","model says 'He was as dangerous as a flea. He was not dangerous.' is more likely\n","\n","\n","Q: The water was as warm as the surface of the sun: 1. The water was scalding hot 2. The water was cold\n","model says 'The water was as warm as the surface of the sun. The water was cold.' is more likely\n","\n","\n","Q: The water was as warm as an icicle: 1. The water was scalding hot 2. The water was cold\n","model says 'The water was as warm as an icicle. The water was cold.' is more likely\n","\n","\n","Q: Her excuse had the conviction of a deserting soldier.: 1. Her excuse lacked conviction. 2. Her excuse was full of conviction.\n","model says 'Her excuse had the conviction of a deserting soldier.. Her excuse lacked conviction..' is more likely\n","\n","\n","Q: Her excuse had the conviction of a revivalist preacher.: 1. Her excuse lacked conviction. 2. Her excuse was full of conviction.\n","model says 'Her excuse had the conviction of a revivalist preacher.. Her excuse lacked conviction..' is more likely\n","\n","\n","Q: The threat was an oncoming train: 1. The threat was imminent. 2. The threat was distant.\n","model says 'The threat was an oncoming train. The threat was distant..' is more likely\n","\n","\n","Q: The threat was a third cousin thrice removed: 1. The threat was imminent. 2. The threat was distant.\n","model says 'The threat was a third cousin thrice removed. The threat was distant..' is more likely\n","\n","\n","Q: Their love was as easy to understand as a Bob Dylan lyric.: 1. Their love was complex and hard to interpret. 2. Their love was hot and short lived.\n","model says 'Their love was as easy to understand as a Bob Dylan lyric.. Their love was hot and short lived..' is more likely\n","\n","\n","Q: Their love was as a California wildfire season.: 1. Their love was complex and hard to interpret. 2. Their love was hot and short lived.\n","model says 'Their love was as a California wildfire season.. Their love was hot and short lived..' is more likely\n","\n","\n","Q: The book grabbed my attention like legalese in a merger agreement: 1. The book totally bored me. 2. The book really interested me.\n","model says 'The book grabbed my attention like legalese in a merger agreement. The book really interested me..' is more likely\n","\n","\n","Q: The book grabbed my attention like a trashy magazine headline: 1. The book totally bored me. 2. The book really interested me.\n","model says 'The book grabbed my attention like a trashy magazine headline. The book really interested me..' is more likely\n","\n","\n","Q: Her thoughts were like a yo-yo: 1. Her thoughts were all over the place. 2. Her thoughts were steady.\n","model says 'Her thoughts were like a yo-yo. Her thoughts were steady..' is more likely\n","\n","\n","Q: Her thoughts were like a spring stream: 1. Her thoughts were all over the place. 2. Her thoughts were steady.\n","model says 'Her thoughts were like a spring stream. Her thoughts were steady..' is more likely\n","\n","\n","Q: Her ego was a Ritz cracker: 1. Her ego was very fragile. 2. Her ego was unshakeable.\n","model says 'Her ego was a Ritz cracker. Her ego was unshakeable..' is more likely\n","\n","\n","Q: Her ego was a brick building: 1. Her ego was very fragile. 2. Her ego was unshakeable.\n","model says 'Her ego was a brick building. Her ego was unshakeable..' is more likely\n","\n","\n","Q: His mind is a steel cage: 1. He has a very good memory and rarely forgets anything 2. His memory is terrible, things go in one ear and out the other\n","model says 'His mind is a steel cage. His memory is terrible, things go in one ear and out the other.' is more likely\n","\n","\n","Q: His mind is an open barn door: 1. He has a very good memory and rarely forgets anything 2. His memory is terrible, things go in one ear and out the other\n","model says 'His mind is an open barn door. His memory is terrible, things go in one ear and out the other.' is more likely\n","\n","\n","Q: The screen was dim like a flashlight.: 1. The screen was bright. 2. The screen was dim.\n","model says 'The screen was dim like a flashlight.. The screen was dim..' is more likely\n","\n","\n","Q: The screen was dim like a candle.: 1. The screen was bright. 2. The screen was dim.\n","model says 'The screen was dim like a candle.. The screen was dim..' is more likely\n","\n","\n","Q: That politician's speech was a good as Lincoln's Gettysburg Address: 1. The speech was sycinct and powerful 2. The speech was overbearing and boring.\n","model says 'That politician's speech was a good as Lincoln's Gettysburg Address. The speech was sycinct and powerful.' is more likely\n","\n","\n","Q: That politician's speech was a good as a college professor dense lecture.: 1. The speech was sycinct and powerful 2. The speech was overbearing and boring.\n","model says 'That politician's speech was a good as a college professor dense lecture.. The speech was sycinct and powerful.' is more likely\n","\n","\n","Q: you are as hard as pillow: 1. You are soft 2. You are stubborn\n","model says 'you are as hard as pillow. You are soft.' is more likely\n","\n","\n","Q: you are as hard as rock: 1. You are soft 2. You are stubborn\n","model says 'you are as hard as rock. You are soft.' is more likely\n","\n","\n","Q: You are as tough as an egg: 1. eggs crack 2. coconuts are hard\n","model says 'You are as tough as an egg. eggs crack.' is more likely\n","\n","\n","Q: You are as tough as a coconut: 1. eggs crack 2. coconuts are hard\n","model says 'You are as tough as a coconut. eggs crack.' is more likely\n","\n","\n","Q: The girl is as good at camouflaging her emotions as a chameleon: 1. The girl hides her emotions well. 2. The girl shows off her emotions.\n","model says 'The girl is as good at camouflaging her emotions as a chameleon. The girl shows off her emotions..' is more likely\n","\n","\n","Q: The girl is as good at camouflaging her emotions as a peacock: 1. The girl hides her emotions well. 2. The girl shows off her emotions.\n","model says 'The girl is as good at camouflaging her emotions as a peacock. The girl shows off her emotions..' is more likely\n","\n","\n","Q: My bank account is dry as the Sahara: 1. My bank account is barren, I have no money 2. My bank account is fat with cash, I'm rich\n","model says 'My bank account is dry as the Sahara. My bank account is barren, I have no money.' is more likely\n","\n","\n","Q: My bank account is stuffed like a Thanksgiving turkey: 1. My bank account is barren, I have no money 2. My bank account is fat with cash, I'm rich\n","model says 'My bank account is stuffed like a Thanksgiving turkey. My bank account is barren, I have no money.' is more likely\n","\n","\n","Q: The sandwich has the cheesiness of the moon as depicted in cartoons: 1. The sandwich is very cheesy 2. The sandwich lacks cheese\n","model says 'The sandwich has the cheesiness of the moon as depicted in cartoons. The sandwich lacks cheese.' is more likely\n","\n","\n","Q: The sandwich has the cheesiness of a pizza without the primary topping: 1. The sandwich is very cheesy 2. The sandwich lacks cheese\n","model says 'The sandwich has the cheesiness of a pizza without the primary topping. The sandwich lacks cheese.' is more likely\n","\n","\n","Q: The tower has the wind resistance of metal roofing on a fair weather day: 1. The tower has a high wind resistance 2. The tower has almost no resistance to wind\n","model says 'The tower has the wind resistance of metal roofing on a fair weather day. The tower has a high wind resistance.' is more likely\n","\n","\n","Q: The tower has the wind resistance of candy wrapper caught in an updraft: 1. The tower has a high wind resistance 2. The tower has almost no resistance to wind\n","model says 'The tower has the wind resistance of candy wrapper caught in an updraft. The tower has a high wind resistance.' is more likely\n","\n","\n","Q: The body has the survivability of a hungry tiger in a hen house: 1. It has high survivability 2. It has a low survivability rate\n","model says 'The body has the survivability of a hungry tiger in a hen house. It has high survivability.' is more likely\n","\n","\n","Q: The body has the survivability of a paper bag in a stormy ocean: 1. It has high survivability 2. It has a low survivability rate\n","model says 'The body has the survivability of a paper bag in a stormy ocean. It has high survivability.' is more likely\n","\n","\n","Q: She rode that horse like An acrobat: 1. She rode it well 2. She rode it poorly\n","model says 'She rode that horse like An acrobat. She rode it well.' is more likely\n","\n","\n","Q: She rode that horse like A seizure victim: 1. She rode it well 2. She rode it poorly\n","model says 'She rode that horse like A seizure victim. She rode it well.' is more likely\n","\n","\n","Q: The speech was as inspiring as A cement block: 1. It is dull 2. It is motivating\n","model says 'The speech was as inspiring as A cement block. It is dull.' is more likely\n","\n","\n","Q: The speech was as inspiring as A legless marathon runner: 1. It is dull 2. It is motivating\n","model says 'The speech was as inspiring as A legless marathon runner. It is dull.' is more likely\n","\n","\n","Q: The glass is a clear as Ikea instructions: 1. It is not clear 2. It is see thru\n","model says 'The glass is a clear as Ikea instructions. It is see thru.' is more likely\n","\n","\n","Q: The glass is a clear as Saran wrap: 1. It is not clear 2. It is see thru\n","model says 'The glass is a clear as Saran wrap. It is see thru.' is more likely\n","\n","\n","Q: The cookies tasted like hardtack.: 1. The cookies are awful. 2. The cookies are delicous.\n","model says 'The cookies tasted like hardtack.. The cookies are awful..' is more likely\n","\n","\n","Q: The cookies tasted like heaven.: 1. The cookies are awful. 2. The cookies are delicous.\n","model says 'The cookies tasted like heaven.. The cookies are awful..' is more likely\n","\n","\n","Q: The floor was as slippery as oil: 1. The floor was slippery. 2. The floor wasn't slippery at all.\n","model says 'The floor was as slippery as oil. The floor was slippery..' is more likely\n","\n","\n","Q: The floor was as slippery as sandpaper: 1. The floor was slippery. 2. The floor wasn't slippery at all.\n","model says 'The floor was as slippery as sandpaper. The floor was slippery..' is more likely\n","\n","\n","Q: The gem was as fake as a bad toupee: 1. The gem was obviously fake. 2. The gem was obviously real.\n","model says 'The gem was as fake as a bad toupee. The gem was obviously real..' is more likely\n","\n","\n","Q: The gem was as fake as the air we breathe: 1. The gem was obviously fake. 2. The gem was obviously real.\n","model says 'The gem was as fake as the air we breathe. The gem was obviously real..' is more likely\n","\n","\n","Q: The boys are as disciplined as the military: 1. The boys are highly disciplined. 2. The boys lack any discipline.\n","model says 'The boys are as disciplined as the military. The boys lack any discipline..' is more likely\n","\n","\n","Q: The boys are as disciplined as barrel monkeys: 1. The boys are highly disciplined. 2. The boys lack any discipline.\n","model says 'The boys are as disciplined as barrel monkeys. The boys lack any discipline..' is more likely\n","\n","\n","Q: The helicopter had the reliability of a collapsing tower.: 1. The helicopter was not reliable. 2. The helicopter was very reliable.\n","model says 'The helicopter had the reliability of a collapsing tower.. The helicopter was not reliable..' is more likely\n","\n","\n","Q: The helicopter had the reliability of a battleship.: 1. The helicopter was not reliable. 2. The helicopter was very reliable.\n","model says 'The helicopter had the reliability of a battleship.. The helicopter was not reliable..' is more likely\n","\n","\n","Q: This book is like silk in my hands.: 1. This book is hard to put down. 2. This book is forgettable.\n","model says 'This book is like silk in my hands.. This book is forgettable..' is more likely\n","\n","\n","Q: This book is like hard-cover amnesia.: 1. This book is hard to put down. 2. This book is forgettable.\n","model says 'This book is like hard-cover amnesia.. This book is forgettable..' is more likely\n","\n","\n","Q: The teams passion was burning like an inferno: 1. The team had a lot of passion 2. THe team had very little passion\n","model says 'The teams passion was burning like an inferno. The team had a lot of passion.' is more likely\n","\n","\n","Q: The teams passion was burning like a match: 1. The team had a lot of passion 2. THe team had very little passion\n","model says 'The teams passion was burning like a match. The team had a lot of passion.' is more likely\n","\n","\n","Q: The sword was as sharp as a laser: 1. The sword was sharp 2. The sword was dull\n","model says 'The sword was as sharp as a laser. The sword was sharp.' is more likely\n","\n","\n","Q: The sword was as sharp as a stick: 1. The sword was sharp 2. The sword was dull\n","model says 'The sword was as sharp as a stick. The sword was sharp.' is more likely\n","\n","\n","Q: He maneuvered with the tactical precision of an experienced general.: 1. He manuevered skillfully. 2. He maneuvered poorly.\n","model says 'He maneuvered with the tactical precision of an experienced general.. He maneuvered poorly..' is more likely\n","\n","\n","Q: He maneuvered with the tactical precision of a clown car.: 1. He manuevered skillfully. 2. He maneuvered poorly.\n","model says 'He maneuvered with the tactical precision of a clown car.. He maneuvered poorly..' is more likely\n","\n","\n","Q: The ending was as satisfying as a Thanksgiving dinner with all the trimmings.: 1. The ending was satisfying. 2. The ending was unsatisfying.\n","model says 'The ending was as satisfying as a Thanksgiving dinner with all the trimmings.. The ending was satisfying..' is more likely\n","\n","\n","Q: The ending was as satisfying as a stale saltine cracker.: 1. The ending was satisfying. 2. The ending was unsatisfying.\n","model says 'The ending was as satisfying as a stale saltine cracker.. The ending was satisfying..' is more likely\n","\n","\n","Q: That guy is as smart as a rock: 1. The guy is dumb 2. The guy is intelligent\n","model says 'That guy is as smart as a rock. The guy is intelligent.' is more likely\n","\n","\n","Q: That guy is as smart as a computer: 1. The guy is dumb 2. The guy is intelligent\n","model says 'That guy is as smart as a computer. The guy is intelligent.' is more likely\n","\n","\n","Q: The friendship was as meaningful as a contract on a napkin: 1. The friendship wasn't meaningful at all. 2. The friendship was highly meaningful.\n","model says 'The friendship was as meaningful as a contract on a napkin. The friendship was highly meaningful..' is more likely\n","\n","\n","Q: The friendship was as meaningful as an international treaty: 1. The friendship wasn't meaningful at all. 2. The friendship was highly meaningful.\n","model says 'The friendship was as meaningful as an international treaty. The friendship was highly meaningful..' is more likely\n","\n","\n","Q: The child was as still as a marble slab: 1. The child was totally still. 2. The child couldn't stop moving.\n","model says 'The child was as still as a marble slab. The child was totally still..' is more likely\n","\n","\n","Q: The child was as still as a waterfall: 1. The child was totally still. 2. The child couldn't stop moving.\n","model says 'The child was as still as a waterfall. The child was totally still..' is more likely\n","\n","\n","Q: He is as strong as a diamond.: 1. He is very strong. 2. He is weak.\n","model says 'He is as strong as a diamond.. He is weak..' is more likely\n","\n","\n","Q: He is as strong as a piece of graphite.: 1. He is very strong. 2. He is weak.\n","model says 'He is as strong as a piece of graphite.. He is weak..' is more likely\n","\n","\n","Q: He has the satisfaction of a master chef after making a 5 star meal: 1. He is very satisfied 2. He has very little satisfaction\n","model says 'He has the satisfaction of a master chef after making a 5 star meal. He is very satisfied.' is more likely\n","\n","\n","Q: He has the satisfaction of a master chef aftet making a bowl of canned 🍝: 1. He is very satisfied 2. He has very little satisfaction\n","model says 'He has the satisfaction of a master chef aftet making a bowl of canned 🍝. He is very satisfied.' is more likely\n","\n","\n","Q: She had the dedication of a gnat: 1. She is flighty and unfocused 2. She applies pressure consistently and over time.\n","model says 'She had the dedication of a gnat. She applies pressure consistently and over time..' is more likely\n","\n","\n","Q: She had the dedication of a tectonic plate: 1. She is flighty and unfocused 2. She applies pressure consistently and over time.\n","model says 'She had the dedication of a tectonic plate. She applies pressure consistently and over time..' is more likely\n","\n","\n","Q: The desire she felt was a mere trickle: 1. She felt little desire 2. She felt a strong desire\n","model says 'The desire she felt was a mere trickle. She felt little desire.' is more likely\n","\n","\n","Q: The desire she felt was a surging wave: 1. She felt little desire 2. She felt a strong desire\n","model says 'The desire she felt was a surging wave. She felt little desire.' is more likely\n","\n","\n","Q: The man has the taste of a picky child.: 1. The man has poor taste in things. 2. The man has exquisite and fine taste in things.\n","model says 'The man has the taste of a picky child.. The man has poor taste in things..' is more likely\n","\n","\n","Q: The man has the taste of the Queen of England.: 1. The man has poor taste in things. 2. The man has exquisite and fine taste in things.\n","model says 'The man has the taste of the Queen of England.. The man has poor taste in things..' is more likely\n","\n","\n","Q: The bed is as comfortable as cloud.: 1. The bed is very comfortable. 2. The bed is very uncomfortable.\n","model says 'The bed is as comfortable as cloud.. The bed is very comfortable..' is more likely\n","\n","\n","Q: The bed is as comfortable as seeing your ex.: 1. The bed is very comfortable. 2. The bed is very uncomfortable.\n","model says 'The bed is as comfortable as seeing your ex.. The bed is very comfortable..' is more likely\n","\n","\n","Q: She has the patience of a saint: 1. She is very patient 2. She is not patient at all\n","model says 'She has the patience of a saint. She is very patient.' is more likely\n","\n","\n","Q: She has the patience of a bull: 1. She is very patient 2. She is not patient at all\n","model says 'She has the patience of a bull. She is very patient.' is more likely\n","\n","\n","Q: He has the morality of a puppy dog.: 1. He is very moral and kind. 2. He is not very moral or kind.\n","model says 'He has the morality of a puppy dog.. He is very moral and kind..' is more likely\n","\n","\n","Q: He has the morality of a vulture.: 1. He is very moral and kind. 2. He is not very moral or kind.\n","model says 'He has the morality of a vulture.. He is very moral and kind..' is more likely\n","\n","\n","Q: His desire for her was a runaway horse.: 1. His desire for her was wild. 2. His desire for her was dormant.\n","model says 'His desire for her was a runaway horse.. His desire for her was wild..' is more likely\n","\n","\n","Q: His desire for her was a snail.: 1. His desire for her was wild. 2. His desire for her was dormant.\n","model says 'His desire for her was a snail.. His desire for her was wild..' is more likely\n","\n","\n","Q: He could sprint like the wind: 1. He was fast. 2. He was slow.\n","model says 'He could sprint like the wind. He was fast..' is more likely\n","\n","\n","Q: He could sprint like a tortoise: 1. He was fast. 2. He was slow.\n","model says 'He could sprint like a tortoise. He was fast..' is more likely\n","\n","\n","Q: They fit each other's personalities like a plug in a socket: 1. They fit each other's personalities perfectly. 2. They don't fit each other's personalities well at all.\n","model says 'They fit each other's personalities like a plug in a socket. They fit each other's personalities perfectly..' is more likely\n","\n","\n","Q: They fit each other's personalities like a magnet on paper: 1. They fit each other's personalities perfectly. 2. They don't fit each other's personalities well at all.\n","model says 'They fit each other's personalities like a magnet on paper. They fit each other's personalities perfectly..' is more likely\n","\n","\n","Q: The spaghetti was as cold as the gaze of an angry parochial school teacher: 1. The spaghetti was cold 2. The spaghetti was very hot\n","model says 'The spaghetti was as cold as the gaze of an angry parochial school teacher. The spaghetti was cold.' is more likely\n","\n","\n","Q: The spaghetti was as cold as a vacation to Hades: 1. The spaghetti was cold 2. The spaghetti was very hot\n","model says 'The spaghetti was as cold as a vacation to Hades. The spaghetti was cold.' is more likely\n","\n","\n","Q: Her mind was like a safe deposit box: 1. Her mind is closed and secretive 2. Her mind is wide open and easily accessible\n","model says 'Her mind was like a safe deposit box. Her mind is wide open and easily accessible.' is more likely\n","\n","\n","Q: Her mind was like a child's toy box: 1. Her mind is closed and secretive 2. Her mind is wide open and easily accessible\n","model says 'Her mind was like a child's toy box. Her mind is wide open and easily accessible.' is more likely\n","\n","\n","Q: The ghost has the invisibility of a shy middle child with an overachieving older brother and a wild and rambunctious younger sister: 1. The ghost is very hard to see 2. The ghost is very noticeable\n","model says 'The ghost has the invisibility of a shy middle child with an overachieving older brother and a wild and rambunctious younger sister. The ghost is very hard to see.' is more likely\n","\n","\n","Q: The ghost has the invisibility of a bully in a china shop, smashing the china on his victim: 1. The ghost is very hard to see 2. The ghost is very noticeable\n","model says 'The ghost has the invisibility of a bully in a china shop, smashing the china on his victim. The ghost is very hard to see.' is more likely\n","\n","\n","Q: Your wit has the sharpness of a blade: 1. Your wit is clever. 2. Your wit is dull and not clever.\n","model says 'Your wit has the sharpness of a blade. Your wit is clever..' is more likely\n","\n","\n","Q: Your wit has the sharpness of a stone: 1. Your wit is clever. 2. Your wit is dull and not clever.\n","model says 'Your wit has the sharpness of a stone. Your wit is clever..' is more likely\n","\n","\n","Q: She had all the grace and elegance of a ballerina: 1. She is very graceful and elegant. 2. She is not graceful or elegant, and in fact is cumbersome and unsophisticated.\n","model says 'She had all the grace and elegance of a ballerina. She is very graceful and elegant..' is more likely\n","\n","\n","Q: She had all the grace and elegance of a dump truck: 1. She is very graceful and elegant. 2. She is not graceful or elegant, and in fact is cumbersome and unsophisticated.\n","model says 'She had all the grace and elegance of a dump truck. She is very graceful and elegant..' is more likely\n","\n","\n","Q: The teacher had the patience of a flea: 1. The teacher was impatient. 2. The teacher was patient.\n","model says 'The teacher had the patience of a flea. The teacher was patient..' is more likely\n","\n","\n","Q: The teacher had the patience of a tortoise: 1. The teacher was impatient. 2. The teacher was patient.\n","model says 'The teacher had the patience of a tortoise. The teacher was patient..' is more likely\n","\n","\n","Q: The dog had the attitude of a yogi: 1. The dog had a calm attitude. 2. The dog had an aggressive attitude.\n","model says 'The dog had the attitude of a yogi. The dog had an aggressive attitude..' is more likely\n","\n","\n","Q: The dog had the attitude of a military commander: 1. The dog had a calm attitude. 2. The dog had an aggressive attitude.\n","model says 'The dog had the attitude of a military commander. The dog had an aggressive attitude..' is more likely\n","\n","\n","Q: He could run with the speed of a racehorse.: 1. He was really fast. 2. He was really slow.\n","model says 'He could run with the speed of a racehorse.. He was really fast..' is more likely\n","\n","\n","Q: He could run with the speed of a elderly tortoise.: 1. He was really fast. 2. He was really slow.\n","model says 'He could run with the speed of a elderly tortoise.. He was really fast..' is more likely\n","\n","\n","Q: Henry is a golden retriever.: 1. Henry is trustworthy and friendly. 2. Henry is not friendly or trustworthy.\n","model says 'Henry is a golden retriever.. Henry is trustworthy and friendly..' is more likely\n","\n","\n","Q: Henry is a cobra.: 1. Henry is trustworthy and friendly. 2. Henry is not friendly or trustworthy.\n","model says 'Henry is a cobra.. Henry is trustworthy and friendly..' is more likely\n","\n","\n","Q: This cat has the grace of a ballerina.: 1. The cat is extremely graceful. 2. The cat is clumsy and ungraceful.\n","model says 'This cat has the grace of a ballerina.. The cat is extremely graceful..' is more likely\n","\n","\n","Q: This cat has the grace of a pig on ice.: 1. The cat is extremely graceful. 2. The cat is clumsy and ungraceful.\n","model says 'This cat has the grace of a pig on ice.. The cat is extremely graceful..' is more likely\n","\n","\n","Q: The dog is as smart as a bowl of rocks: 1. the dog is dumb 2. the dog is smart\n","model says 'The dog is as smart as a bowl of rocks. the dog is smart.' is more likely\n","\n","\n","Q: The dog is as smart as a scientist: 1. the dog is dumb 2. the dog is smart\n","model says 'The dog is as smart as a scientist. the dog is smart.' is more likely\n","\n","\n","Q: The tax penalty was as heavy as a bowling ball: 1. The tax penalty was very heavy. 2. The tax penalty was very light.\n","model says 'The tax penalty was as heavy as a bowling ball. The tax penalty was very light..' is more likely\n","\n","\n","Q: The tax penalty was as heavy as a hairpin: 1. The tax penalty was very heavy. 2. The tax penalty was very light.\n","model says 'The tax penalty was as heavy as a hairpin. The tax penalty was very light..' is more likely\n","\n","\n","Q: The food is as warm as a volcano: 1. The food is hot 2. the food is cold\n","model says 'The food is as warm as a volcano. The food is hot.' is more likely\n","\n","\n","Q: The food is as warm as ice: 1. The food is hot 2. the food is cold\n","model says 'The food is as warm as ice. The food is hot.' is more likely\n","\n","\n","Q: The road is as flat as a pancake: 1. The road is flat 2. The road is rolling\n","model says 'The road is as flat as a pancake. The road is flat.' is more likely\n","\n","\n","Q: The road is as flat as a roller coaster: 1. The road is flat 2. The road is rolling\n","model says 'The road is as flat as a roller coaster. The road is flat.' is more likely\n","\n","\n","Q: She is as transparent as a window: 1. You can see her intentions 2. You can't tell what kind of person she is\n","model says 'She is as transparent as a window. You can see her intentions.' is more likely\n","\n","\n","Q: She is as transparent as a wall: 1. You can see her intentions 2. You can't tell what kind of person she is\n","model says 'She is as transparent as a wall. You can see her intentions.' is more likely\n","\n","\n","Q: He has a heart of gold: 1. He has a great deal of concern for others 2. He doesn't care too much for others\n","model says 'He has a heart of gold. He doesn't care too much for others.' is more likely\n","\n","\n","Q: He has a heart of coal: 1. He has a great deal of concern for others 2. He doesn't care too much for others\n","model says 'He has a heart of coal. He doesn't care too much for others.' is more likely\n","\n","\n","Q: The movie has the tension of a cat in a room full of rocking chairs.: 1. The movie is tense. 2. The movie's pace is relaxed.\n","model says 'The movie has the tension of a cat in a room full of rocking chairs.. The movie is tense..' is more likely\n","\n","\n","Q: The movie has the tension of a wet noodle.: 1. The movie is tense. 2. The movie's pace is relaxed.\n","model says 'The movie has the tension of a wet noodle.. The movie is tense..' is more likely\n","\n","\n","Q: the book has the depth of an ant’s bathtub: 1. the story is superficial 2. the story is profound\n","model says 'the book has the depth of an ant’s bathtub. the story is superficial.' is more likely\n","\n","\n","Q: the book has the depth of the marianna trench: 1. the story is superficial 2. the story is profound\n","model says 'the book has the depth of the marianna trench. the story is superficial.' is more likely\n","\n","\n","Q: She was as jumpy as a yo-yo string: 1. She was very anxious. 2. She was very calm.\n","model says 'She was as jumpy as a yo-yo string. She was very calm..' is more likely\n","\n","\n","Q: She was as jumpy as a yogi: 1. She was very anxious. 2. She was very calm.\n","model says 'She was as jumpy as a yogi. She was very calm..' is more likely\n","\n","\n","Q: The job pays as good as a Chinese factory: 1. The job pays very little 2. The job pays excellent.\n","model says 'The job pays as good as a Chinese factory. The job pays excellent..' is more likely\n","\n","\n","Q: The job pays as good as a politician's pay.: 1. The job pays very little 2. The job pays excellent.\n","model says 'The job pays as good as a politician's pay.. The job pays excellent..' is more likely\n","\n","\n","Q: The book is as interesting as counting drips of water: 1. The book is beyond boring. 2. The book is incredible.\n","model says 'The book is as interesting as counting drips of water. The book is incredible..' is more likely\n","\n","\n","Q: The book is as interesting as time travel.: 1. The book is beyond boring. 2. The book is incredible.\n","model says 'The book is as interesting as time travel.. The book is incredible..' is more likely\n","\n","\n","Q: The date had all the magic of an exotic tale: 1. The date was intriguing 2. The date was boring\n","model says 'The date had all the magic of an exotic tale. The date was intriguing.' is more likely\n","\n","\n","Q: The date had all the magic of a classified ad: 1. The date was intriguing 2. The date was boring\n","model says 'The date had all the magic of a classified ad. The date was intriguing.' is more likely\n","\n","\n","Q: The photography is as beautiful as a sunrise on a crisp autumn day: 1. The photography is beautiful and moving 2. The photography is ugly and unwanted\n","model says 'The photography is as beautiful as a sunrise on a crisp autumn day. The photography is ugly and unwanted.' is more likely\n","\n","\n","Q: The photography is as beautiful as a trash heap: 1. The photography is beautiful and moving 2. The photography is ugly and unwanted\n","model says 'The photography is as beautiful as a trash heap. The photography is ugly and unwanted.' is more likely\n","\n","\n","Q: The clown has a smile like a cat who just caught a mouse: 1. The clown's smile is wide and happy 2. The clown's smile is inexpressive, flat\n","model says 'The clown has a smile like a cat who just caught a mouse. The clown's smile is wide and happy.' is more likely\n","\n","\n","Q: The clown has a smile like a marionette: 1. The clown's smile is wide and happy 2. The clown's smile is inexpressive, flat\n","model says 'The clown has a smile like a marionette. The clown's smile is wide and happy.' is more likely\n","\n","\n","Q: She thinks of him as highly as a full diaper: 1. She thinks he's worthless. 2. She prizes him.\n","model says 'She thinks of him as highly as a full diaper. She prizes him..' is more likely\n","\n","\n","Q: She thinks of him as highly as a diamond: 1. She thinks he's worthless. 2. She prizes him.\n","model says 'She thinks of him as highly as a diamond. She prizes him..' is more likely\n","\n","\n","Q: His mother's words were littered with garbage.: 1. His mother's words were stupid. 2. His mother's words were wise.\n","model says 'His mother's words were littered with garbage.. His mother's words were stupid..' is more likely\n","\n","\n","Q: His mother's words were littered with gems.: 1. His mother's words were stupid. 2. His mother's words were wise.\n","model says 'His mother's words were littered with gems.. His mother's words were stupid..' is more likely\n","\n","\n","Q: The crowd was filled with wolves.: 1. The crowd had several dangerous leaders. 2. The crowd had several unthinking followers.\n","model says 'The crowd was filled with wolves.. The crowd had several dangerous leaders..' is more likely\n","\n","\n","Q: The crowd was filled with sheep.: 1. The crowd had several dangerous leaders. 2. The crowd had several unthinking followers.\n","model says 'The crowd was filled with sheep.. The crowd had several dangerous leaders..' is more likely\n","\n","\n","Q: He eats like a mouse.: 1. He doesn't eat a lot. 2. He eats a lot.\n","model says 'He eats like a mouse.. He eats a lot..' is more likely\n","\n","\n","Q: He eats like a dog.: 1. He doesn't eat a lot. 2. He eats a lot.\n","model says 'He eats like a dog.. He eats a lot..' is more likely\n","\n","\n","Q: The rabbit had the softness of an Eider Duck crossbred with a chinchilla: 1. The rabbit feels extremely soft 2. The rabbit feels rough\n","model says 'The rabbit had the softness of an Eider Duck crossbred with a chinchilla. The rabbit feels rough.' is more likely\n","\n","\n","Q: The rabbit had the softness of the face of a man with 5 o'clock shadow: 1. The rabbit feels extremely soft 2. The rabbit feels rough\n","model says 'The rabbit had the softness of the face of a man with 5 o'clock shadow. The rabbit feels rough.' is more likely\n","\n","\n","Q: The teacher was as amused as a girl on a date with her crush: 1. the teacher was interested 2. the teacher didn't want to hear anything\n","model says 'The teacher was as amused as a girl on a date with her crush. the teacher was interested.' is more likely\n","\n","\n","Q: The teacher was as amused as a judge in the courtroom: 1. the teacher was interested 2. the teacher didn't want to hear anything\n","model says 'The teacher was as amused as a judge in the courtroom. the teacher was interested.' is more likely\n","\n","\n","Q: The whole series had the depth of a puddle.: 1. The series was boring. 2. The series was profound.\n","model says 'The whole series had the depth of a puddle.. The series was profound..' is more likely\n","\n","\n","Q: The whole series had the depth of a lake.: 1. The series was boring. 2. The series was profound.\n","model says 'The whole series had the depth of a lake.. The series was profound..' is more likely\n","\n","\n","Q: The air had the cleanliness of pre-industrial China: 1. The air is quite clean 2. The air is filthy\n","model says 'The air had the cleanliness of pre-industrial China. The air is quite clean.' is more likely\n","\n","\n","Q: The air had the cleanliness of a freshly opened vacuum: 1. The air is quite clean 2. The air is filthy\n","model says 'The air had the cleanliness of a freshly opened vacuum. The air is quite clean.' is more likely\n","\n","\n","Q: She is as busy as a beaver.: 1. She is really busy. 2. She is lazy.\n","model says 'She is as busy as a beaver.. She is lazy..' is more likely\n","\n","\n","Q: She is as busy as a sloth.: 1. She is really busy. 2. She is lazy.\n","model says 'She is as busy as a sloth.. She is lazy..' is more likely\n","\n","\n","Q: She sings like a song bird.: 1. She sings well. 2. She sings badly.\n","model says 'She sings like a song bird.. She sings well..' is more likely\n","\n","\n","Q: She sings like a howling cat.: 1. She sings well. 2. She sings badly.\n","model says 'She sings like a howling cat.. She sings well..' is more likely\n","\n","\n","Q: He is as open as a closed door.: 1. He is not open at all. 2. He is very open.\n","model says 'He is as open as a closed door.. He is very open..' is more likely\n","\n","\n","Q: He is as open as a large mall.: 1. He is not open at all. 2. He is very open.\n","model says 'He is as open as a large mall.. He is very open..' is more likely\n","\n","\n","Q: His mood had the permanence of the sun.: 1. His mood never changes. 2. His mood was always changing.\n","model says 'His mood had the permanence of the sun.. His mood never changes..' is more likely\n","\n","\n","Q: His mood had the permanence of the tide.: 1. His mood never changes. 2. His mood was always changing.\n","model says 'His mood had the permanence of the tide.. His mood never changes..' is more likely\n","\n","\n","Q: She was hiding like Anne Frank: 1. She was hiding well 2. She was hiding poorly\n","model says 'She was hiding like Anne Frank. She was hiding well.' is more likely\n","\n","\n","Q: She was hiding like circus clown: 1. She was hiding well 2. She was hiding poorly\n","model says 'She was hiding like circus clown. She was hiding well.' is more likely\n","\n","\n","Q: Those facts were like the Bible: 1. Those facts were not true 2. Those facts were true\n","model says 'Those facts were like the Bible. Those facts were true.' is more likely\n","\n","\n","Q: Those facts were like dictionary: 1. Those facts were not true 2. Those facts were true\n","model says 'Those facts were like dictionary. Those facts were true.' is more likely\n","\n","\n","Q: The final score of the game ended up being closer than the hair on a dog's tail.: 1. The teams scored similar amounts of points till the end of the game. 2. The teams did not score similar amounts till the end of the game.\n","model says 'The final score of the game ended up being closer than the hair on a dog's tail.. The teams did not score similar amounts till the end of the game..' is more likely\n","\n","\n","Q: The final score of the game ended up being further than two goal posts on a football field.: 1. The teams scored similar amounts of points till the end of the game. 2. The teams did not score similar amounts till the end of the game.\n","model says 'The final score of the game ended up being further than two goal posts on a football field.. The teams did not score similar amounts till the end of the game..' is more likely\n","\n","\n","Q: The facts verified the case like A thief's lies: 1. The facts were unreliable 2. The facts were solid and supported the case\n","model says 'The facts verified the case like A thief's lies. The facts were unreliable.' is more likely\n","\n","\n","Q: The facts verified the case like A solid Sherlock Holmes case: 1. The facts were unreliable 2. The facts were solid and supported the case\n","model says 'The facts verified the case like A solid Sherlock Holmes case. The facts were unreliable.' is more likely\n","\n","\n","Q: Laughter is like music to soul.: 1. Laughter makes me happy. 2. Laughter annoys me.\n","model says 'Laughter is like music to soul.. Laughter makes me happy..' is more likely\n","\n","\n","Q: Laughter is like screeching on a chalkboard.: 1. Laughter makes me happy. 2. Laughter annoys me.\n","model says 'Laughter is like screeching on a chalkboard.. Laughter makes me happy..' is more likely\n","\n","\n","Q: Facts are immovable boulders.: 1. Facts cannot be changed. 2. Facts are constantly changing.\n","model says 'Facts are immovable boulders.. Facts cannot be changed..' is more likely\n","\n","\n","Q: Facts are liquid.: 1. Facts cannot be changed. 2. Facts are constantly changing.\n","model says 'Facts are liquid.. Facts cannot be changed..' is more likely\n","\n","\n","Q: His library was a brain.: 1. His library was really intellectual. 2. His library was unimpressive.\n","model says 'His library was a brain.. His library was really intellectual..' is more likely\n","\n","\n","Q: His library was a puff of smoke.: 1. His library was really intellectual. 2. His library was unimpressive.\n","model says 'His library was a puff of smoke.. His library was really intellectual..' is more likely\n","\n","\n","Q: Her face is a crater.: 1. Her face is bumpy. 2. Her face is smooth.\n","model says 'Her face is a crater.. Her face is smooth..' is more likely\n","\n","\n","Q: Her face is an ice rink.: 1. Her face is bumpy. 2. Her face is smooth.\n","model says 'Her face is an ice rink.. Her face is smooth..' is more likely\n","\n","\n","Q: The driver is a lumberjack.: 1. The driver is not careful. 2. The driver is careful.\n","model says 'The driver is a lumberjack.. The driver is careful..' is more likely\n","\n","\n","Q: The driver is a ballerina.: 1. The driver is not careful. 2. The driver is careful.\n","model says 'The driver is a ballerina.. The driver is careful..' is more likely\n","\n","\n","Q: The monkey was a modern edison: 1. The monkey was smart 2. The monkey was dumb\n","model says 'The monkey was a modern edison. The monkey was smart.' is more likely\n","\n","\n","Q: The monkey was a 1st grade dropout: 1. The monkey was smart 2. The monkey was dumb\n","model says 'The monkey was a 1st grade dropout. The monkey was smart.' is more likely\n","\n","\n","Q: She has the conscience of the Pope after having a religious experience: 1. She has a good conscience 2. She has a bad conscience\n","model says 'She has the conscience of the Pope after having a religious experience. She has a good conscience.' is more likely\n","\n","\n","Q: She has the conscience of Hitler on a bad day: 1. She has a good conscience 2. She has a bad conscience\n","model says 'She has the conscience of Hitler on a bad day. She has a good conscience.' is more likely\n","\n","\n","Q: The candy wrapper has the crinkles of an old woman after soaking in a hot tub: 1. The wrapper is very crinkly 2. The wrapper has no crinkles\n","model says 'The candy wrapper has the crinkles of an old woman after soaking in a hot tub. The wrapper has no crinkles.' is more likely\n","\n","\n","Q: The candy wrapper has the crinkles of a celebrity's face after a Botox injection: 1. The wrapper is very crinkly 2. The wrapper has no crinkles\n","model says 'The candy wrapper has the crinkles of a celebrity's face after a Botox injection. The wrapper has no crinkles.' is more likely\n","\n","\n","Q: The microphone is as jumpy as a frog: 1. the microphone is highly sensitive / overpowered. 2. the microphone is highly insensitive / underpowered.\n","model says 'The microphone is as jumpy as a frog. the microphone is highly insensitive / underpowered..' is more likely\n","\n","\n","Q: The microphone is as jumpy as mud: 1. the microphone is highly sensitive / overpowered. 2. the microphone is highly insensitive / underpowered.\n","model says 'The microphone is as jumpy as mud. the microphone is highly insensitive / underpowered..' is more likely\n","\n","\n","Q: The woman is as artistic as a wet mop.: 1. The woman is not artistic. 2. The woman is a wonderful artist.\n","model says 'The woman is as artistic as a wet mop.. The woman is not artistic..' is more likely\n","\n","\n","Q: The woman is as artistic as Van Gogh.: 1. The woman is not artistic. 2. The woman is a wonderful artist.\n","model says 'The woman is as artistic as Van Gogh.. The woman is not artistic..' is more likely\n","\n","\n","Q: The parking lot is a crater.: 1. The parking lot is bumpy. 2. The parking lot is smooth.\n","model says 'The parking lot is a crater.. The parking lot is smooth..' is more likely\n","\n","\n","Q: The parking lot is a sheet of glass.: 1. The parking lot is bumpy. 2. The parking lot is smooth.\n","model says 'The parking lot is a sheet of glass.. The parking lot is smooth..' is more likely\n","\n","\n","Q: The punch hit me with the strength of a marshmallow: 1. The punch is soft 2. The punch is hard\n","model says 'The punch hit me with the strength of a marshmallow. The punch is soft.' is more likely\n","\n","\n","Q: The punch hit me with the strength of a stone: 1. The punch is soft 2. The punch is hard\n","model says 'The punch hit me with the strength of a stone. The punch is soft.' is more likely\n","\n","\n","Q: The wing span of the bird goes on forever: 1. The wings on the bird are large and massive 2. The wings are so small they look like a butterfly's wings.\n","model says 'The wing span of the bird goes on forever. The wings on the bird are large and massive.' is more likely\n","\n","\n","Q: The wing span of the bird is as small as that of a butterfly: 1. The wings on the bird are large and massive 2. The wings are so small they look like a butterfly's wings.\n","model says 'The wing span of the bird is as small as that of a butterfly. The wings on the bird are large and massive.' is more likely\n","\n","\n","Q: Class was as interesting as a wet paper bag.: 1. Class was boring and dull. 2. Class was very inspiring and made me think in a different way.\n","model says 'Class was as interesting as a wet paper bag.. Class was boring and dull..' is more likely\n","\n","\n","Q: Class was so stimulating that I felt reborn.: 1. Class was boring and dull. 2. Class was very inspiring and made me think in a different way.\n","model says 'Class was so stimulating that I felt reborn.. Class was boring and dull..' is more likely\n","\n","\n","Q: his voice was coffee on an early morning.: 1. He had a very soothing voice. 2. His voice was startlingly unpleasant.\n","model says 'his voice was coffee on an early morning.. He had a very soothing voice..' is more likely\n","\n","\n","Q: his voice was an alarm on an early morning.: 1. He had a very soothing voice. 2. His voice was startlingly unpleasant.\n","model says 'his voice was an alarm on an early morning.. He had a very soothing voice..' is more likely\n","\n","\n","Q: Dogs are loyalty and love given life.: 1. Dog wonderful creatures. 2. Dogs are gross creatures.\n","model says 'Dogs are loyalty and love given life.. Dog wonderful creatures..' is more likely\n","\n","\n","Q: Dogs are begging and poop given life.: 1. Dog wonderful creatures. 2. Dogs are gross creatures.\n","model says 'Dogs are begging and poop given life.. Dog wonderful creatures..' is more likely\n","\n","\n","Q: The man was as handsome as a J. Crew model: 1. The man had excellent looks. 2. The man had poor looks.\n","model says 'The man was as handsome as a J. Crew model. The man had excellent looks..' is more likely\n","\n","\n","Q: The man was as handsome as a naked mole rat: 1. The man had excellent looks. 2. The man had poor looks.\n","model says 'The man was as handsome as a naked mole rat. The man had excellent looks..' is more likely\n","\n","\n","Q: His face is a dirt road.: 1. His face is bumpy. 2. His face is smooth.\n","model says 'His face is a dirt road.. His face is smooth..' is more likely\n","\n","\n","Q: His face is a sheet of glass.: 1. His face is bumpy. 2. His face is smooth.\n","model says 'His face is a sheet of glass.. His face is smooth..' is more likely\n","\n","\n","Q: The painter is a demolition derby.: 1. The painter is rough. 2. The painter is careful.\n","model says 'The painter is a demolition derby.. The painter is careful..' is more likely\n","\n","\n","Q: The painter is a surgeon.: 1. The painter is rough. 2. The painter is careful.\n","model says 'The painter is a surgeon.. The painter is rough..' is more likely\n","\n","\n","Q: Matt's girlfriend is a vending machine.: 1. Matt's girlfriend is large. 2. Matt's girlfriend is small.\n","model says 'Matt's girlfriend is a vending machine.. Matt's girlfriend is large..' is more likely\n","\n","\n","Q: Matt's girlfriend is a P.O. Box.: 1. Matt's girlfriend is large. 2. Matt's girlfriend is small.\n","model says 'Matt's girlfriend is a P.O. Box.. Matt's girlfriend is large..' is more likely\n","\n","\n","Q: This table has been made by a Greek God.: 1. The table was well constructed. 2. The table was poorly made.\n","model says 'This table has been made by a Greek God.. The table was well constructed..' is more likely\n","\n","\n","Q: This table has been made by A chimpanzee.: 1. The table was well constructed. 2. The table was poorly made.\n","model says 'This table has been made by A chimpanzee.. The table was well constructed..' is more likely\n","\n","\n","Q: The child's room was a garbage dump: 1. The child's room was messy 2. The child's room was clean\n","model says 'The child's room was a garbage dump. The child's room was clean.' is more likely\n","\n","\n","Q: The child's room was a pre-surgical hospital room: 1. The child's room was messy 2. The child's room was clean\n","model says 'The child's room was a pre-surgical hospital room. The child's room was clean.' is more likely\n","\n","\n","Q: Her mind was a set of broken chairs: 1. Her mind was confused. 2. Her mind was clever.\n","model says 'Her mind was a set of broken chairs. Her mind was confused..' is more likely\n","\n","\n","Q: Her mind was a vintage bookshelf.: 1. Her mind was confused. 2. Her mind was clever.\n","model says 'Her mind was a vintage bookshelf.. Her mind was confused..' is more likely\n","\n","\n","Q: The man approached the project with as much skill as a neurosurgeon: 1. The man brought expert skills to the project. 2. The man brought no skills to the project.\n","model says 'The man approached the project with as much skill as a neurosurgeon. The man brought no skills to the project..' is more likely\n","\n","\n","Q: The man approached the project with as much skill as a middle school student: 1. The man brought expert skills to the project. 2. The man brought no skills to the project.\n","model says 'The man approached the project with as much skill as a middle school student. The man brought no skills to the project..' is more likely\n","\n","\n","Q: The man moved as quickly as a car stuck in traffic: 1. The man moved with no speed at all. 2. The man moved with great speed.\n","model says 'The man moved as quickly as a car stuck in traffic. The man moved with great speed..' is more likely\n","\n","\n","Q: The man moved as quickly as Niagara Falls: 1. The man moved with no speed at all. 2. The man moved with great speed.\n","model says 'The man moved as quickly as Niagara Falls. The man moved with great speed..' is more likely\n","\n","\n","Q: He talked to me like I was going to give him money.: 1. He was really friendly. 2. He was really evasive.\n","model says 'He talked to me like I was going to give him money.. He was really friendly..' is more likely\n","\n","\n","Q: He talked to me like he thought I was going to ask for money.: 1. He was really friendly. 2. He was really evasive.\n","model says 'He talked to me like he thought I was going to ask for money.. He was really friendly..' is more likely\n","\n","\n","Q: That's about as useful as an icecube in a snowstorm.: 1. It's not useful at all. 2. It's very useful.\n","model says 'That's about as useful as an icecube in a snowstorm.. It's very useful..' is more likely\n","\n","\n","Q: That's about as useful as a heated cabin in a snowstorm.: 1. It's not useful at all. 2. It's very useful.\n","model says 'That's about as useful as a heated cabin in a snowstorm.. It's very useful..' is more likely\n","\n","\n","Q: The mattress was soft as granite: 1. The mattress is hard 2. the mattress is soft\n","model says 'The mattress was soft as granite. The mattress is hard.' is more likely\n","\n","\n","Q: The mattress was soft as a cloud: 1. The mattress is hard 2. the mattress is soft\n","model says 'The mattress was soft as a cloud. The mattress is hard.' is more likely\n","\n","\n","Q: The soap smelled like a field of lillies: 1. the soap smelled good 2. the soap smelled bad\n","model says 'The soap smelled like a field of lillies. the soap smelled good.' is more likely\n","\n","\n","Q: The soap smelled like wildebeest dung.: 1. the soap smelled good 2. the soap smelled bad\n","model says 'The soap smelled like wildebeest dung.. the soap smelled good.' is more likely\n","\n","\n","Q: We have all the time of the lifespan of the universe: 1. We have a lot of time 2. We have very little time\n","model says 'We have all the time of the lifespan of the universe. We have very little time.' is more likely\n","\n","\n","Q: We have all the time of the lifespan of a housefly: 1. We have a lot of time 2. We have very little time\n","model says 'We have all the time of the lifespan of a housefly. We have a lot of time.' is more likely\n","\n","\n","Q: The culture has the depth of a kiddie pool.: 1. The culture is superficial. 2. The culture is complex.\n","model says 'The culture has the depth of a kiddie pool.. The culture is complex..' is more likely\n","\n","\n","Q: The culture has the depth of the mariana trench.: 1. The culture is superficial. 2. The culture is complex.\n","model says 'The culture has the depth of the mariana trench.. The culture is complex..' is more likely\n","\n","\n","Q: The road is a bed of rocks.: 1. The road is bumpy. 2. The road is smooth.\n","model says 'The road is a bed of rocks.. The road is smooth..' is more likely\n","\n","\n","Q: The road is an ice rink.: 1. The road is bumpy. 2. The road is smooth.\n","model says 'The road is an ice rink.. The road is smooth..' is more likely\n","\n","\n","Q: The yogurt was like onion ring batter: 1. The yogurt was thick. 2. The yogurt was thin.\n","model says 'The yogurt was like onion ring batter. The yogurt was thick..' is more likely\n","\n","\n","Q: The yogurt was like mist: 1. The yogurt was thick. 2. The yogurt was thin.\n","model says 'The yogurt was like mist. The yogurt was thick..' is more likely\n","\n","\n","Q: Masonite siding on houses repels water as well as a sponge: 1. Masonite siding soaks up water 2. Masonite is water repellant\n","model says 'Masonite siding on houses repels water as well as a sponge. Masonite is water repellant.' is more likely\n","\n","\n","Q: Masonite siding on houses repels water as well as a raincoat: 1. Masonite siding soaks up water 2. Masonite is water repellant\n","model says 'Masonite siding on houses repels water as well as a raincoat. Masonite is water repellant.' is more likely\n","\n","\n","Q: Their culture has the openness of a meadow: 1. The culture is very open and tolerant 2. The culture is not open or tolerant\n","model says 'Their culture has the openness of a meadow. The culture is not open or tolerant.' is more likely\n","\n","\n","Q: Their culture has the openness of a closet: 1. The culture is very open and tolerant 2. The culture is not open or tolerant\n","model says 'Their culture has the openness of a closet. The culture is not open or tolerant.' is more likely\n","\n","\n","Q: The woman has the shallowness of a bucket: 1. She is very shallow 2. She is not very shallow\n","model says 'The woman has the shallowness of a bucket. She is very shallow.' is more likely\n","\n","\n","Q: The woman has the shallowness of the ocean: 1. She is very shallow 2. She is not very shallow\n","model says 'The woman has the shallowness of the ocean. She is very shallow.' is more likely\n","\n","\n","overall accuracy: \n","0.494\n","confusion matrix: \n","correct forward 253 wrong forward 247 correct backward 251 wrong_backward 249\n"]}],"source":["out_df, preds, labels = evaluate_model(model, tokenizer, subset_test_dataset, score_type=\"loss\")\n","compute_stats(out_df, preds, labels)\n"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"elapsed":730,"status":"error","timestamp":1697050857235,"user":{"displayName":"gvvvbjj ffbkitb","userId":"08953530729188044176"},"user_tz":-120},"id":"CT6WPDE6HPVF","outputId":"23af5e67-f473-4ae6-bc98-fcf65a3dc305"},"outputs":[{"ename":"ZeroDivisionError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-c9b485a368a5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset_test_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcompute_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-47-0e100743a412>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, tokenizer, test_set, middle_phrase, use_prefix, verbose, score_type, use_cuda, return_acc)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mP_x_1_y_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mP_x_1_y_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mP_x_1_correct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscore2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"]}],"source":["out_df, preds, labels = evaluate_model(model, tokenizer, subset_test_dataset)\n","compute_stats(out_df, preds, labels)\n"]},{"cell_type":"markdown","metadata":{"id":"zjN5FCH1J8Up"},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOIgzfyLC4J3ZSvRJS1Txn6","collapsed_sections":["hnl88B6s0WLq"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"002859109910485c8f28080ad763086b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0423a515af344236b0263c86e7f59e14":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"089172e6835a460fac915e13ee4661e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_419f1a11c0294059b79e11c7f5cafdc2","IPY_MODEL_d4d3c823a8584f09bdc561f9bc3f107a","IPY_MODEL_c03bd5d3e0f44200bfa621907204e486"],"layout":"IPY_MODEL_d7feffc945e040ef809fbbaceb354615"}},"090cfbf845eb4b0f9e59fcc7b401f9bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0da7bbb40a914bb5beb3b4cf970caedf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ee27c6705f24f46bee5c713f31c9915":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_445b09e5ce53442d9be9a880c44de7d4","placeholder":"​","style":"IPY_MODEL_a74ed066624340dab8e663a4720e0d96","value":" 1.40k/1.40k [00:00&lt;00:00, 52.3kB/s]"}},"18d821832ff943acb81042e53f1a8b15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2b3cc9e2ea449b7a9ef1773ae416cda","IPY_MODEL_a04b9d28063341b880d8b41862ccac5b","IPY_MODEL_0ee27c6705f24f46bee5c713f31c9915"],"layout":"IPY_MODEL_df841ecb03d240668b5908ca2417bce7"}},"191500a57b204bc7a4447b7feed83d9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e3df34a74dd4965baf4eda82f9894df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23987df4304e4bdb893c174feacbd502":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"338d953d031740759d3fbce10fde164f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36bc0510dd4d4046b3318dfecdec02cd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"391bf6451aca4aceb80c3380bc8e838f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e25d44e49e94ea0a24550ab289ec3ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e562c723b8044e89d4fc216cb766618":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"419f1a11c0294059b79e11c7f5cafdc2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56526590bff74160903e9d2b59d70d3d","placeholder":"​","style":"IPY_MODEL_7ffdca088b314776b11662ce2cf05042","value":"Downloading spiece.model: 100%"}},"445b09e5ce53442d9be9a880c44de7d4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"499f6d8a64ef46aa981d907dfbdf4634":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a28d2ee9adb40a996e0442032a9dfa8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cdd3992ef194731a58e0434d6fef13f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d1828b0442540a4a1a3e81a62f47496":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23987df4304e4bdb893c174feacbd502","placeholder":"​","style":"IPY_MODEL_cac799e0dd114080a80109300f2fd898","value":"Downloading (…)cial_tokens_map.json: 100%"}},"4dc349300b4b49fd9cf8f469561e495a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f7e899147c24f87b3cef008335c982b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_090cfbf845eb4b0f9e59fcc7b401f9bc","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53085247ec3f478bafdadefa3df37a69","value":147}},"4f7e94fd47294ca587fac6ed4def3f91":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53085247ec3f478bafdadefa3df37a69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"55af7f5dc9c54380991d2a49f90c6e1d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e3df34a74dd4965baf4eda82f9894df","max":2424064,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0da7bbb40a914bb5beb3b4cf970caedf","value":2424064}},"56526590bff74160903e9d2b59d70d3d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56c10f6eafe14ad8a3816c2907782a51":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d1bbeeeca3542cfa314c77edfd32c2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5d2abec5863e45aab0a5379a9091f319":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61e56244890d44a3bc9d5b8ba5d4c85a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62b8ec06283142c08eaad7890bffdfab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"667e715e6708430997c333054794d301":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b616c754e074617b569c2e69ca69671":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d22fbfec8334fe890e35e60224b7ef3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_724d461bfd264b02ac97d8e9be0b17cc","placeholder":"​","style":"IPY_MODEL_3e25d44e49e94ea0a24550ab289ec3ed","value":" 990M/990M [00:09&lt;00:00, 99.4MB/s]"}},"70d40c165c4943e0a0df89fd84c4c576":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cec043cb9a144e4f92d2629e671e16b2","IPY_MODEL_f8c64b0aebf44360bba893487fd20307","IPY_MODEL_dc08843021dd48acb698835e4bd56a52"],"layout":"IPY_MODEL_191500a57b204bc7a4447b7feed83d9f"}},"724d461bfd264b02ac97d8e9be0b17cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ffdca088b314776b11662ce2cf05042":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85a7e86998624deab1f08b115d165bf7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"86a177ce1f71411ea4ff1a66cc1dbc70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87d84206fbe844cfb397b11408a01e4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91de9c438b3947f9a4e4b35bf3ff06a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d84575b9a4814bf6924cedb17a5fdebe","max":990345061,"min":0,"orientation":"horizontal","style":"IPY_MODEL_391bf6451aca4aceb80c3380bc8e838f","value":990345061}},"97a6015603d3448ca61eb7029e01a2e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff6fc5ae2a0a4f749a93e9bd19903d28","placeholder":"​","style":"IPY_MODEL_3e562c723b8044e89d4fc216cb766618","value":" 147/147 [00:00&lt;00:00, 2.70kB/s]"}},"a04b9d28063341b880d8b41862ccac5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_36bc0510dd4d4046b3318dfecdec02cd","max":1404,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d1bbeeeca3542cfa314c77edfd32c2b","value":1404}},"a2ea31659d9c4b3f99953c21830a8ebf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d1828b0442540a4a1a3e81a62f47496","IPY_MODEL_b0307975789e45c89c1cd6eeeafd0c1c","IPY_MODEL_dbf692fafc0c4000b9b67f8c00c71a6d"],"layout":"IPY_MODEL_338d953d031740759d3fbce10fde164f"}},"a3b012607ba745dba08e0ede1ac7dadf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a74ed066624340dab8e663a4720e0d96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7ab3185abb745f58d841ebf7c3f31b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc5c4d2eee714a8482bde0a6109ba300","placeholder":"​","style":"IPY_MODEL_499f6d8a64ef46aa981d907dfbdf4634","value":"Downloading (…)neration_config.json: 100%"}},"aa171d9eeaf8473bb929b505dfe67320":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"adb0608c055e47ef9f00909c9cdd5a5d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0307975789e45c89c1cd6eeeafd0c1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61e56244890d44a3bc9d5b8ba5d4c85a","max":2201,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aa171d9eeaf8473bb929b505dfe67320","value":2201}},"b20cc5fd379643efabebef42ffd49e7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6477e8529a7435ca7fb2affe865d200","IPY_MODEL_91de9c438b3947f9a4e4b35bf3ff06a4","IPY_MODEL_6d22fbfec8334fe890e35e60224b7ef3"],"layout":"IPY_MODEL_4a28d2ee9adb40a996e0442032a9dfa8"}},"b2b3cc9e2ea449b7a9ef1773ae416cda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e334478e7aa94f24afb967ead2747179","placeholder":"​","style":"IPY_MODEL_6b616c754e074617b569c2e69ca69671","value":"Downloading (…)lve/main/config.json: 100%"}},"b8d77e05cdb549349d8046a4500a1684":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_edddccf7bcf24b92ad4b3f75ab241e97","IPY_MODEL_55af7f5dc9c54380991d2a49f90c6e1d","IPY_MODEL_c826b981fc5b40ffb3f894d1ba5dbed1"],"layout":"IPY_MODEL_cdbc3b25bb9a408a95aa0d3c3a10858b"}},"bc5c4d2eee714a8482bde0a6109ba300":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf32282753f84223b5e567d273ab18cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c03bd5d3e0f44200bfa621907204e486":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecc4da78df434380aba28b160abe6817","placeholder":"​","style":"IPY_MODEL_adb0608c055e47ef9f00909c9cdd5a5d","value":" 792k/792k [00:00&lt;00:00, 6.38MB/s]"}},"c826b981fc5b40ffb3f894d1ba5dbed1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f7e94fd47294ca587fac6ed4def3f91","placeholder":"​","style":"IPY_MODEL_86a177ce1f71411ea4ff1a66cc1dbc70","value":" 2.42M/2.42M [00:00&lt;00:00, 10.6MB/s]"}},"cac799e0dd114080a80109300f2fd898":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cdb88dc0478440a283bf98dbf71abeda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7ab3185abb745f58d841ebf7c3f31b1","IPY_MODEL_4f7e899147c24f87b3cef008335c982b","IPY_MODEL_97a6015603d3448ca61eb7029e01a2e9"],"layout":"IPY_MODEL_4cdd3992ef194731a58e0434d6fef13f"}},"cdbc3b25bb9a408a95aa0d3c3a10858b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cec043cb9a144e4f92d2629e671e16b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0423a515af344236b0263c86e7f59e14","placeholder":"​","style":"IPY_MODEL_87d84206fbe844cfb397b11408a01e4e","value":"Downloading (…)okenizer_config.json: 100%"}},"d4d3c823a8584f09bdc561f9bc3f107a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_667e715e6708430997c333054794d301","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85a7e86998624deab1f08b115d165bf7","value":791656}},"d6477e8529a7435ca7fb2affe865d200":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62b8ec06283142c08eaad7890bffdfab","placeholder":"​","style":"IPY_MODEL_5d2abec5863e45aab0a5379a9091f319","value":"Downloading model.safetensors: 100%"}},"d7feffc945e040ef809fbbaceb354615":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d84575b9a4814bf6924cedb17a5fdebe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbf692fafc0c4000b9b67f8c00c71a6d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4dc349300b4b49fd9cf8f469561e495a","placeholder":"​","style":"IPY_MODEL_ebf79df9339341aa8ddc6b8a9eaec2c6","value":" 2.20k/2.20k [00:00&lt;00:00, 78.8kB/s]"}},"dc08843021dd48acb698835e4bd56a52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56c10f6eafe14ad8a3816c2907782a51","placeholder":"​","style":"IPY_MODEL_bf32282753f84223b5e567d273ab18cb","value":" 2.54k/2.54k [00:00&lt;00:00, 51.4kB/s]"}},"df841ecb03d240668b5908ca2417bce7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e334478e7aa94f24afb967ead2747179":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5795608e20b444aa01d7c3475a77deb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebf79df9339341aa8ddc6b8a9eaec2c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecc4da78df434380aba28b160abe6817":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edddccf7bcf24b92ad4b3f75ab241e97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3b012607ba745dba08e0ede1ac7dadf","placeholder":"​","style":"IPY_MODEL_002859109910485c8f28080ad763086b","value":"Downloading (…)/main/tokenizer.json: 100%"}},"eeeb31234ea64cad9c795ecbd22a2b9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8c64b0aebf44360bba893487fd20307":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5795608e20b444aa01d7c3475a77deb","max":2537,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eeeb31234ea64cad9c795ecbd22a2b9a","value":2537}},"ff6fc5ae2a0a4f749a93e9bd19903d28":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
