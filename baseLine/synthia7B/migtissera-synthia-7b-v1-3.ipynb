{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"e585dc4361fc4f5c9f395e14c92c1ca0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc54e89c06f549759a55e7c3db9e3501","IPY_MODEL_757c2d29a718400ea309acdb3e8e5113","IPY_MODEL_11b8af75eedc4482866a222372219815"],"layout":"IPY_MODEL_9dbc05f106ae48a79f74f7fdcce64dae"}},"fc54e89c06f549759a55e7c3db9e3501":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_001925813a8044e0a73b759d787db5ff","placeholder":"​","style":"IPY_MODEL_19448306978749d39a1e08d6b55082dc","value":"Downloading pytorch_model.bin: 100%"}},"757c2d29a718400ea309acdb3e8e5113":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_42b28bb1abb349b481aa99d10852f478","max":2836623617,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8788661831d343e491c23cef0849a688","value":2836623617}},"11b8af75eedc4482866a222372219815":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5596352cfa7465f87dd5e6732ba7cae","placeholder":"​","style":"IPY_MODEL_219f98fc7e0b4ab296fc914bb679b956","value":" 2.84G/2.84G [00:26&lt;00:00, 135MB/s]"}},"9dbc05f106ae48a79f74f7fdcce64dae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"001925813a8044e0a73b759d787db5ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19448306978749d39a1e08d6b55082dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42b28bb1abb349b481aa99d10852f478":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8788661831d343e491c23cef0849a688":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c5596352cfa7465f87dd5e6732ba7cae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"219f98fc7e0b4ab296fc914bb679b956":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f84b48669ef4049bdd40a540f2529f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c559a294d33742e390116907662f0abb","IPY_MODEL_cc229d3e170242a7b9b3a21567d83818","IPY_MODEL_062d0521aa0a4ca98ee983eefd65506f"],"layout":"IPY_MODEL_23d4e2d8daa440bdb37e7c2ebdc5db02"}},"c559a294d33742e390116907662f0abb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f947befc04d442aea7dfb25613bd9939","placeholder":"​","style":"IPY_MODEL_7c51c6f5d1344354963f811bf9a3bc06","value":"Downloading (…)neration_config.json: 100%"}},"cc229d3e170242a7b9b3a21567d83818":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d957b3a701084f8aafb9102a6238788c","max":69,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2864b5ed0a2d4955a83cbf6618e8af96","value":69}},"062d0521aa0a4ca98ee983eefd65506f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75c42ef8bd2b4b7fa72fd4803af9a603","placeholder":"​","style":"IPY_MODEL_13a0c04afa044ee1a122ecd6ff240e7f","value":" 69.0/69.0 [00:00&lt;00:00, 4.94kB/s]"}},"23d4e2d8daa440bdb37e7c2ebdc5db02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f947befc04d442aea7dfb25613bd9939":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c51c6f5d1344354963f811bf9a3bc06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d957b3a701084f8aafb9102a6238788c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2864b5ed0a2d4955a83cbf6618e8af96":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75c42ef8bd2b4b7fa72fd4803af9a603":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13a0c04afa044ee1a122ecd6ff240e7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98351baf42934fe5b7524b3b64accbd8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d0671ee3f234656b8a2627389e07e9d","IPY_MODEL_15b50e5a174a40c3b7c0dd24943b80c0","IPY_MODEL_41f80043500046d79f105206a1c91610"],"layout":"IPY_MODEL_737604363ab84acab1980304dfae18b7"}},"3d0671ee3f234656b8a2627389e07e9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d5ce9cf72a741508b0044e9d36b36f9","placeholder":"​","style":"IPY_MODEL_5fc16426f4c04d54acc2f2e0457a6416","value":"Downloading readme: 100%"}},"15b50e5a174a40c3b7c0dd24943b80c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e690820d66e4416ba819ebbef9f2909e","max":5554,"min":0,"orientation":"horizontal","style":"IPY_MODEL_42716af8d24146c4b29393ddc2dc6a8a","value":5554}},"41f80043500046d79f105206a1c91610":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03421596b8f343eaafd392d951860431","placeholder":"​","style":"IPY_MODEL_71eda188275c493b89b4a2dcdbf3f336","value":" 5.55k/5.55k [00:00&lt;00:00, 169kB/s]"}},"737604363ab84acab1980304dfae18b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d5ce9cf72a741508b0044e9d36b36f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fc16426f4c04d54acc2f2e0457a6416":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e690820d66e4416ba819ebbef9f2909e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42716af8d24146c4b29393ddc2dc6a8a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"03421596b8f343eaafd392d951860431":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71eda188275c493b89b4a2dcdbf3f336":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e3dc5d6c0b540ccb7f7afa134e43dcf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf463801021a47f284c7e0d3acfc8d63","IPY_MODEL_3e763d4588cd492baf6f5dcfbab241cc","IPY_MODEL_3c093130754d4825b2d1772e7ae1f2ae"],"layout":"IPY_MODEL_c50c4ada3b8f46429028c0fb11bb856a"}},"cf463801021a47f284c7e0d3acfc8d63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24abc37e54ba41669611b618d77b332d","placeholder":"​","style":"IPY_MODEL_bc02bb96ad494682a4443818bf9e2b36","value":"Downloading data files: 100%"}},"3e763d4588cd492baf6f5dcfbab241cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_32c4670df43042e9b5258bf33dff8c7e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d4bb2ee46b2c489e954139c44fc9a192","value":1}},"3c093130754d4825b2d1772e7ae1f2ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4748ce5b31647e3ad85c750a7862e49","placeholder":"​","style":"IPY_MODEL_010e9589a46941dd83eb4cac8770a626","value":" 1/1 [00:00&lt;00:00,  2.95it/s]"}},"c50c4ada3b8f46429028c0fb11bb856a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24abc37e54ba41669611b618d77b332d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc02bb96ad494682a4443818bf9e2b36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32c4670df43042e9b5258bf33dff8c7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4bb2ee46b2c489e954139c44fc9a192":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4748ce5b31647e3ad85c750a7862e49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"010e9589a46941dd83eb4cac8770a626":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3286bad3a57445e9a41b81ea027e631d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72abdfd49b8e4960b22d25e0615b6a6c","IPY_MODEL_76377837c9e346efaf05625d9ec9782d","IPY_MODEL_968a0fcf5fad48028404e342f677e664"],"layout":"IPY_MODEL_33e0587bb0b24accb05c16cc02d75b3d"}},"72abdfd49b8e4960b22d25e0615b6a6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7c0ccb695a64e6ba4bc08de65ac7739","placeholder":"​","style":"IPY_MODEL_c19ffd16e845410bbe563cecb1b3d612","value":"Downloading data: 100%"}},"76377837c9e346efaf05625d9ec9782d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a88eec22474455d80a541f1afc10dd6","max":646739,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cff47dc83ead4436903d9b651b9b4649","value":646739}},"968a0fcf5fad48028404e342f677e664":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5967538111e4487b8a49e40189f97c31","placeholder":"​","style":"IPY_MODEL_b464aa7530da497791ce86ae00bdc07e","value":" 647k/647k [00:00&lt;00:00, 2.11MB/s]"}},"33e0587bb0b24accb05c16cc02d75b3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7c0ccb695a64e6ba4bc08de65ac7739":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c19ffd16e845410bbe563cecb1b3d612":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a88eec22474455d80a541f1afc10dd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cff47dc83ead4436903d9b651b9b4649":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5967538111e4487b8a49e40189f97c31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b464aa7530da497791ce86ae00bdc07e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a18b440ce6fe49f68a92cac0f0e1c2fb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5f394fcda1fd4f39957d14a5c4caa631","IPY_MODEL_06352b37a3de45199d28f0710e31742f","IPY_MODEL_9408db961369449a9f1716a185ac6e7d"],"layout":"IPY_MODEL_1ab6fddb871b4889bad1850aeb911e42"}},"5f394fcda1fd4f39957d14a5c4caa631":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d3cdf0730754282af4d57e8db5aef80","placeholder":"​","style":"IPY_MODEL_6fc4c705d1214cc193bf64963121e81b","value":"Extracting data files: 100%"}},"06352b37a3de45199d28f0710e31742f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fcdf6c2ce5f4dcdb97e270d25d08a0d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7cdf6b8039e1414ca97892214106a41d","value":1}},"9408db961369449a9f1716a185ac6e7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2bcfde8fbc1462b9a7f2334f592e615","placeholder":"​","style":"IPY_MODEL_ccc72c8249a04775b61d24a9edf914f9","value":" 1/1 [00:00&lt;00:00, 37.26it/s]"}},"1ab6fddb871b4889bad1850aeb911e42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d3cdf0730754282af4d57e8db5aef80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fc4c705d1214cc193bf64963121e81b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9fcdf6c2ce5f4dcdb97e270d25d08a0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cdf6b8039e1414ca97892214106a41d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f2bcfde8fbc1462b9a7f2334f592e615":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccc72c8249a04775b61d24a9edf914f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9bbfdae62be4fb9a4343c3dfd2c557a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d2c2407dec094aef82681b44ec2e3d2f","IPY_MODEL_9e8a6ae9602f48dbb83083b72ca53e1d","IPY_MODEL_899f4a2877e949b6a2117b81c9aed8a5"],"layout":"IPY_MODEL_60a2c67412904f369f8c046ab8ca29e2"}},"d2c2407dec094aef82681b44ec2e3d2f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f99b02cc6f1149c08fadf7959c5c2685","placeholder":"​","style":"IPY_MODEL_fb8017a9dccb4103a6e4a012053e0fec","value":"Generating train split: "}},"9e8a6ae9602f48dbb83083b72ca53e1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_96d68d033c774137a3db337e978d83a5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_990018b5851242c2a93a39761cd44e8c","value":1}},"899f4a2877e949b6a2117b81c9aed8a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02676ed015414b7bad8f234881fd1fe7","placeholder":"​","style":"IPY_MODEL_13bfd884d21e4579855fc8acf09533a8","value":" 2508/0 [00:00&lt;00:00, 48879.07 examples/s]"}},"60a2c67412904f369f8c046ab8ca29e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f99b02cc6f1149c08fadf7959c5c2685":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb8017a9dccb4103a6e4a012053e0fec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96d68d033c774137a3db337e978d83a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"990018b5851242c2a93a39761cd44e8c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"02676ed015414b7bad8f234881fd1fe7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13bfd884d21e4579855fc8acf09533a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6df57c6325c74747be601eb8b75d1dd5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5fef097a0cbe41d2bd7a33e694a82b5a","IPY_MODEL_426040f036ac497d83a8af02a1a26a63","IPY_MODEL_b3af7e680e6645a496bd0b4a48776fbb"],"layout":"IPY_MODEL_01f89584ce88486d9405e71c14817b37"}},"5fef097a0cbe41d2bd7a33e694a82b5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b743164f8184e0cafc84c9883d8729d","placeholder":"​","style":"IPY_MODEL_388e42c3747c44fe95febfb0a495982a","value":"Map: 100%"}},"426040f036ac497d83a8af02a1a26a63":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_31fa3a0b8ff84732aaa2ed4032373a4b","max":2508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0016ad3003c0499fb29df618377d5632","value":2508}},"b3af7e680e6645a496bd0b4a48776fbb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_680f8d845c0646b090e13fa5b25ae971","placeholder":"​","style":"IPY_MODEL_f7f5cabdccc84b3b83f9d93e5e03a5c0","value":" 2508/2508 [00:00&lt;00:00, 4393.26 examples/s]"}},"01f89584ce88486d9405e71c14817b37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b743164f8184e0cafc84c9883d8729d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"388e42c3747c44fe95febfb0a495982a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31fa3a0b8ff84732aaa2ed4032373a4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0016ad3003c0499fb29df618377d5632":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"680f8d845c0646b090e13fa5b25ae971":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7f5cabdccc84b3b83f9d93e5e03a5c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# `transformers` meets `bitsandbytes` for democratzing Large Language Models (LLMs) through 4bit quantization\n\n<center>\n<img src=\"https://github.com/huggingface/blog/blob/main/assets/96_hf_bitsandbytes_integration/Thumbnail_blue.png?raw=true\" alt=\"drawing\" width=\"700\" class=\"center\"/>\n</center>\n\nWelcome to this notebook that goes through the recent `bitsandbytes` integration that includes the work from XXX that introduces no performance degradation 4bit quantization techniques, for democratizing LLMs inference and training.\n\nIn this notebook, we will learn together how to load a large model in 4bit (`gpt-neo-x-20b`) and train it using Google Colab and PEFT library from Hugging Face 🤗.\n\n[In the general usage notebook](https://colab.research.google.com/drive/1ge2F1QSK8Q7h0hn3YKuBCOAS0bK8E0wf?usp=sharing), you can learn how to propely load a model in 4bit with all its variants.\n\nIf you liked the previous work for integrating [*LLM.int8*](https://arxiv.org/abs/2208.07339), you can have a look at the [introduction blogpost](https://huggingface.co/blog/hf-bitsandbytes-integration) to lean more about that quantization method.\n","metadata":{"id":"XIyP_0r6zuVc"}},{"cell_type":"code","source":"!pip uninstall datasets -y\n!pip install datasets","metadata":{"id":"cheX4_C2xz2X","colab":{"base_uri":"https://localhost:8080/"},"outputId":"51ff543c-882d-45a4-e755-2d485ba80717","execution":{"iopub.status.busy":"2023-10-06T21:30:18.500321Z","iopub.execute_input":"2023-10-06T21:30:18.501102Z","iopub.status.idle":"2023-10-06T21:30:32.455684Z","shell.execute_reply.started":"2023-10-06T21:30:18.501071Z","shell.execute_reply":"2023-10-06T21:30:32.454638Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Found existing installation: datasets 2.1.0\nUninstalling datasets-2.1.0:\n  Successfully uninstalled datasets-2.1.0\nCollecting datasets\n  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nCollecting fsspec[http]<2023.9.0,>=2023.1.0 (from datasets)\n  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nInstalling collected packages: fsspec, datasets\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2023.9.0\n    Uninstalling fsspec-2023.9.0:\n      Successfully uninstalled fsspec-2023.9.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ns3fs 2023.9.0 requires fsspec==2023.9.0, but you have fsspec 2023.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.14.5 fsspec-2023.6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install sentencepiece","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nlFxRGVGybOu","outputId":"f92f2906-456b-44cf-9b33-ccc485c3c835","execution":{"iopub.status.busy":"2023-10-04T13:05:30.808012Z","iopub.execute_input":"2023-10-04T13:05:30.809285Z","iopub.status.idle":"2023-10-04T13:05:41.968960Z","shell.execute_reply.started":"2023-10-04T13:05:30.809252Z","shell.execute_reply":"2023-10-04T13:05:41.967851Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"Collecting sentencepiece\n\n  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hInstalling collected packages: sentencepiece\n\nSuccessfully installed sentencepiece-0.1.99\n"}]},{"cell_type":"code","source":"!pip install -q -U transformers","metadata":{"id":"hfgefLMDylI9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"07fa79e1-55d1-411e-cfc3-a3451ef43ddb","execution":{"iopub.status.busy":"2023-10-04T13:05:41.970760Z","iopub.execute_input":"2023-10-04T13:05:41.971164Z","iopub.status.idle":"2023-10-04T13:05:59.275128Z","shell.execute_reply.started":"2023-10-04T13:05:41.971128Z","shell.execute_reply":"2023-10-04T13:05:59.273889Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25h"}]},{"cell_type":"code","source":"!pip install -q -U bitsandbytes\n!pip install -q -U git+https://github.com/huggingface/transformers.git\n!pip install -q -U git+https://github.com/huggingface/peft.git\n!pip install -q -U git+https://github.com/huggingface/accelerate.git\n!pip install -q datasets","metadata":{"id":"FuXIFTFapAMI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0a60b09e-966b-47f5-9276-08a9134a71cd","execution":{"iopub.status.busy":"2023-10-06T21:30:51.556254Z","iopub.execute_input":"2023-10-06T21:30:51.556604Z","iopub.status.idle":"2023-10-06T21:32:27.269629Z","shell.execute_reply.started":"2023-10-06T21:30:51.556556Z","shell.execute_reply":"2023-10-06T21:32:27.268225Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"id":"ddJWcW-y3suD","execution":{"iopub.status.busy":"2023-10-06T21:30:32.458399Z","iopub.execute_input":"2023-10-06T21:30:32.458750Z","iopub.status.idle":"2023-10-06T21:30:33.549514Z","shell.execute_reply.started":"2023-10-06T21:30:32.458709Z","shell.execute_reply":"2023-10-06T21:30:33.548683Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"First let's load the model we are going to use - GPT-neo-x-20B! Note that the model itself is around 40GB in half precision","metadata":{"id":"MJ-5idQwzvg-"}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nmodel_id = \"migtissera/SynthIA-7B-v1.3\"\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})","metadata":{"id":"E0Nl5mWL0k2T","colab":{"base_uri":"https://localhost:8080/","height":262,"referenced_widgets":["e585dc4361fc4f5c9f395e14c92c1ca0","fc54e89c06f549759a55e7c3db9e3501","757c2d29a718400ea309acdb3e8e5113","11b8af75eedc4482866a222372219815","9dbc05f106ae48a79f74f7fdcce64dae","001925813a8044e0a73b759d787db5ff","19448306978749d39a1e08d6b55082dc","42b28bb1abb349b481aa99d10852f478","8788661831d343e491c23cef0849a688","c5596352cfa7465f87dd5e6732ba7cae","219f98fc7e0b4ab296fc914bb679b956","6f84b48669ef4049bdd40a540f2529f0","c559a294d33742e390116907662f0abb","cc229d3e170242a7b9b3a21567d83818","062d0521aa0a4ca98ee983eefd65506f","23d4e2d8daa440bdb37e7c2ebdc5db02","f947befc04d442aea7dfb25613bd9939","7c51c6f5d1344354963f811bf9a3bc06","d957b3a701084f8aafb9102a6238788c","2864b5ed0a2d4955a83cbf6618e8af96","75c42ef8bd2b4b7fa72fd4803af9a603","13a0c04afa044ee1a122ecd6ff240e7f"]},"outputId":"62648f23-282b-43ac-e123-94e1dea6a730","execution":{"iopub.status.busy":"2023-10-06T21:32:27.273763Z","iopub.execute_input":"2023-10-06T21:32:27.274164Z","iopub.status.idle":"2023-10-06T22:02:21.737565Z","shell.execute_reply.started":"2023-10-06T21:32:27.274126Z","shell.execute_reply":"2023-10-06T22:02:21.736636Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/915 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cccf0f7e51a4afbb308d342a06a2567"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3109130623094f3ba9289f1d09cda97d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d094cdcb9c24681845d1617c83d3f00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0258c6f5673b4599b2104bd62b029962"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85b019ffc3fa4142bd875703e198615a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c91edc3b25e848c986810ab8b1488cbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba178185937b4f7b94dc165aed4af239"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"506930ffec7442019c73f2c3df1ea1a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4e28b6031614f4294ae4fd5973e91b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c37819cff46944169704b858b1490b41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2136bdc3f19641b490ad7e539eefd109"}},"metadata":{}}]},{"cell_type":"markdown","source":"Then we have to apply some preprocessing to the model to prepare it for training. For that use the `prepare_model_for_kbit_training` method from PEFT.","metadata":{"id":"Mp2gMi1ZzGET"}},{"cell_type":"markdown","source":"## Metaphor Probabilities (zero-shot) for the pretrained model","metadata":{"id":"9cx78s7wxz2a"}},{"cell_type":"code","source":"import numpy as np\nfrom scipy.special import softmax\nimport pdb\nimport pandas as pd\nimport math\nfrom typing import List\nimport random\nimport argparse\nimport torch\n\n\ndef sent_scoring(model_tokenizer, text, cuda, score_type=\"loss\", output_attentions=False, length_normalize=False):\n    model = model_tokenizer[0]\n    tokenizer = model_tokenizer[1]\n    assert model is not None\n    assert tokenizer is not None\n    encoded_text = tokenizer.encode(text)\n    input_ids = torch.tensor(encoded_text).unsqueeze(0)\n    if cuda:\n        input_ids = input_ids.to('cuda')\n    with torch.no_grad():\n        outputs = model(input_ids, labels=input_ids, output_attentions=output_attentions)\n    loss, logits = outputs[:2]\n\n    sentence_prob = loss.item()\n    if score_type == \"prob\":\n        if length_normalize:\n            mult = 2\n        else:\n            mult = len(encoded_text)\n\n        sentence_prob = math.exp(-1.0 * loss * (mult - 1))\n\n    if output_attentions:\n        attn = outputs[\"attentions\"]\n        return sentence_prob, attn, input_ids\n\n    return sentence_prob\n\ndef confusion_matrix(P_forward_1, P_forward_2, P_backward_1, P_backward_2):\n    correct_forward = len(np.where(np.array(P_forward_1) >= 0.5)[0]) + len(np.where(np.array(P_forward_2) >=0.5)[0])\n    wrong_forward = len(P_forward_1) + len(P_forward_2) - correct_forward\n\n    correct_backward = len(np.where(np.array(P_backward_1) >= 0.5)[0]) + len(np.where(np.array(P_backward_2) >=0.5)[0])\n    wrong_backward = len(P_backward_1) + len(P_backward_2) - correct_backward\n\n    print(\"correct forward\", correct_forward, \"wrong forward\", wrong_forward, \"correct backward\", correct_backward, \"wrong_backward\", wrong_backward)\n\n    results = {\n        \"correct_forward\": correct_forward,\n        \"wrong_forward\": wrong_forward,\n        \"correct_backward\": correct_backward,\n        \"wrong_backward\": wrong_backward\n    }\n\n    return results\n\nfrom tqdm import tqdm\n\ndef evaluate_model(model, tokenizer, test_set, middle_phrase=\"\", use_prefix=0, verbose=True, score_type=\"prob\", use_cuda=False, return_acc=False, total = 1094) -> tuple:\n    preds = []\n    labels = []\n    x_1 = []\n    x_2 = []\n    y_1 = []\n    y_2 = []\n    P_x_1 = []\n    P_x_2 = []\n    P_y_1 = []\n    P_y_2 = []\n    P_x_1_y_1 = []\n    P_x_1_y_2 = []\n    P_x_2_y_1 = []\n    P_x_2_y_2 = []\n    P_x_1_correct = []\n    P_x_2_correct = []\n    P_y_1_correct = []\n    P_y_2_correct = []\n    correct = 0\n\n    for i, metaphor_data in tqdm(enumerate(test_set), total = total):\n        ctx, p1, p2 = metaphor_data[\"startphrase\"], metaphor_data[\"ending1\"], metaphor_data[\"ending2\"]\n        labels.append(int(metaphor_data[\"labels\"]))\n        if use_prefix > 0:\n            prefix_prompt = select_prefix_prompts(prompt_file, use_prefix) if use_prefix else \"\"\n        else:\n            prefix_prompt = \"\"\n\n        sent1 = prefix_prompt + ctx + \". \" + middle_phrase + p1 + \".\"\n        sent2 = prefix_prompt + ctx + \". \" + middle_phrase + p2 + \".\"\n\n        score1 = sent_scoring((model, tokenizer), sent1, use_cuda, score_type=score_type)\n        score2 = sent_scoring((model, tokenizer), sent2, use_cuda, score_type=score_type)\n\n        if score_type == \"loss\":\n            pred = 0 if score1 < score2 else 1\n        else:\n            pred = 1 if score1 < score2 else 0\n\n        pred_sent = sent1 if pred == 0 else sent2\n\n        if i % 2 == 0:\n            x_1.append(ctx)\n            x_1_score = sent_scoring((model, tokenizer), ctx + \".\", use_cuda, score_type=score_type)\n            P_x_1.append(x_1_score)\n            y_1.append(p1)\n            y_2.append(p2)\n            y1_score = sent_scoring((model, tokenizer), p1 + \".\", use_cuda, score_type=score_type)\n            y2_score = sent_scoring((model, tokenizer), p2 + \".\", use_cuda, score_type=score_type)\n            P_y_1.append(y1_score)\n            P_y_2.append(y2_score)\n\n            P_x_1_y_1.append(score1)\n            P_x_1_y_2.append(score2)\n            P_x_1_correct.append(score1/(score1 + score2))\n\n        else:\n            x_2.append(ctx)\n            x_2_score = sent_scoring((model, tokenizer), ctx + \".\", use_cuda, score_type=score_type)\n            P_x_2.append(x_2_score)\n            P_x_2_y_1.append(score1)\n            P_x_2_y_2.append(score2)\n            P_x_2_correct.append(score2/(score1 + score2))\n\n            P_y_1_correct.append(P_x_1_y_1[-1]/(P_x_1_y_1[-1] + score1))\n            P_y_2_correct.append(score2/(P_x_1_y_2[-1] + score2))\n\n        if verbose:\n            print(f\"Q: {ctx}: 1. {p1} 2. {p2}\")\n            print(f\"model says '{pred_sent}' is more likely\")\n            print(\"\\n\")\n        if pred == metaphor_data[\"labels\"]:\n            correct += 1\n        preds.append(pred)\n\n    cols = {\"x_1\": x_1, \"x_2\": x_2, \"y_1\": y_1, \"y_2\": y_2, \"P(x_1)\": P_x_1, \"P(x_2)\": P_x_2, \"P(y_1)\": P_y_1, \"P(y_2)\": P_y_2,\n        \"P(x_1, y_1)\": P_x_1_y_1, \"P(x_1, y_2)\": P_x_1_y_2, \"P(x_2, y_1)\": P_x_2_y_1, \"P(x_2, y_2)\": P_x_2_y_2,\n        \"P(y_1|x_1)\": P_x_1_correct, \"P(y_2|x_2)\": P_x_2_correct, \"P(x_1|y_1)\": P_y_1_correct, \"P(x_2|y_2)\": P_y_2_correct}\n    out_df = pd.DataFrame(cols)\n\n    if return_acc:\n        return correct/len(preds), out_df, preds, labels\n\n    return out_df, preds, labels\n\ndef compute_stats(total_df: pd.DataFrame, all_preds: List, all_labels: List) -> None:\n    print(\"overall accuracy: \")\n    accuracyy = len(np.where(np.array(all_preds) == np.array(all_labels))[0])/len(all_labels)\n    print(accuracyy)\n    print(\"confusion matrix: \")\n    matrix_dic = confusion_matrix(list(total_df[\"P(y_1|x_1)\"]), list(total_df[\"P(y_2|x_2)\"]), list(total_df[\"P(x_1|y_1)\"]), list(total_df[\"P(x_2|y_2)\"]))\n\n    return accuracyy, matrix_dic\n","metadata":{"id":"butPbYIbxz2a","execution":{"iopub.status.busy":"2023-10-06T22:06:15.813641Z","iopub.execute_input":"2023-10-06T22:06:15.814370Z","iopub.status.idle":"2023-10-06T22:06:15.852292Z","shell.execute_reply.started":"2023-10-06T22:06:15.814332Z","shell.execute_reply":"2023-10-06T22:06:15.851445Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset(\"nightingal3/fig-qa\")","metadata":{"id":"-MD2kwlmxz2b","execution":{"iopub.status.busy":"2023-10-06T21:30:33.550910Z","iopub.execute_input":"2023-10-06T21:30:33.551369Z","iopub.status.idle":"2023-10-06T21:30:36.323400Z","shell.execute_reply.started":"2023-10-06T21:30:33.551338Z","shell.execute_reply":"2023-10-06T21:30:36.322559Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/3.36k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18149632d1894d08ac7ae38fb1de1493"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04e266704369410daecadd62f6f9b876"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/155k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a382ef67eb94be7a42fbc81c613613d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/21.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c967cf06a1a429683715367eb2f0431"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/864k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c693ed5ac7844df8bedfbc22c867efac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/116k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc76ae3a0059449dbcd91dc93b1580df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/120k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"514f2d67a50f463cafad3b7e34c3bedb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fec00e29d0647f78dc8bbbd8a522830"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60e6c383e7754b48adae95dc7ae1e5d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b74e8edb2c2499fb2a658b74acd316a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0d86883a8e74ae99e749ff99a69b8b5"}},"metadata":{}}]},{"cell_type":"code","source":"dataset['validation']","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u-p0BAxiBCQx","outputId":"06d03f17-007e-420f-9b0c-b4709ef59e44","execution":{"iopub.status.busy":"2023-10-06T22:06:21.451032Z","iopub.execute_input":"2023-10-06T22:06:21.451362Z","iopub.status.idle":"2023-10-06T22:06:21.458714Z","shell.execute_reply.started":"2023-10-06T22:06:21.451334Z","shell.execute_reply":"2023-10-06T22:06:21.457747Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['startphrase', 'ending1', 'ending2', 'labels', 'valid'],\n    num_rows: 1094\n})"},"metadata":{}}]},{"cell_type":"code","source":"#subset_test_dataset = dataset['validation'].select(range(10))\nsubset_test_dataset = dataset['validation']","metadata":{"id":"UkmIOMfV3elH","execution":{"iopub.status.busy":"2023-10-06T22:06:23.884288Z","iopub.execute_input":"2023-10-06T22:06:23.884651Z","iopub.status.idle":"2023-10-06T22:06:23.889368Z","shell.execute_reply.started":"2023-10-06T22:06:23.884618Z","shell.execute_reply":"2023-10-06T22:06:23.887835Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"out_df, preds, labels = evaluate_model(model, tokenizer, subset_test_dataset, verbose = False)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AAuyTVnr31VL","outputId":"057336cb-0d3a-46a9-fa92-d20fa5f4179c","execution":{"iopub.status.busy":"2023-10-06T22:06:27.686321Z","iopub.execute_input":"2023-10-06T22:06:27.686673Z","iopub.status.idle":"2023-10-06T22:46:03.528194Z","shell.execute_reply.started":"2023-10-06T22:06:27.686644Z","shell.execute_reply":"2023-10-06T22:46:03.527118Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"100%|██████████| 1094/1094 [39:35<00:00,  2.17s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"zero_shot_accuracy, conf_matrix_zero_shot =  compute_stats(out_df, preds, labels)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DV8w0TDc34fo","outputId":"9d561724-5024-49c3-a402-4732c9747c95","execution":{"iopub.status.busy":"2023-10-06T22:46:03.530255Z","iopub.execute_input":"2023-10-06T22:46:03.531370Z","iopub.status.idle":"2023-10-06T22:46:03.539084Z","shell.execute_reply.started":"2023-10-06T22:46:03.531334Z","shell.execute_reply":"2023-10-06T22:46:03.538087Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"overall accuracy: \n0.6901279707495429\nconfusion matrix: \ncorrect forward 755 wrong forward 339 correct backward 682 wrong_backward 412\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\n\nmodel_id_string = model_id.replace(\"/\", \"-\")\n\n# Saving DataFrame to CSV\nout_df.to_csv(f'output_df_{model_id_string}.csv', sep=\"\\t\", index=False)\n\n# Saving other data as JSON\ndata_to_save = {\n    \"preds\": preds,\n    \"labels\": labels,\n    \"zero_shot_accuracy\": zero_shot_accuracy,\n    \"conf_matrix_zero_shot\": conf_matrix_zero_shot\n}\n\nwith open(f'output_data_{model_id_string}.json', 'w') as file:\n    json.dump(data_to_save, file)\n\nimport pickle\n\ndata_to_save_pick = {\n    \"out_df\": out_df,\n    \"preds\": preds,\n    \"labels\": labels,\n    \"zero_shot_accuracy\": zero_shot_accuracy,\n    \"conf_matrix_zero_shot\": conf_matrix_zero_shot\n}\n\nwith open(f'pickle_output_data_{model_id_string}.pkl', 'wb') as file:\n    pickle.dump(data_to_save_pick, file)\n\n","metadata":{"id":"f-Oxn_ffXelA","execution":{"iopub.status.busy":"2023-10-06T22:46:08.908753Z","iopub.execute_input":"2023-10-06T22:46:08.909087Z","iopub.status.idle":"2023-10-06T22:46:08.934752Z","shell.execute_reply.started":"2023-10-06T22:46:08.909060Z","shell.execute_reply":"2023-10-06T22:46:08.933737Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Finetuning","metadata":{"id":"d4uwXib2xz2b"}},{"cell_type":"code","source":"from peft import prepare_model_for_kbit_training\n\nmodel.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)","metadata":{"id":"a9EUEDAl0ss3","colab":{"base_uri":"https://localhost:8080/","height":381},"outputId":"0cfa011b-1894-4d60-8abc-dc7a48916f87","execution":{"iopub.status.busy":"2023-10-06T22:48:06.506796Z","iopub.execute_input":"2023-10-06T22:48:06.507176Z","iopub.status.idle":"2023-10-06T22:48:06.557846Z","shell.execute_reply.started":"2023-10-06T22:48:06.507150Z","shell.execute_reply":"2023-10-06T22:48:06.556950Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def print_modules(model, prefix=''):\n    for name, module in model.named_children():\n        full_name = f\"{prefix}.{name}\" if prefix else name\n        print(full_name)\n        print_modules(module, full_name)\n\nprint_modules(model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3S0tJHkaDEde","outputId":"264b1736-3f27-449e-ea9a-e4fb7165ee19","execution":{"iopub.status.busy":"2023-10-06T22:48:10.001365Z","iopub.execute_input":"2023-10-06T22:48:10.002082Z","iopub.status.idle":"2023-10-06T22:48:10.010278Z","shell.execute_reply.started":"2023-10-06T22:48:10.002050Z","shell.execute_reply":"2023-10-06T22:48:10.009366Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"model\nmodel.embed_tokens\nmodel.layers\nmodel.layers.0\nmodel.layers.0.self_attn\nmodel.layers.0.self_attn.q_proj\nmodel.layers.0.self_attn.k_proj\nmodel.layers.0.self_attn.v_proj\nmodel.layers.0.self_attn.o_proj\nmodel.layers.0.self_attn.rotary_emb\nmodel.layers.0.mlp\nmodel.layers.0.mlp.gate_proj\nmodel.layers.0.mlp.up_proj\nmodel.layers.0.mlp.down_proj\nmodel.layers.0.mlp.act_fn\nmodel.layers.0.input_layernorm\nmodel.layers.0.post_attention_layernorm\nmodel.layers.1\nmodel.layers.1.self_attn\nmodel.layers.1.self_attn.q_proj\nmodel.layers.1.self_attn.k_proj\nmodel.layers.1.self_attn.v_proj\nmodel.layers.1.self_attn.o_proj\nmodel.layers.1.self_attn.rotary_emb\nmodel.layers.1.mlp\nmodel.layers.1.mlp.gate_proj\nmodel.layers.1.mlp.up_proj\nmodel.layers.1.mlp.down_proj\nmodel.layers.1.mlp.act_fn\nmodel.layers.1.input_layernorm\nmodel.layers.1.post_attention_layernorm\nmodel.layers.2\nmodel.layers.2.self_attn\nmodel.layers.2.self_attn.q_proj\nmodel.layers.2.self_attn.k_proj\nmodel.layers.2.self_attn.v_proj\nmodel.layers.2.self_attn.o_proj\nmodel.layers.2.self_attn.rotary_emb\nmodel.layers.2.mlp\nmodel.layers.2.mlp.gate_proj\nmodel.layers.2.mlp.up_proj\nmodel.layers.2.mlp.down_proj\nmodel.layers.2.mlp.act_fn\nmodel.layers.2.input_layernorm\nmodel.layers.2.post_attention_layernorm\nmodel.layers.3\nmodel.layers.3.self_attn\nmodel.layers.3.self_attn.q_proj\nmodel.layers.3.self_attn.k_proj\nmodel.layers.3.self_attn.v_proj\nmodel.layers.3.self_attn.o_proj\nmodel.layers.3.self_attn.rotary_emb\nmodel.layers.3.mlp\nmodel.layers.3.mlp.gate_proj\nmodel.layers.3.mlp.up_proj\nmodel.layers.3.mlp.down_proj\nmodel.layers.3.mlp.act_fn\nmodel.layers.3.input_layernorm\nmodel.layers.3.post_attention_layernorm\nmodel.layers.4\nmodel.layers.4.self_attn\nmodel.layers.4.self_attn.q_proj\nmodel.layers.4.self_attn.k_proj\nmodel.layers.4.self_attn.v_proj\nmodel.layers.4.self_attn.o_proj\nmodel.layers.4.self_attn.rotary_emb\nmodel.layers.4.mlp\nmodel.layers.4.mlp.gate_proj\nmodel.layers.4.mlp.up_proj\nmodel.layers.4.mlp.down_proj\nmodel.layers.4.mlp.act_fn\nmodel.layers.4.input_layernorm\nmodel.layers.4.post_attention_layernorm\nmodel.layers.5\nmodel.layers.5.self_attn\nmodel.layers.5.self_attn.q_proj\nmodel.layers.5.self_attn.k_proj\nmodel.layers.5.self_attn.v_proj\nmodel.layers.5.self_attn.o_proj\nmodel.layers.5.self_attn.rotary_emb\nmodel.layers.5.mlp\nmodel.layers.5.mlp.gate_proj\nmodel.layers.5.mlp.up_proj\nmodel.layers.5.mlp.down_proj\nmodel.layers.5.mlp.act_fn\nmodel.layers.5.input_layernorm\nmodel.layers.5.post_attention_layernorm\nmodel.layers.6\nmodel.layers.6.self_attn\nmodel.layers.6.self_attn.q_proj\nmodel.layers.6.self_attn.k_proj\nmodel.layers.6.self_attn.v_proj\nmodel.layers.6.self_attn.o_proj\nmodel.layers.6.self_attn.rotary_emb\nmodel.layers.6.mlp\nmodel.layers.6.mlp.gate_proj\nmodel.layers.6.mlp.up_proj\nmodel.layers.6.mlp.down_proj\nmodel.layers.6.mlp.act_fn\nmodel.layers.6.input_layernorm\nmodel.layers.6.post_attention_layernorm\nmodel.layers.7\nmodel.layers.7.self_attn\nmodel.layers.7.self_attn.q_proj\nmodel.layers.7.self_attn.k_proj\nmodel.layers.7.self_attn.v_proj\nmodel.layers.7.self_attn.o_proj\nmodel.layers.7.self_attn.rotary_emb\nmodel.layers.7.mlp\nmodel.layers.7.mlp.gate_proj\nmodel.layers.7.mlp.up_proj\nmodel.layers.7.mlp.down_proj\nmodel.layers.7.mlp.act_fn\nmodel.layers.7.input_layernorm\nmodel.layers.7.post_attention_layernorm\nmodel.layers.8\nmodel.layers.8.self_attn\nmodel.layers.8.self_attn.q_proj\nmodel.layers.8.self_attn.k_proj\nmodel.layers.8.self_attn.v_proj\nmodel.layers.8.self_attn.o_proj\nmodel.layers.8.self_attn.rotary_emb\nmodel.layers.8.mlp\nmodel.layers.8.mlp.gate_proj\nmodel.layers.8.mlp.up_proj\nmodel.layers.8.mlp.down_proj\nmodel.layers.8.mlp.act_fn\nmodel.layers.8.input_layernorm\nmodel.layers.8.post_attention_layernorm\nmodel.layers.9\nmodel.layers.9.self_attn\nmodel.layers.9.self_attn.q_proj\nmodel.layers.9.self_attn.k_proj\nmodel.layers.9.self_attn.v_proj\nmodel.layers.9.self_attn.o_proj\nmodel.layers.9.self_attn.rotary_emb\nmodel.layers.9.mlp\nmodel.layers.9.mlp.gate_proj\nmodel.layers.9.mlp.up_proj\nmodel.layers.9.mlp.down_proj\nmodel.layers.9.mlp.act_fn\nmodel.layers.9.input_layernorm\nmodel.layers.9.post_attention_layernorm\nmodel.layers.10\nmodel.layers.10.self_attn\nmodel.layers.10.self_attn.q_proj\nmodel.layers.10.self_attn.k_proj\nmodel.layers.10.self_attn.v_proj\nmodel.layers.10.self_attn.o_proj\nmodel.layers.10.self_attn.rotary_emb\nmodel.layers.10.mlp\nmodel.layers.10.mlp.gate_proj\nmodel.layers.10.mlp.up_proj\nmodel.layers.10.mlp.down_proj\nmodel.layers.10.mlp.act_fn\nmodel.layers.10.input_layernorm\nmodel.layers.10.post_attention_layernorm\nmodel.layers.11\nmodel.layers.11.self_attn\nmodel.layers.11.self_attn.q_proj\nmodel.layers.11.self_attn.k_proj\nmodel.layers.11.self_attn.v_proj\nmodel.layers.11.self_attn.o_proj\nmodel.layers.11.self_attn.rotary_emb\nmodel.layers.11.mlp\nmodel.layers.11.mlp.gate_proj\nmodel.layers.11.mlp.up_proj\nmodel.layers.11.mlp.down_proj\nmodel.layers.11.mlp.act_fn\nmodel.layers.11.input_layernorm\nmodel.layers.11.post_attention_layernorm\nmodel.layers.12\nmodel.layers.12.self_attn\nmodel.layers.12.self_attn.q_proj\nmodel.layers.12.self_attn.k_proj\nmodel.layers.12.self_attn.v_proj\nmodel.layers.12.self_attn.o_proj\nmodel.layers.12.self_attn.rotary_emb\nmodel.layers.12.mlp\nmodel.layers.12.mlp.gate_proj\nmodel.layers.12.mlp.up_proj\nmodel.layers.12.mlp.down_proj\nmodel.layers.12.mlp.act_fn\nmodel.layers.12.input_layernorm\nmodel.layers.12.post_attention_layernorm\nmodel.layers.13\nmodel.layers.13.self_attn\nmodel.layers.13.self_attn.q_proj\nmodel.layers.13.self_attn.k_proj\nmodel.layers.13.self_attn.v_proj\nmodel.layers.13.self_attn.o_proj\nmodel.layers.13.self_attn.rotary_emb\nmodel.layers.13.mlp\nmodel.layers.13.mlp.gate_proj\nmodel.layers.13.mlp.up_proj\nmodel.layers.13.mlp.down_proj\nmodel.layers.13.mlp.act_fn\nmodel.layers.13.input_layernorm\nmodel.layers.13.post_attention_layernorm\nmodel.layers.14\nmodel.layers.14.self_attn\nmodel.layers.14.self_attn.q_proj\nmodel.layers.14.self_attn.k_proj\nmodel.layers.14.self_attn.v_proj\nmodel.layers.14.self_attn.o_proj\nmodel.layers.14.self_attn.rotary_emb\nmodel.layers.14.mlp\nmodel.layers.14.mlp.gate_proj\nmodel.layers.14.mlp.up_proj\nmodel.layers.14.mlp.down_proj\nmodel.layers.14.mlp.act_fn\nmodel.layers.14.input_layernorm\nmodel.layers.14.post_attention_layernorm\nmodel.layers.15\nmodel.layers.15.self_attn\nmodel.layers.15.self_attn.q_proj\nmodel.layers.15.self_attn.k_proj\nmodel.layers.15.self_attn.v_proj\nmodel.layers.15.self_attn.o_proj\nmodel.layers.15.self_attn.rotary_emb\nmodel.layers.15.mlp\nmodel.layers.15.mlp.gate_proj\nmodel.layers.15.mlp.up_proj\nmodel.layers.15.mlp.down_proj\nmodel.layers.15.mlp.act_fn\nmodel.layers.15.input_layernorm\nmodel.layers.15.post_attention_layernorm\nmodel.layers.16\nmodel.layers.16.self_attn\nmodel.layers.16.self_attn.q_proj\nmodel.layers.16.self_attn.k_proj\nmodel.layers.16.self_attn.v_proj\nmodel.layers.16.self_attn.o_proj\nmodel.layers.16.self_attn.rotary_emb\nmodel.layers.16.mlp\nmodel.layers.16.mlp.gate_proj\nmodel.layers.16.mlp.up_proj\nmodel.layers.16.mlp.down_proj\nmodel.layers.16.mlp.act_fn\nmodel.layers.16.input_layernorm\nmodel.layers.16.post_attention_layernorm\nmodel.layers.17\nmodel.layers.17.self_attn\nmodel.layers.17.self_attn.q_proj\nmodel.layers.17.self_attn.k_proj\nmodel.layers.17.self_attn.v_proj\nmodel.layers.17.self_attn.o_proj\nmodel.layers.17.self_attn.rotary_emb\nmodel.layers.17.mlp\nmodel.layers.17.mlp.gate_proj\nmodel.layers.17.mlp.up_proj\nmodel.layers.17.mlp.down_proj\nmodel.layers.17.mlp.act_fn\nmodel.layers.17.input_layernorm\nmodel.layers.17.post_attention_layernorm\nmodel.layers.18\nmodel.layers.18.self_attn\nmodel.layers.18.self_attn.q_proj\nmodel.layers.18.self_attn.k_proj\nmodel.layers.18.self_attn.v_proj\nmodel.layers.18.self_attn.o_proj\nmodel.layers.18.self_attn.rotary_emb\nmodel.layers.18.mlp\nmodel.layers.18.mlp.gate_proj\nmodel.layers.18.mlp.up_proj\nmodel.layers.18.mlp.down_proj\nmodel.layers.18.mlp.act_fn\nmodel.layers.18.input_layernorm\nmodel.layers.18.post_attention_layernorm\nmodel.layers.19\nmodel.layers.19.self_attn\nmodel.layers.19.self_attn.q_proj\nmodel.layers.19.self_attn.k_proj\nmodel.layers.19.self_attn.v_proj\nmodel.layers.19.self_attn.o_proj\nmodel.layers.19.self_attn.rotary_emb\nmodel.layers.19.mlp\nmodel.layers.19.mlp.gate_proj\nmodel.layers.19.mlp.up_proj\nmodel.layers.19.mlp.down_proj\nmodel.layers.19.mlp.act_fn\nmodel.layers.19.input_layernorm\nmodel.layers.19.post_attention_layernorm\nmodel.layers.20\nmodel.layers.20.self_attn\nmodel.layers.20.self_attn.q_proj\nmodel.layers.20.self_attn.k_proj\nmodel.layers.20.self_attn.v_proj\nmodel.layers.20.self_attn.o_proj\nmodel.layers.20.self_attn.rotary_emb\nmodel.layers.20.mlp\nmodel.layers.20.mlp.gate_proj\nmodel.layers.20.mlp.up_proj\nmodel.layers.20.mlp.down_proj\nmodel.layers.20.mlp.act_fn\nmodel.layers.20.input_layernorm\nmodel.layers.20.post_attention_layernorm\nmodel.layers.21\nmodel.layers.21.self_attn\nmodel.layers.21.self_attn.q_proj\nmodel.layers.21.self_attn.k_proj\nmodel.layers.21.self_attn.v_proj\nmodel.layers.21.self_attn.o_proj\nmodel.layers.21.self_attn.rotary_emb\nmodel.layers.21.mlp\nmodel.layers.21.mlp.gate_proj\nmodel.layers.21.mlp.up_proj\nmodel.layers.21.mlp.down_proj\nmodel.layers.21.mlp.act_fn\nmodel.layers.21.input_layernorm\nmodel.layers.21.post_attention_layernorm\nmodel.layers.22\nmodel.layers.22.self_attn\nmodel.layers.22.self_attn.q_proj\nmodel.layers.22.self_attn.k_proj\nmodel.layers.22.self_attn.v_proj\nmodel.layers.22.self_attn.o_proj\nmodel.layers.22.self_attn.rotary_emb\nmodel.layers.22.mlp\nmodel.layers.22.mlp.gate_proj\nmodel.layers.22.mlp.up_proj\nmodel.layers.22.mlp.down_proj\nmodel.layers.22.mlp.act_fn\nmodel.layers.22.input_layernorm\nmodel.layers.22.post_attention_layernorm\nmodel.layers.23\nmodel.layers.23.self_attn\nmodel.layers.23.self_attn.q_proj\nmodel.layers.23.self_attn.k_proj\nmodel.layers.23.self_attn.v_proj\nmodel.layers.23.self_attn.o_proj\nmodel.layers.23.self_attn.rotary_emb\nmodel.layers.23.mlp\nmodel.layers.23.mlp.gate_proj\nmodel.layers.23.mlp.up_proj\nmodel.layers.23.mlp.down_proj\nmodel.layers.23.mlp.act_fn\nmodel.layers.23.input_layernorm\nmodel.layers.23.post_attention_layernorm\nmodel.layers.24\nmodel.layers.24.self_attn\nmodel.layers.24.self_attn.q_proj\nmodel.layers.24.self_attn.k_proj\nmodel.layers.24.self_attn.v_proj\nmodel.layers.24.self_attn.o_proj\nmodel.layers.24.self_attn.rotary_emb\nmodel.layers.24.mlp\nmodel.layers.24.mlp.gate_proj\nmodel.layers.24.mlp.up_proj\nmodel.layers.24.mlp.down_proj\nmodel.layers.24.mlp.act_fn\nmodel.layers.24.input_layernorm\nmodel.layers.24.post_attention_layernorm\nmodel.layers.25\nmodel.layers.25.self_attn\nmodel.layers.25.self_attn.q_proj\nmodel.layers.25.self_attn.k_proj\nmodel.layers.25.self_attn.v_proj\nmodel.layers.25.self_attn.o_proj\nmodel.layers.25.self_attn.rotary_emb\nmodel.layers.25.mlp\nmodel.layers.25.mlp.gate_proj\nmodel.layers.25.mlp.up_proj\nmodel.layers.25.mlp.down_proj\nmodel.layers.25.mlp.act_fn\nmodel.layers.25.input_layernorm\nmodel.layers.25.post_attention_layernorm\nmodel.layers.26\nmodel.layers.26.self_attn\nmodel.layers.26.self_attn.q_proj\nmodel.layers.26.self_attn.k_proj\nmodel.layers.26.self_attn.v_proj\nmodel.layers.26.self_attn.o_proj\nmodel.layers.26.self_attn.rotary_emb\nmodel.layers.26.mlp\nmodel.layers.26.mlp.gate_proj\nmodel.layers.26.mlp.up_proj\nmodel.layers.26.mlp.down_proj\nmodel.layers.26.mlp.act_fn\nmodel.layers.26.input_layernorm\nmodel.layers.26.post_attention_layernorm\nmodel.layers.27\nmodel.layers.27.self_attn\nmodel.layers.27.self_attn.q_proj\nmodel.layers.27.self_attn.k_proj\nmodel.layers.27.self_attn.v_proj\nmodel.layers.27.self_attn.o_proj\nmodel.layers.27.self_attn.rotary_emb\nmodel.layers.27.mlp\nmodel.layers.27.mlp.gate_proj\nmodel.layers.27.mlp.up_proj\nmodel.layers.27.mlp.down_proj\nmodel.layers.27.mlp.act_fn\nmodel.layers.27.input_layernorm\nmodel.layers.27.post_attention_layernorm\nmodel.layers.28\nmodel.layers.28.self_attn\nmodel.layers.28.self_attn.q_proj\nmodel.layers.28.self_attn.k_proj\nmodel.layers.28.self_attn.v_proj\nmodel.layers.28.self_attn.o_proj\nmodel.layers.28.self_attn.rotary_emb\nmodel.layers.28.mlp\nmodel.layers.28.mlp.gate_proj\nmodel.layers.28.mlp.up_proj\nmodel.layers.28.mlp.down_proj\nmodel.layers.28.mlp.act_fn\nmodel.layers.28.input_layernorm\nmodel.layers.28.post_attention_layernorm\nmodel.layers.29\nmodel.layers.29.self_attn\nmodel.layers.29.self_attn.q_proj\nmodel.layers.29.self_attn.k_proj\nmodel.layers.29.self_attn.v_proj\nmodel.layers.29.self_attn.o_proj\nmodel.layers.29.self_attn.rotary_emb\nmodel.layers.29.mlp\nmodel.layers.29.mlp.gate_proj\nmodel.layers.29.mlp.up_proj\nmodel.layers.29.mlp.down_proj\nmodel.layers.29.mlp.act_fn\nmodel.layers.29.input_layernorm\nmodel.layers.29.post_attention_layernorm\nmodel.layers.30\nmodel.layers.30.self_attn\nmodel.layers.30.self_attn.q_proj\nmodel.layers.30.self_attn.k_proj\nmodel.layers.30.self_attn.v_proj\nmodel.layers.30.self_attn.o_proj\nmodel.layers.30.self_attn.rotary_emb\nmodel.layers.30.mlp\nmodel.layers.30.mlp.gate_proj\nmodel.layers.30.mlp.up_proj\nmodel.layers.30.mlp.down_proj\nmodel.layers.30.mlp.act_fn\nmodel.layers.30.input_layernorm\nmodel.layers.30.post_attention_layernorm\nmodel.layers.31\nmodel.layers.31.self_attn\nmodel.layers.31.self_attn.q_proj\nmodel.layers.31.self_attn.k_proj\nmodel.layers.31.self_attn.v_proj\nmodel.layers.31.self_attn.o_proj\nmodel.layers.31.self_attn.rotary_emb\nmodel.layers.31.mlp\nmodel.layers.31.mlp.gate_proj\nmodel.layers.31.mlp.up_proj\nmodel.layers.31.mlp.down_proj\nmodel.layers.31.mlp.act_fn\nmodel.layers.31.input_layernorm\nmodel.layers.31.post_attention_layernorm\nmodel.norm\nlm_head\n","output_type":"stream"}]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )","metadata":{"id":"gkIcwsSU01EB","execution":{"iopub.status.busy":"2023-10-06T22:50:03.737996Z","iopub.execute_input":"2023-10-06T22:50:03.738360Z","iopub.status.idle":"2023-10-06T22:50:03.743996Z","shell.execute_reply.started":"2023-10-06T22:50:03.738331Z","shell.execute_reply":"2023-10-06T22:50:03.742724Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\nconfig = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    #target_modules=[\"query_key_value\"],\n    target_modules=[\"self_attn.q_proj\", \"self_attn.k_proj\", \"self_attn.v_proj\", \"self_attn.o_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, config)\nprint_trainable_parameters(model)","metadata":{"id":"Ybeyl20n3dYH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e3b48447-b507-4a2c-8cfa-379c6c75f762","execution":{"iopub.status.busy":"2023-10-06T22:50:07.401404Z","iopub.execute_input":"2023-10-06T22:50:07.401760Z","iopub.status.idle":"2023-10-06T22:50:19.195939Z","shell.execute_reply.started":"2023-10-06T22:50:07.401730Z","shell.execute_reply":"2023-10-06T22:50:19.194954Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"trainable params: 6815744 || all params: 3758886912 || trainable%: 0.18132346515244138\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let's load a common dataset, english quotes, to fine tune our model on famous quotes.","metadata":{"id":"FCc64bfnmd3j"}},{"cell_type":"code","source":"text = \"\"\"I'm selfish, impatient and a little insecure.\"\"\"\n\ndevice = \"cuda:0\"\n\ninputs = tokenizer(text, return_tensors=\"pt\").to(device)\noutputs = model.generate(**inputs, max_new_tokens=150)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2023-10-06T22:54:09.404788Z","iopub.execute_input":"2023-10-06T22:54:09.405164Z","iopub.status.idle":"2023-10-06T22:54:23.680609Z","shell.execute_reply.started":"2023-10-06T22:54:09.405137Z","shell.execute_reply":"2023-10-06T22:54:23.679628Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"I'm selfish, impatient and a little insecure. I make mistakes, I am out of control and at times hard to handle. But if you can't handle me at my worst, then you sure as hell don't deserve me at my best.\n\nI'm not perfect, but I'm not trying to be. I'm not trying to be anyone's savior, I'm just trying to be the best version of myself that I can be. I'm not trying to be anyone's hero, I'm just trying to be the best version of myself that I can be. I'm not trying to be anyone's inspiration, I'm just trying to be the best version of myself that I can be. I'm\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndata = dataset\ndata = data.map(lambda samples: tokenizer(samples[\"startphrase\"]), batched=True)","metadata":{"id":"s6f4z8EYmcJ6","colab":{"base_uri":"https://localhost:8080/","height":209,"referenced_widgets":["98351baf42934fe5b7524b3b64accbd8","3d0671ee3f234656b8a2627389e07e9d","15b50e5a174a40c3b7c0dd24943b80c0","41f80043500046d79f105206a1c91610","737604363ab84acab1980304dfae18b7","7d5ce9cf72a741508b0044e9d36b36f9","5fc16426f4c04d54acc2f2e0457a6416","e690820d66e4416ba819ebbef9f2909e","42716af8d24146c4b29393ddc2dc6a8a","03421596b8f343eaafd392d951860431","71eda188275c493b89b4a2dcdbf3f336","3e3dc5d6c0b540ccb7f7afa134e43dcf","cf463801021a47f284c7e0d3acfc8d63","3e763d4588cd492baf6f5dcfbab241cc","3c093130754d4825b2d1772e7ae1f2ae","c50c4ada3b8f46429028c0fb11bb856a","24abc37e54ba41669611b618d77b332d","bc02bb96ad494682a4443818bf9e2b36","32c4670df43042e9b5258bf33dff8c7e","d4bb2ee46b2c489e954139c44fc9a192","f4748ce5b31647e3ad85c750a7862e49","010e9589a46941dd83eb4cac8770a626","3286bad3a57445e9a41b81ea027e631d","72abdfd49b8e4960b22d25e0615b6a6c","76377837c9e346efaf05625d9ec9782d","968a0fcf5fad48028404e342f677e664","33e0587bb0b24accb05c16cc02d75b3d","d7c0ccb695a64e6ba4bc08de65ac7739","c19ffd16e845410bbe563cecb1b3d612","3a88eec22474455d80a541f1afc10dd6","cff47dc83ead4436903d9b651b9b4649","5967538111e4487b8a49e40189f97c31","b464aa7530da497791ce86ae00bdc07e","a18b440ce6fe49f68a92cac0f0e1c2fb","5f394fcda1fd4f39957d14a5c4caa631","06352b37a3de45199d28f0710e31742f","9408db961369449a9f1716a185ac6e7d","1ab6fddb871b4889bad1850aeb911e42","0d3cdf0730754282af4d57e8db5aef80","6fc4c705d1214cc193bf64963121e81b","9fcdf6c2ce5f4dcdb97e270d25d08a0d","7cdf6b8039e1414ca97892214106a41d","f2bcfde8fbc1462b9a7f2334f592e615","ccc72c8249a04775b61d24a9edf914f9","c9bbfdae62be4fb9a4343c3dfd2c557a","d2c2407dec094aef82681b44ec2e3d2f","9e8a6ae9602f48dbb83083b72ca53e1d","899f4a2877e949b6a2117b81c9aed8a5","60a2c67412904f369f8c046ab8ca29e2","f99b02cc6f1149c08fadf7959c5c2685","fb8017a9dccb4103a6e4a012053e0fec","96d68d033c774137a3db337e978d83a5","990018b5851242c2a93a39761cd44e8c","02676ed015414b7bad8f234881fd1fe7","13bfd884d21e4579855fc8acf09533a8","6df57c6325c74747be601eb8b75d1dd5","5fef097a0cbe41d2bd7a33e694a82b5a","426040f036ac497d83a8af02a1a26a63","b3af7e680e6645a496bd0b4a48776fbb","01f89584ce88486d9405e71c14817b37","0b743164f8184e0cafc84c9883d8729d","388e42c3747c44fe95febfb0a495982a","31fa3a0b8ff84732aaa2ed4032373a4b","0016ad3003c0499fb29df618377d5632","680f8d845c0646b090e13fa5b25ae971","f7f5cabdccc84b3b83f9d93e5e03a5c0"]},"outputId":"2dcfb618-fc3d-4633-fffe-0c8358336876","execution":{"iopub.status.busy":"2023-10-06T22:55:08.707108Z","iopub.execute_input":"2023-10-06T22:55:08.707439Z","iopub.status.idle":"2023-10-06T22:55:09.630740Z","shell.execute_reply.started":"2023-10-06T22:55:08.707411Z","shell.execute_reply":"2023-10-06T22:55:09.629827Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9674 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68e8c412ee4843b2bca45e5cea567046"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1094 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a4ec16cbd18405eb9ff38aaccdbb530"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1146 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fea9527ac7ac425fabe9a18bba4def82"}},"metadata":{}}]},{"cell_type":"markdown","source":"Run the cell below to run the training! For the sake of the demo, we just ran it for few steps just to showcase how to use this integration with existing tools on the HF ecosystem.","metadata":{"id":"_0MOtwf3zdZp"}},{"cell_type":"code","source":"import transformers\n\n# needed for gpt-neo-x tokenizer\ntokenizer.pad_token = tokenizer.eos_token\n\ntrainer = transformers.Trainer(\n    model=model,\n    train_dataset=data[\"train\"],\n    args=transformers.TrainingArguments(\n        per_device_train_batch_size=1,\n        gradient_accumulation_steps=4,\n        warmup_steps=2,\n        max_steps=10,\n        learning_rate=2e-4,\n        fp16=True,\n        logging_steps=1,\n        output_dir=\"outputs\",\n        optim=\"paged_adamw_8bit\"\n    ),\n    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n)\nmodel.config.use_cache = False  # silence the warnings. Please re-enable for inference!\ntrainer.train()","metadata":{"id":"jq0nX33BmfaC","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f9686f25-c90a-4d75-9a41-4dfc4f269113","execution":{"iopub.status.busy":"2023-10-06T22:55:15.794484Z","iopub.execute_input":"2023-10-06T22:55:15.794842Z","iopub.status.idle":"2023-10-06T22:57:28.369505Z","shell.execute_reply.started":"2023-10-06T22:55:15.794814Z","shell.execute_reply":"2023-10-06T22:57:28.368511Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.12 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231006_225607-nclb0nmx</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/davinci/huggingface/runs/nclb0nmx' target=\"_blank\">rare-shadow-2</a></strong> to <a href='https://wandb.ai/davinci/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/davinci/huggingface' target=\"_blank\">https://wandb.ai/davinci/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/davinci/huggingface/runs/nclb0nmx' target=\"_blank\">https://wandb.ai/davinci/huggingface/runs/nclb0nmx</a>"},"metadata":{}},{"name":"stderr","text":"You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10/10 00:44, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>4.188800</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.809600</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4.296000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>3.851200</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>3.944500</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>4.126700</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>4.726100</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>4.913800</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>3.877000</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>4.039000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=10, training_loss=4.177276349067688, metrics={'train_runtime': 131.3959, 'train_samples_per_second': 0.304, 'train_steps_per_second': 0.076, 'total_flos': 22462753751040.0, 'train_loss': 4.177276349067688, 'epoch': 0.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-10-06T22:57:44.678264Z","iopub.execute_input":"2023-10-06T22:57:44.678634Z","iopub.status.idle":"2023-10-06T22:58:35.142274Z","shell.execute_reply.started":"2023-10-06T22:57:44.678592Z","shell.execute_reply":"2023-10-06T22:58:35.141258Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10/10 00:45, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.484700</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.799700</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3.661600</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>3.789600</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.825400</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.758300</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.942700</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>3.483200</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>3.146500</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>5.058700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=10, training_loss=3.6950220823287965, metrics={'train_runtime': 50.1215, 'train_samples_per_second': 0.798, 'train_steps_per_second': 0.2, 'total_flos': 20925378969600.0, 'train_loss': 3.6950220823287965, 'epoch': 0.0})"},"metadata":{}}]},{"cell_type":"code","source":"model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model  # Take care of distributed/parallel training\nmodel_to_save.save_pretrained(\"outputs\")","metadata":{"id":"p66mZk1RAlOR","execution":{"iopub.status.busy":"2023-10-06T22:58:42.346830Z","iopub.execute_input":"2023-10-06T22:58:42.347573Z","iopub.status.idle":"2023-10-06T22:58:42.447754Z","shell.execute_reply.started":"2023-10-06T22:58:42.347538Z","shell.execute_reply":"2023-10-06T22:58:42.446642Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"lora_config = LoraConfig.from_pretrained('outputs')\nmodel = get_peft_model(model, lora_config)","metadata":{"id":"L2Hllu-bCuN6","execution":{"iopub.status.busy":"2023-10-06T22:58:44.768715Z","iopub.execute_input":"2023-10-06T22:58:44.769051Z","iopub.status.idle":"2023-10-06T22:58:44.954949Z","shell.execute_reply.started":"2023-10-06T22:58:44.769025Z","shell.execute_reply":"2023-10-06T22:58:44.953914Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"text = \"\"\"I'm selfish, impatient and a little insecure.\"\"\"\n\ndevice = \"cuda:0\"\n\ninputs = tokenizer(text, return_tensors=\"pt\").to(device)\noutputs = model.generate(**inputs, max_new_tokens=150)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2023-10-06T22:58:50.780095Z","iopub.execute_input":"2023-10-06T22:58:50.780411Z","iopub.status.idle":"2023-10-06T23:00:19.951449Z","shell.execute_reply.started":"2023-10-06T22:58:50.780384Z","shell.execute_reply":"2023-10-06T23:00:19.950611Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1421: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n","output_type":"stream"},{"name":"stdout","text":"I'm selfish, impatient and a little insecure. I make mistakes, I am out of control and at times hard to handle. But if you can't handle me at my worst, then you sure as hell don't deserve me at my best.\n\nI'm not perfect, but I'm not trying to be. I'm not trying to be anyone's savior, I'm just trying to be the best version of myself that I can be. I'm not trying to be anyone's hero, I'm just trying to be the best version of myself that I can be. I'm not trying to be anyone's inspiration, I'm just trying to be the best version of myself that I can be. I'm\n","output_type":"stream"}]},{"cell_type":"code","source":"out_df_finetuned, preds_finetuned, labels_finetuned = evaluate_model(model, tokenizer, subset_test_dataset, verbose = False)","metadata":{"execution":{"iopub.status.busy":"2023-10-06T23:03:13.194637Z","iopub.execute_input":"2023-10-06T23:03:13.195014Z","iopub.status.idle":"2023-10-06T23:39:29.757839Z","shell.execute_reply.started":"2023-10-06T23:03:13.194988Z","shell.execute_reply":"2023-10-06T23:39:29.756825Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"100%|██████████| 1094/1094 [36:16<00:00,  1.99s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"zero_shot_accuracy_finetuned, conf_matrix_zero_shot_finetuned =  compute_stats(out_df_finetuned, preds_finetuned, labels_finetuned)","metadata":{"id":"kEESIVXyESi-","execution":{"iopub.status.busy":"2023-10-06T23:39:29.775873Z","iopub.execute_input":"2023-10-06T23:39:29.776494Z","iopub.status.idle":"2023-10-06T23:39:29.791374Z","shell.execute_reply.started":"2023-10-06T23:39:29.776462Z","shell.execute_reply":"2023-10-06T23:39:29.790485Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"overall accuracy: \n0.6910420475319927\nconfusion matrix: \ncorrect forward 756 wrong forward 338 correct backward 682 wrong_backward 412\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\n\nmodel_id_string = model_id.replace(\"/\", \"-\")\n\n# Saving DataFrame to CSV\nout_df_finetuned.to_csv(f'output_df_{model_id_string}_finetuned.csv', sep=\"\\t\", index=False)\n\n# Saving other data as JSON\ndata_to_save = {\n    \"preds\": preds_finetuned,\n    \"labels\": labels_finetuned,\n    \"zero_shot_accuracy\": zero_shot_accuracy_finetuned,\n    \"conf_matrix_zero_shot\": conf_matrix_zero_shot_finetuned\n}\n\nwith open(f'output_data_{model_id_string}_finetuned.json', 'w') as file:\n    json.dump(data_to_save, file)\n\nimport pickle\n\ndata_to_save_pick = {\n    \"out_df\": out_df_finetuned,\n    \"preds\": preds_finetuned,\n    \"labels\": labels_finetuned,\n    \"zero_shot_accuracy\": zero_shot_accuracy_finetuned,\n    \"conf_matrix_zero_shot\": conf_matrix_zero_shot_finetuned\n}\n\nwith open(f'pickle_output_data_{model_id_string}_finetuned.pkl', 'wb') as file:\n    pickle.dump(data_to_save_pick, file)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-06T23:39:29.795078Z","iopub.execute_input":"2023-10-06T23:39:29.795402Z","iopub.status.idle":"2023-10-06T23:39:29.829418Z","shell.execute_reply.started":"2023-10-06T23:39:29.795372Z","shell.execute_reply":"2023-10-06T23:39:29.828462Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2023-10-06T23:43:18.068726Z","iopub.execute_input":"2023-10-06T23:43:18.069063Z","iopub.status.idle":"2023-10-06T23:43:18.078453Z","shell.execute_reply.started":"2023-10-06T23:43:18.069035Z","shell.execute_reply":"2023-10-06T23:43:18.076716Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['startphrase', 'ending1', 'ending2', 'labels', 'valid', 'input_ids', 'attention_mask'],\n        num_rows: 9674\n    })\n    validation: Dataset({\n        features: ['startphrase', 'ending1', 'ending2', 'labels', 'valid', 'input_ids', 'attention_mask'],\n        num_rows: 1094\n    })\n    test: Dataset({\n        features: ['startphrase', 'ending1', 'ending2', 'labels', 'valid', 'input_ids', 'attention_mask'],\n        num_rows: 1146\n    })\n})"},"metadata":{}}]}]}